<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos | Ding's Coding Forge</title>
<meta name=keywords content="kafka,burrow,monitoring,prometheus,thanos,lag"><meta name=description content="People often rely solely on basic Kafka metrics like Input/Output Bytes, missing crucial insights into their event-driven architecture. This post demonstrates how to set up comprehensive topic-level monitoring for Kafka (AWS MSK) using Burrow, Prometheus, and Thanos. By combining Burrow for accurate consumer lag tracking, Prometheus for metric collection, and Thanos for long-term data storage and high availability, you'll achieve effective Kafka monitoring without the high costs and limitations of cloud-native solutions."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/dance-with-burrow/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/dance-with-burrow/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/dance-with-burrow/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/dance-with-burrow/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos"><meta property="og:description" content="People often rely solely on basic Kafka metrics like Input/Output Bytes, missing crucial insights into their event-driven architecture. This post demonstrates how to set up comprehensive topic-level monitoring for Kafka (AWS MSK) using Burrow, Prometheus, and Thanos. By combining Burrow for accurate consumer lag tracking, Prometheus for metric collection, and Thanos for long-term data storage and high availability, you'll achieve effective Kafka monitoring without the high costs and limitations of cloud-native solutions."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-21T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Burrow"><meta property="article:tag" content="Monitoring"><meta property="article:tag" content="Prometheus"><meta property="article:tag" content="Thanos"><meta property="article:tag" content="Lag"><meta property="og:image" content="https://dingyu.dev/en/posts/dance-with-burrow/img/kafka.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/dance-with-burrow/img/kafka.png"><meta name=twitter:title content="[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos"><meta name=twitter:description content="People often rely solely on basic Kafka metrics like Input/Output Bytes, missing crucial insights into their event-driven architecture. This post demonstrates how to set up comprehensive topic-level monitoring for Kafka (AWS MSK) using Burrow, Prometheus, and Thanos. By combining Burrow for accurate consumer lag tracking, Prometheus for metric collection, and Thanos for long-term data storage and high availability, you'll achieve effective Kafka monitoring without the high costs and limitations of cloud-native solutions."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos","item":"https://dingyu.dev/en/posts/dance-with-burrow/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos","name":"[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos","description":"People often rely solely on basic Kafka metrics like Input/Output Bytes, missing crucial insights into their event-driven architecture. This post demonstrates how to set up comprehensive topic-level monitoring for Kafka (AWS MSK) using Burrow, Prometheus, and Thanos. By combining Burrow for accurate consumer lag tracking, Prometheus for metric collection, and Thanos for long-term data storage and high availability, you'll achieve effective Kafka monitoring without the high costs and limitations of cloud-native solutions.","keywords":["kafka","burrow","monitoring","prometheus","thanos","lag"],"articleBody":"Background One of the biggest trade-offs between asynchronous and synchronous programming is that while performance may be improved, it becomes harder to trace.\nThe same is true for event-driven architecture (EDA) using Kafka. It is not easy to track the flow of asynchronously processed data in real-time. In particular, issues often go unnoticed until after they occur, making Kafka monitoring increasingly critical.\nIn event-driven systems, performance monitoring is crucial. In REST API-based architectures, traffic is typically handled using Kubernetes Horizontal Pod Autoscaler (HPA) based on CPU/memory usage and request rates. However, in Kafka-based architectures, the key performance factors are the number of partitions and the processing speed of consumers.\nWhat if there are too few partitions or slow consumers causing lag? → Developers must manually analyze performance and perform partition scaling or consumer scale-out.\nTo detect and address such issues in advance, a Kafka monitoring system was built.\nWe considered three different options for monitoring Kafka performance:\nDesign Comparison of Kafka Monitoring Solutions AWS CloudWatch Using AWS CloudWatch for Kafka monitoring allows metric collection at the PER_TOPIC_PER_PARTITION level.\nKey Monitoring Metrics Metric (AWS/MSK) Description EstimatedTimeLag Time lag (in seconds) of the partition offset after the consumer group reads data OffsetLag Number of offset lag in the partition after consumption by the consumer group Item Description ✅ Easy setup Integrated with AWS MSK by default ✅ Supports CloudWatch Alarm + SNS Simple alert setup available ❌ Viewable only on AWS Console Hard to integrate with external monitoring tools ❌ Cost concerns Additional fees for topic-level monitoring Helm-based Monitoring on EKS (Internal solution, failed attempt) We attempted Kafka monitoring using an internal Helm chart, but it failed due to MSK and EKS residing in different regions.\nItem Description ✅ Internal system integration Smooth integration with in-house systems ❌ MSK and EKS are in different regions Integration not possible ❌ Cost if EKS is redeployed in MSK region Additional expenses may occur Ultimately, this approach was abandoned.\nEC2-based Docker Compose Monitoring (Final Choice) Eventually, we opted to deploy EC2 in the same VPC as MSK and build the Kafka monitoring stack manually.\nUsed JMX Exporter \u0026 Node Exporter for Kafka metric collection Used Burrow to monitor consumer lag Enabled long-term monitoring via Thanos and Prometheus Item Description ✅ Cost-efficient Can run on low-cost T-series EC2 instances ✅ Scalable Easily customizable and extensible ✅ Fine-grained Kafka monitoring Enables detailed tracking via Burrow ❌ Initial setup burden Manual configuration with potential trial-and-error ❌ Lack of Burrow \u0026 Thanos ops experience Required team to learn and operate monitoring stack from scratch Surprisingly, starting from scratch became a benefit, so we decided to build EC2-based monitoring ourselves.\nArchitecture Overview MSK Terminology zookeeper: Stores Kafka metadata and manages Kafka states broker: The server/node where Kafka runs JMX Exporter: Exposes various metrics from Apache Kafka (brokers, producers, consumers) for monitoring via JMX Node Exporter: Exposes CPU and disk metrics Kafka Monitoring Architecture Evolution: Integrating Prometheus, Thanos, and Burrow Our monitoring architecture evolved from standalone Prometheus (V1), to Thanos integration (V2), to including Kafka consumer monitoring with Burrow (V3).\nEach version is compared below with its respective pros and cons.\nV1: Standalone Prometheus Metric Collection Used Prometheus to gather Kafka metrics and added both CloudWatch and Prometheus as data sources in Grafana for monitoring.\nArchitecture Diagram Pros Simple setup using only Prometheus Easy to compare metrics between Prometheus and CloudWatch in Grafana Cons If Prometheus goes down, the entire monitoring stack becomes unavailable → SPOF risk Prometheus stores all metrics in-memory (TSDB), increasing memory usage with metric volume Large TSDB size can degrade Prometheus performance V2: Prometheus + Thanos Sidecar for HA To ensure high availability, we ran two Prometheus instances and added Thanos Sidecars to connect them to a central Thanos Query + Store server.\nArchitecture Diagram Why Thanos? Avoid metric duplication: Thanos Query deduplicates metrics collected from multiple Prometheus instances Separate short-term (Prometheus) and long-term (Thanos Store) storage: Enables restoration from S3 Reduce TSDB size: Lowers memory usage and cost Pros HA support: Continues monitoring even if one Prometheus fails Long-term metric storage: Offload to S3/GCS Resource efficiency: Reduces Prometheus memory usage Cons Increased operational complexity: Requires Sidecar, Query, and Object Storage (S3) configuration Performance limits of Thanos Query: Heavy queries may impact performance V3: Burrow + Prometheus + Thanos Sidecar for Kafka Consumer Monitoring To cut costs and enhance Kafka Consumer Lag monitoring, we replaced CloudWatch with Burrow for metric collection.\nNow the monitoring stack is fully built with Burrow + Prometheus + Thanos, removing CloudWatch.\nArchitecture Diagram Burrow collects Kafka consumer metrics periodically, Prometheus scrapes those metrics, and Thanos Query gathers them from Sidecar.\nWhy Burrow? Cost savings: Eliminates CloudWatch fees Detailed Consumer Lag visibility: Real-time offset tracking for Kafka consumer groups ACL-aware monitoring: Burrow provides fine-grained lag info per topic and group, unlike CloudWatch Pros Reduces CloudWatch cost Detailed insights into Consumer Group lag and partition status Integrates well with existing Prometheus + Thanos stack Cons Setup overhead: Initial integration with Kafka clusters and ACL permissions needed Limited alerting in Burrow: Works best when combined with Prometheus Alertmanager or Grafana Alerta Version Comparison Summary Architecture Pros Cons Verdict V1: Prometheus only Easy and fast setup Lacks HA, high memory usage Inefficient due to SPOF V2: Prometheus + Thanos HA, long-term storage, memory optimization More complex setup Good for scalable systems V3: Burrow + Prometheus + Thanos Reduces cost, adds detailed monitoring, integrates well Needs setup, weak built-in alerts ✅ Final choice To monitor Kafka effectively, a combination of Burrow + Prometheus + Thanos was the optimal solution for comprehensive Kafka consumer lag visibility.\nImplementation Burrow Kafka Consumer Lag Monitoring with Burrow While Kafka clients can expose records-lag-max using the metrics() method, this only reflects the lag of the slowest partition, making it difficult to get a full picture of the consumer’s performance. Additionally, if the consumer stops, lag will no longer be measured, requiring an external monitoring system. A representative solution is LinkedIn’s Burrow.\nBurrow: Kafka Consumer Monitoring Reinvented\nConsumer A: Lag is consistently decreasing → Healthy Consumer B: Lag temporarily spiked but recovered → Healthy Consumer C: Lag remains constant → Healthy Consumer D: Lag temporarily increased but recovered → Healthy traffic pattern The Problem with Lag Thresholds Threshold-based detection is prone to false positives. For example, if a threshold of 250 is set, consumers B and D, which are behaving normally, could be incorrectly flagged as unhealthy.\n⚠️ You cannot determine the health of a Kafka consumer solely based on MaxLag!\nHow Burrow Solves This Burrow reads the internal Kafka topic where consumer offsets are committed and evaluates the state of each consumer independently. It’s not dependent on any specific consumer, and automatically monitors all consumers to enable objective status analysis.\nHow Burrow Works Burrow uses a sliding window technique to analyze the last N offset commits. LinkedIn recommends using 10 commits (approx. 10 minutes) to evaluate the following:\nIs the consumer committing offsets regularly? Are the offsets increasing? Is lag increasing? Is there a sustained pattern of increasing lag? Based on this, Burrow categorizes the consumer’s status as:\n✅ OK: Operating normally ⚠️ Warning: Lag is increasing ❌ Error: Consumer has stopped or stalled Burrow detects anomalies through pattern analysis rather than thresholds, and exposes this information via HTTP API and alerting integrations.\nExample Burrow API GET /v2/kafka/local/consumer/dingyu/status Returns the current state of a consumer and details about affected topics and partitions.\nIntegration Guide 1. Prerequisites OS: Amazon Linux 2 or Ubuntu 20.04+ Install Docker and Docker Compose Open these ports in the EC2 security group: Prometheus: 9090 Thanos Sidecar: 10901, 10902 Burrow: 8000 2. Install Packages # Install Docker sudo yum install -y docker sudo systemctl enable docker --now # Install Docker Compose sudo curl -L \"https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 3. Folder Structure MSK-MONITORING/ ├── templates/ # Configuration templates │ ├── burrow.tmpl.toml # Burrow config template │ ├── prometheus.tmpl.yaml # Prometheus config template │ ├── targets.tmpl.json # Prometheus targets ├── deploy.sh # Deployment script ├── docker-compose.yaml # Docker Compose file ├── Makefile # Build and render utility ├── README.md # Project documentation 4. Core Components 4.1 Burrow Monitors Kafka consumer states Configured using burrow.tmpl.toml with environment variable substitution Connects to MSK with SASL/TLS Exposes status via HTTP Burrow Troubleshooting SASL authentication lacked documentation, resulting in heavy trial and error Even when skipping TLS auth, skip verify had to be explicitly set Required debugging with custom sarama client configuration Burrow supports SCRAM-SHA-512 and SCRAM-SHA-256 mechanisms. Make sure to match the mechanism used by MSK.\n4.2 Prometheus Collects metrics from Kafka and Burrow Config based on prometheus.tmpl.yaml Uses targets.tmpl.json to gather JMX and Node Exporter metrics 4.3 Docker Compose Launches Burrow, Prometheus, and Thanos Sidecar containers Ensures smooth inter-container communication 4.4 Makefile make render: Renders config files with current environment variables into generated/ directory 4.5 Environment Variable Management Create a .env file in the same directory as docker-compose.yaml, for example:\nPROM_CLUSTER={your-cluster-name} PROMETHEUS_PORT=9090 BURROW_PORT=8000 ZOOKEEPER_HOST_1={zookeeper1_endpoint} ZOOKEEPER_HOST_2={zookeeper2_endpoint} ZOOKEEPER_HOST_3={zookeeper3_endpoint} BROKER_HOST_1={broker1_endpoint} BROKER_HOST_2={broker2_endpoint} BROKER_HOST_3={broker3_endpoint} BURROW_USERNAME={user} BURROW_PASSWORD={password} 5. Setup and Launch 5.1 Clone the Project git clone https://github.com/dings-things/msk-monitoring-docker-compose.git cd msk-monitoring-docker-compose 5.2 Configure Environment Variables Create a .env file.\n5.3 Run Deployment Script chmod +x deploy.sh ./deploy.sh 5.4 Manual Startup (optional) make render docker compose up -d Deployment Tips For detailed usage, see the GitHub repo.\nIn production environments, you can use GitLab Snippets to manage environment variables dynamically via API.\nBuilding the Dashboard Here are the key metrics you should monitor:\nStatus per Topic/Partition: Detect anomalies per partition Use burrow_kafka_topic_partition_status Disk Usage: Alert when nearing disk limits Use node_filesystem_avail_bytes vs. size_bytes for disk utilization CPU Usage: Alert on CPU threshold breaches (may require partition scaling) Use node_cpu_seconds_total to measure user vs idle CPU Consumer Group Health: Overall health of consumers (apps) Use burrow_kafka_consumer_status Group/Topic Lag: Lag per topic/group Use burrow_kafka_consumer_partition_lag Lag per Partition: Granular lag analysis Use tabular view of burrow_kafka_consumer_partition_lag Current Offset: Latest committed offset Use burrow_kafka_consumer_status Final Architecture References Burrow Official Docs Prometheus Documentation Thanos for Prometheus Scaling Operating AWS MSK Connect Effectively MSK Monitoring at Yanolja ","wordCount":"1665","inLanguage":"en","image":"https://dingyu.dev/en/posts/dance-with-burrow/img/kafka.png","datePublished":"2025-03-21T00:00:00Z","dateModified":"2025-03-21T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/dance-with-burrow/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos</h1><div class=post-description>People often rely solely on basic Kafka metrics like Input/Output Bytes, missing crucial insights into their event-driven architecture. This post demonstrates how to set up comprehensive topic-level monitoring for Kafka (AWS MSK) using Burrow, Prometheus, and Thanos. By combining Burrow for accurate consumer lag tracking, Prometheus for metric collection, and Thanos for long-term data storage and high availability, you'll achieve effective Kafka monitoring without the high costs and limitations of cloud-native solutions.</div><div class=post-meta><span title='2025-03-21 00:00:00 +0000 UTC'>March 21, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1665 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/dance-with-burrow/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/dance-with-burrow/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/kafka.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#background aria-label=Background>Background</a></li><li><a href=#design aria-label=Design>Design</a><ul><li><a href=#comparison-of-kafka-monitoring-solutions aria-label="Comparison of Kafka Monitoring Solutions">Comparison of Kafka Monitoring Solutions</a><ul><li><a href=#aws-cloudwatch aria-label="AWS CloudWatch">AWS CloudWatch</a><ul><li><a href=#key-monitoring-metrics aria-label="Key Monitoring Metrics"><strong>Key Monitoring Metrics</strong></a></li></ul></li><li><a href=#helm-based-monitoring-on-eks-internal-solution-failed-attempt aria-label="Helm-based Monitoring on EKS (Internal solution, failed attempt)">Helm-based Monitoring on EKS (Internal solution, failed attempt)</a></li><li><a href=#ec2-based-docker-compose-monitoring-final-choice aria-label="EC2-based Docker Compose Monitoring (Final Choice)">EC2-based Docker Compose Monitoring (Final Choice)</a></li></ul></li><li><a href=#architecture-overview aria-label="Architecture Overview">Architecture Overview</a><ul><ul><li><a href=#msk-terminology aria-label="MSK Terminology">MSK Terminology</a></li><li><a href=#kafka-monitoring-architecture-evolution-integrating-prometheus-thanos-and-burrow aria-label="Kafka Monitoring Architecture Evolution: Integrating Prometheus, Thanos, and Burrow">Kafka Monitoring Architecture Evolution: Integrating Prometheus, Thanos, and Burrow</a></li></ul><li><a href=#v1-standalone-prometheus-metric-collection aria-label="V1: Standalone Prometheus Metric Collection">V1: Standalone Prometheus Metric Collection</a><ul><li><a href=#architecture-diagram aria-label="Architecture Diagram">Architecture Diagram</a></li><li><a href=#pros aria-label=Pros>Pros</a></li><li><a href=#cons aria-label=Cons>Cons</a></li></ul></li><li><a href=#v2-prometheus--thanos-sidecar-for-ha aria-label="V2: Prometheus + Thanos Sidecar for HA">V2: Prometheus + Thanos Sidecar for HA</a><ul><li><a href=#architecture-diagram-1 aria-label="Architecture Diagram">Architecture Diagram</a></li><li><a href=#why-thanos aria-label="Why Thanos?">Why Thanos?</a></li><li><a href=#pros-1 aria-label=Pros>Pros</a></li><li><a href=#cons-1 aria-label=Cons>Cons</a></li></ul></li><li><a href=#v3-burrow--prometheus--thanos-sidecar-for-kafka-consumer-monitoring aria-label="V3: Burrow + Prometheus + Thanos Sidecar for Kafka Consumer Monitoring">V3: Burrow + Prometheus + Thanos Sidecar for Kafka Consumer Monitoring</a><ul><li><a href=#architecture-diagram-2 aria-label="Architecture Diagram">Architecture Diagram</a></li><li><a href=#why-burrow aria-label="Why Burrow?">Why Burrow?</a></li><li><a href=#pros-2 aria-label=Pros>Pros</a></li><li><a href=#cons-2 aria-label=Cons>Cons</a></li></ul></li><li><a href=#version-comparison-summary aria-label="Version Comparison Summary">Version Comparison Summary</a></li></ul></li></ul></li><li><a href=#implementation aria-label=Implementation>Implementation</a><ul><li><a href=#burrow aria-label=Burrow>Burrow</a><ul><li><a href=#kafka-consumer-lag-monitoring-with-burrow aria-label="Kafka Consumer Lag Monitoring with Burrow">Kafka Consumer Lag Monitoring with Burrow</a></li><li><a href=#the-problem-with-lag-thresholds aria-label="The Problem with Lag Thresholds">The Problem with Lag Thresholds</a></li><li><a href=#how-burrow-solves-this aria-label="How Burrow Solves This">How Burrow Solves This</a><ul><li><a href=#how-burrow-works aria-label="How Burrow Works">How Burrow Works</a></li><li><a href=#example-burrow-api aria-label="Example Burrow API">Example Burrow API</a></li></ul></li></ul></li><li><a href=#integration-guide aria-label="Integration Guide">Integration Guide</a><ul><li><a href=#1-prerequisites aria-label="1. Prerequisites">1. Prerequisites</a></li><li><a href=#2-install-packages aria-label="2. Install Packages">2. Install Packages</a></li><li><a href=#3-folder-structure aria-label="3. Folder Structure">3. Folder Structure</a></li><li><a href=#4-core-components aria-label="4. Core Components">4. Core Components</a><ul><li><a href=#41-burrow aria-label="4.1 Burrow">4.1 Burrow</a><ul><li><a href=#burrow-troubleshooting aria-label="Burrow Troubleshooting">Burrow Troubleshooting</a></li></ul></li><li><a href=#42-prometheus aria-label="4.2 Prometheus">4.2 Prometheus</a></li><li><a href=#43-docker-compose aria-label="4.3 Docker Compose">4.3 Docker Compose</a></li><li><a href=#44-makefile aria-label="4.4 Makefile">4.4 Makefile</a></li><li><a href=#45-environment-variable-management aria-label="4.5 Environment Variable Management">4.5 Environment Variable Management</a></li></ul></li><li><a href=#5-setup-and-launch aria-label="5. Setup and Launch">5. Setup and Launch</a><ul><li><a href=#51-clone-the-project aria-label="5.1 Clone the Project">5.1 Clone the Project</a></li><li><a href=#52-configure-environment-variables aria-label="5.2 Configure Environment Variables">5.2 Configure Environment Variables</a></li><li><a href=#53-run-deployment-script aria-label="5.3 Run Deployment Script">5.3 Run Deployment Script</a></li><li><a href=#54-manual-startup-optional aria-label="5.4 Manual Startup (optional)">5.4 Manual Startup (optional)</a></li></ul></li><li><a href=#deployment-tips aria-label="Deployment Tips">Deployment Tips</a></li></ul></li><li><a href=#building-the-dashboard aria-label="Building the Dashboard">Building the Dashboard</a></li></ul></li><li><a href=#final-architecture aria-label="Final Architecture">Final Architecture</a><ul><li><a href=#references aria-label=References>References</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h1><p>One of the biggest trade-offs between asynchronous and synchronous programming is that while performance may be improved, <strong>it becomes harder to trace</strong>.</p><p>The same is true for event-driven architecture (EDA) using Kafka. It is not easy to track the flow of asynchronously processed data in real-time.
In particular, issues often go unnoticed until after they occur, making Kafka monitoring increasingly critical.</p><p>In event-driven systems, <strong>performance monitoring</strong> is crucial. In REST API-based architectures, traffic is typically handled using Kubernetes Horizontal Pod Autoscaler (HPA) based on CPU/memory usage and request rates.
However, in Kafka-based architectures, the key performance factors are the <strong>number of partitions</strong> and the <strong>processing speed of consumers</strong>.</p><p>What if there are <strong>too few partitions or slow consumers causing lag</strong>?
→ Developers must manually analyze performance and perform <code>partition scaling</code> or <code>consumer scale-out</code>.</p><p>To detect and address such issues in advance, a <strong>Kafka monitoring system was built</strong>.</p><p>We considered three different options for monitoring Kafka performance:</p><h1 id=design>Design<a hidden class=anchor aria-hidden=true href=#design>#</a></h1><h2 id=comparison-of-kafka-monitoring-solutions>Comparison of Kafka Monitoring Solutions<a hidden class=anchor aria-hidden=true href=#comparison-of-kafka-monitoring-solutions>#</a></h2><h3 id=aws-cloudwatch>AWS CloudWatch<a hidden class=anchor aria-hidden=true href=#aws-cloudwatch>#</a></h3><p>Using AWS CloudWatch for Kafka monitoring allows metric collection at the
<strong>PER_TOPIC_PER_PARTITION</strong> level.</p><h4 id=key-monitoring-metrics><strong>Key Monitoring Metrics</strong><a hidden class=anchor aria-hidden=true href=#key-monitoring-metrics>#</a></h4><table><thead><tr><th>Metric (<code>AWS/MSK</code>)</th><th>Description</th></tr></thead><tbody><tr><td><code>EstimatedTimeLag</code></td><td>Time lag (in seconds) of the partition offset after the consumer group reads data</td></tr><tr><td><code>OffsetLag</code></td><td>Number of offset lag in the partition after consumption by the consumer group</td></tr></tbody></table><table><thead><tr><th>Item</th><th>Description</th></tr></thead><tbody><tr><td><strong>✅ Easy setup</strong></td><td>Integrated with AWS MSK by default</td></tr><tr><td><strong>✅ Supports CloudWatch Alarm + SNS</strong></td><td>Simple alert setup available</td></tr><tr><td><strong>❌ Viewable only on AWS Console</strong></td><td>Hard to integrate with external monitoring tools</td></tr><tr><td><strong>❌ Cost concerns</strong></td><td>Additional fees for topic-level monitoring</td></tr></tbody></table><hr><h3 id=helm-based-monitoring-on-eks-internal-solution-failed-attempt>Helm-based Monitoring on EKS (Internal solution, failed attempt)<a hidden class=anchor aria-hidden=true href=#helm-based-monitoring-on-eks-internal-solution-failed-attempt>#</a></h3><p>We attempted Kafka monitoring using an internal Helm chart,
but it failed due to <strong>MSK and EKS residing in different regions</strong>.</p><table><thead><tr><th>Item</th><th>Description</th></tr></thead><tbody><tr><td><strong>✅ Internal system integration</strong></td><td>Smooth integration with in-house systems</td></tr><tr><td><strong>❌ MSK and EKS are in different regions</strong></td><td>Integration not possible</td></tr><tr><td><strong>❌ Cost if EKS is redeployed in MSK region</strong></td><td>Additional expenses may occur</td></tr></tbody></table><p>Ultimately, this approach was abandoned.</p><hr><h3 id=ec2-based-docker-compose-monitoring-final-choice>EC2-based Docker Compose Monitoring (Final Choice)<a hidden class=anchor aria-hidden=true href=#ec2-based-docker-compose-monitoring-final-choice>#</a></h3><p>Eventually, we opted to <strong>deploy EC2 in the same VPC as MSK and build the Kafka monitoring stack manually</strong>.</p><ul><li>Used <strong>JMX Exporter & Node Exporter</strong> for Kafka metric collection</li><li>Used <strong>Burrow</strong> to monitor consumer lag</li><li>Enabled <strong>long-term monitoring via Thanos and Prometheus</strong></li></ul><table><thead><tr><th>Item</th><th>Description</th></tr></thead><tbody><tr><td><strong>✅ Cost-efficient</strong></td><td>Can run on low-cost T-series EC2 instances</td></tr><tr><td><strong>✅ Scalable</strong></td><td>Easily customizable and extensible</td></tr><tr><td><strong>✅ Fine-grained Kafka monitoring</strong></td><td>Enables detailed tracking via Burrow</td></tr><tr><td><strong>❌ Initial setup burden</strong></td><td>Manual configuration with potential trial-and-error</td></tr><tr><td><strong>❌ Lack of Burrow & Thanos ops experience</strong></td><td>Required team to learn and operate monitoring stack from scratch</td></tr></tbody></table><p>Surprisingly, starting from scratch became a <strong>benefit</strong>, so we decided to build EC2-based monitoring ourselves.</p><h2 id=architecture-overview>Architecture Overview<a hidden class=anchor aria-hidden=true href=#architecture-overview>#</a></h2><blockquote><h4 id=msk-terminology>MSK Terminology<a hidden class=anchor aria-hidden=true href=#msk-terminology>#</a></h4><ul><li><code>zookeeper</code>: Stores Kafka metadata and manages Kafka states</li><li><code>broker</code>: The server/node where Kafka runs</li><li><code>JMX Exporter</code>: Exposes various metrics from Apache Kafka (brokers, producers, consumers) for monitoring via JMX</li><li><code>Node Exporter</code>: Exposes CPU and disk metrics</li></ul></blockquote><h4 id=kafka-monitoring-architecture-evolution-integrating-prometheus-thanos-and-burrow>Kafka Monitoring Architecture Evolution: Integrating Prometheus, Thanos, and Burrow<a hidden class=anchor aria-hidden=true href=#kafka-monitoring-architecture-evolution-integrating-prometheus-thanos-and-burrow>#</a></h4><p>Our monitoring architecture evolved from standalone Prometheus (V1), to Thanos integration (V2), to including Kafka consumer monitoring with Burrow (V3).</p><p>Each version is compared below with its respective pros and cons.</p><hr><h3 id=v1-standalone-prometheus-metric-collection>V1: Standalone Prometheus Metric Collection<a hidden class=anchor aria-hidden=true href=#v1-standalone-prometheus-metric-collection>#</a></h3><p>Used Prometheus to gather Kafka metrics and added both <code>CloudWatch</code> and <code>Prometheus</code> as data sources in Grafana for monitoring.</p><h4 id=architecture-diagram>Architecture Diagram<a hidden class=anchor aria-hidden=true href=#architecture-diagram>#</a></h4><p><img loading=lazy src=/posts/dance-with-burrow/v1-monitor.png></p><h4 id=pros>Pros<a hidden class=anchor aria-hidden=true href=#pros>#</a></h4><ul><li>Simple setup using only Prometheus</li><li>Easy to compare metrics between Prometheus and CloudWatch in Grafana</li></ul><h4 id=cons>Cons<a hidden class=anchor aria-hidden=true href=#cons>#</a></h4><ul><li>If Prometheus goes down, the entire monitoring stack becomes unavailable → <strong>SPOF risk</strong></li><li>Prometheus stores all metrics in-memory (TSDB), increasing memory usage with metric volume</li><li>Large TSDB size can degrade Prometheus performance</li></ul><hr><h3 id=v2-prometheus--thanos-sidecar-for-ha>V2: Prometheus + Thanos Sidecar for HA<a hidden class=anchor aria-hidden=true href=#v2-prometheus--thanos-sidecar-for-ha>#</a></h3><p>To ensure high availability, we ran <strong>two Prometheus instances</strong> and added Thanos Sidecars to connect them to a central <strong>Thanos Query + Store server</strong>.</p><h4 id=architecture-diagram-1>Architecture Diagram<a hidden class=anchor aria-hidden=true href=#architecture-diagram-1>#</a></h4><p><img loading=lazy src=/posts/dance-with-burrow/v2-monitor.png></p><h4 id=why-thanos>Why Thanos?<a hidden class=anchor aria-hidden=true href=#why-thanos>#</a></h4><ul><li><strong>Avoid metric duplication</strong>: Thanos Query deduplicates metrics collected from multiple Prometheus instances</li><li><strong>Separate short-term (Prometheus) and long-term (Thanos Store) storage</strong>: Enables restoration from S3</li><li><strong>Reduce TSDB size</strong>: Lowers memory usage and cost</li></ul><h4 id=pros-1>Pros<a hidden class=anchor aria-hidden=true href=#pros-1>#</a></h4><ul><li><strong>HA support</strong>: Continues monitoring even if one Prometheus fails</li><li><strong>Long-term metric storage</strong>: Offload to S3/GCS</li><li><strong>Resource efficiency</strong>: Reduces Prometheus memory usage</li></ul><h4 id=cons-1>Cons<a hidden class=anchor aria-hidden=true href=#cons-1>#</a></h4><ul><li><strong>Increased operational complexity</strong>: Requires Sidecar, Query, and Object Storage (S3) configuration</li><li><strong>Performance limits of Thanos Query</strong>: Heavy queries may impact performance</li></ul><hr><h3 id=v3-burrow--prometheus--thanos-sidecar-for-kafka-consumer-monitoring>V3: Burrow + Prometheus + Thanos Sidecar for Kafka Consumer Monitoring<a hidden class=anchor aria-hidden=true href=#v3-burrow--prometheus--thanos-sidecar-for-kafka-consumer-monitoring>#</a></h3><p>To cut costs and enhance Kafka Consumer Lag monitoring,
we replaced CloudWatch with Burrow for metric collection.</p><p>Now the monitoring stack is fully built with <strong>Burrow + Prometheus + Thanos</strong>, removing CloudWatch.</p><h4 id=architecture-diagram-2>Architecture Diagram<a hidden class=anchor aria-hidden=true href=#architecture-diagram-2>#</a></h4><p><img loading=lazy src=/posts/dance-with-burrow/v3-monitor.png></p><blockquote><p>Burrow collects Kafka consumer metrics periodically, Prometheus scrapes those metrics, and Thanos Query gathers them from Sidecar.</p></blockquote><h4 id=why-burrow>Why Burrow?<a hidden class=anchor aria-hidden=true href=#why-burrow>#</a></h4><ul><li><strong>Cost savings</strong>: Eliminates CloudWatch fees</li><li><strong>Detailed Consumer Lag visibility</strong>: Real-time offset tracking for Kafka consumer groups</li><li><strong>ACL-aware monitoring</strong>: Burrow provides fine-grained lag info per topic and group, unlike CloudWatch</li></ul><h4 id=pros-2>Pros<a hidden class=anchor aria-hidden=true href=#pros-2>#</a></h4><ul><li><strong>Reduces CloudWatch cost</strong></li><li><strong>Detailed insights into Consumer Group lag and partition status</strong></li><li><strong>Integrates well with existing Prometheus + Thanos stack</strong></li></ul><h4 id=cons-2>Cons<a hidden class=anchor aria-hidden=true href=#cons-2>#</a></h4><ul><li><strong>Setup overhead</strong>: Initial integration with Kafka clusters and ACL permissions needed</li><li><strong>Limited alerting in Burrow</strong>: Works best when combined with Prometheus Alertmanager or Grafana Alerta</li></ul><hr><h3 id=version-comparison-summary>Version Comparison Summary<a hidden class=anchor aria-hidden=true href=#version-comparison-summary>#</a></h3><table><thead><tr><th>Architecture</th><th>Pros</th><th>Cons</th><th>Verdict</th></tr></thead><tbody><tr><td><strong>V1: Prometheus only</strong></td><td>Easy and fast setup</td><td>Lacks HA, high memory usage</td><td>Inefficient due to SPOF</td></tr><tr><td><strong>V2: Prometheus + Thanos</strong></td><td>HA, long-term storage, memory optimization</td><td>More complex setup</td><td>Good for scalable systems</td></tr><tr><td><strong>V3: Burrow + Prometheus + Thanos</strong></td><td>Reduces cost, adds detailed monitoring, integrates well</td><td>Needs setup, weak built-in alerts</td><td>✅ Final choice</td></tr></tbody></table><p>To monitor Kafka effectively,
<strong>a combination of Burrow + Prometheus + Thanos was the optimal solution for comprehensive Kafka consumer lag visibility.</strong></p><h1 id=implementation>Implementation<a hidden class=anchor aria-hidden=true href=#implementation>#</a></h1><h2 id=burrow>Burrow<a hidden class=anchor aria-hidden=true href=#burrow>#</a></h2><h3 id=kafka-consumer-lag-monitoring-with-burrow>Kafka Consumer Lag Monitoring with Burrow<a hidden class=anchor aria-hidden=true href=#kafka-consumer-lag-monitoring-with-burrow>#</a></h3><p>While Kafka clients can expose <code>records-lag-max</code> using the <code>metrics()</code> method, this only reflects the <strong>lag of the slowest partition</strong>, making it difficult to get a full picture of the consumer’s performance. Additionally, if the consumer stops, lag will no longer be measured, requiring an <strong>external monitoring system</strong>. A representative solution is LinkedIn’s <strong>Burrow</strong>.</p><p><img alt="Kafka Consumer Lag Monitoring" loading=lazy src=/posts/dance-with-burrow/image.png></p><p><a href=https://engineering.linkedin.com/apache-kafka/burrow-kafka-consumer-monitoring-reinvented>Burrow: Kafka Consumer Monitoring Reinvented</a></p><ul><li><strong>Consumer A</strong>: Lag is consistently decreasing → Healthy</li><li><strong>Consumer B</strong>: Lag temporarily spiked but recovered → Healthy</li><li><strong>Consumer C</strong>: Lag remains constant → Healthy</li><li><strong>Consumer D</strong>: Lag temporarily increased but recovered → Healthy traffic pattern</li></ul><h3 id=the-problem-with-lag-thresholds>The Problem with Lag Thresholds<a hidden class=anchor aria-hidden=true href=#the-problem-with-lag-thresholds>#</a></h3><p><strong>Threshold-based detection is prone to false positives</strong>. For example, if a threshold of <code>250</code> is set, <strong>consumers B and D</strong>, which are behaving normally, could be incorrectly flagged as unhealthy.</p><blockquote><p>⚠️ You cannot determine the health of a Kafka consumer solely based on <code>MaxLag</code>!</p></blockquote><hr><h3 id=how-burrow-solves-this>How Burrow Solves This<a hidden class=anchor aria-hidden=true href=#how-burrow-solves-this>#</a></h3><p>Burrow <strong>reads the internal Kafka topic where consumer offsets are committed</strong> and evaluates the state of each consumer independently. It’s not dependent on any specific consumer, and <strong>automatically monitors all consumers</strong> to enable <strong>objective status analysis</strong>.</p><p><img loading=lazy src=/posts/dance-with-burrow/image-1.png></p><h4 id=how-burrow-works>How Burrow Works<a hidden class=anchor aria-hidden=true href=#how-burrow-works>#</a></h4><p>Burrow uses a <strong>sliding window technique</strong> to analyze the last N offset commits. LinkedIn recommends using <strong>10 commits (approx. 10 minutes)</strong> to evaluate the following:</p><ol><li><strong>Is the consumer committing offsets regularly?</strong></li><li><strong>Are the offsets increasing?</strong></li><li><strong>Is lag increasing?</strong></li><li><strong>Is there a sustained pattern of increasing lag?</strong></li></ol><p>Based on this, Burrow categorizes the consumer’s status as:</p><ul><li><strong>✅ OK</strong>: Operating normally</li><li><strong>⚠️ Warning</strong>: Lag is increasing</li><li><strong>❌ Error</strong>: Consumer has stopped or stalled</li></ul><p>Burrow detects anomalies through <strong>pattern analysis rather than thresholds</strong>, and exposes this information via HTTP API and alerting integrations.</p><h4 id=example-burrow-api>Example Burrow API<a hidden class=anchor aria-hidden=true href=#example-burrow-api>#</a></h4><pre tabindex=0><code>GET /v2/kafka/local/consumer/dingyu/status
</code></pre><p>Returns the current state of a consumer and details about affected topics and partitions.</p><h2 id=integration-guide>Integration Guide<a hidden class=anchor aria-hidden=true href=#integration-guide>#</a></h2><h3 id=1-prerequisites>1. Prerequisites<a hidden class=anchor aria-hidden=true href=#1-prerequisites>#</a></h3><ul><li>OS: Amazon Linux 2 or Ubuntu 20.04+</li><li>Install Docker and Docker Compose</li><li>Open these ports in the EC2 security group:<ul><li>Prometheus: <code>9090</code></li><li>Thanos Sidecar: <code>10901</code>, <code>10902</code></li><li>Burrow: <code>8000</code></li></ul></li></ul><h3 id=2-install-packages>2. Install Packages<a hidden class=anchor aria-hidden=true href=#2-install-packages>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install Docker</span>
</span></span><span class=line><span class=cl>sudo yum install -y docker
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> docker --now
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install Docker Compose</span>
</span></span><span class=line><span class=cl>sudo curl -L <span class=s2>&#34;https://github.com/docker/compose/releases/latest/download/docker-compose-</span><span class=k>$(</span>uname -s<span class=k>)</span><span class=s2>-</span><span class=k>$(</span>uname -m<span class=k>)</span><span class=s2>&#34;</span> -o /usr/local/bin/docker-compose
</span></span><span class=line><span class=cl>sudo chmod +x /usr/local/bin/docker-compose
</span></span></code></pre></div><h3 id=3-folder-structure>3. Folder Structure<a hidden class=anchor aria-hidden=true href=#3-folder-structure>#</a></h3><pre tabindex=0><code>MSK-MONITORING/
├── templates/                # Configuration templates
│   ├── burrow.tmpl.toml       # Burrow config template
│   ├── prometheus.tmpl.yaml   # Prometheus config template
│   ├── targets.tmpl.json      # Prometheus targets
├── deploy.sh                  # Deployment script
├── docker-compose.yaml        # Docker Compose file
├── Makefile                   # Build and render utility
├── README.md                  # Project documentation
</code></pre><h3 id=4-core-components>4. Core Components<a hidden class=anchor aria-hidden=true href=#4-core-components>#</a></h3><h4 id=41-burrow>4.1 Burrow<a hidden class=anchor aria-hidden=true href=#41-burrow>#</a></h4><ul><li>Monitors Kafka consumer states</li><li>Configured using <code>burrow.tmpl.toml</code> with environment variable substitution</li><li>Connects to MSK with SASL/TLS</li><li>Exposes status via HTTP</li></ul><h5 id=burrow-troubleshooting>Burrow Troubleshooting<a hidden class=anchor aria-hidden=true href=#burrow-troubleshooting>#</a></h5><ul><li>SASL authentication lacked documentation, resulting in heavy trial and error</li><li>Even when skipping TLS auth, <code>skip verify</code> had to be explicitly set</li><li>Required debugging with custom <code>sarama</code> client configuration</li></ul><p><img loading=lazy src=/posts/dance-with-burrow/image-3.png></p><p>Burrow supports <code>SCRAM-SHA-512</code> and <code>SCRAM-SHA-256</code> mechanisms. <strong>Make sure to match the mechanism used by MSK</strong>.</p><h4 id=42-prometheus>4.2 Prometheus<a hidden class=anchor aria-hidden=true href=#42-prometheus>#</a></h4><ul><li>Collects metrics from Kafka and Burrow</li><li>Config based on <code>prometheus.tmpl.yaml</code></li><li>Uses <code>targets.tmpl.json</code> to gather JMX and Node Exporter metrics</li></ul><h4 id=43-docker-compose>4.3 Docker Compose<a hidden class=anchor aria-hidden=true href=#43-docker-compose>#</a></h4><ul><li>Launches Burrow, Prometheus, and Thanos Sidecar containers</li><li>Ensures smooth inter-container communication</li></ul><h4 id=44-makefile>4.4 Makefile<a hidden class=anchor aria-hidden=true href=#44-makefile>#</a></h4><ul><li><code>make render</code>: Renders config files with current environment variables into <code>generated/</code> directory</li></ul><h4 id=45-environment-variable-management>4.5 Environment Variable Management<a hidden class=anchor aria-hidden=true href=#45-environment-variable-management>#</a></h4><p>Create a <code>.env</code> file in the same directory as <code>docker-compose.yaml</code>, for example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>PROM_CLUSTER</span><span class=o>={</span>your-cluster-name<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>PROMETHEUS_PORT</span><span class=o>=</span><span class=m>9090</span>
</span></span><span class=line><span class=cl><span class=nv>BURROW_PORT</span><span class=o>=</span><span class=m>8000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>ZOOKEEPER_HOST_1</span><span class=o>={</span>zookeeper1_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>ZOOKEEPER_HOST_2</span><span class=o>={</span>zookeeper2_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>ZOOKEEPER_HOST_3</span><span class=o>={</span>zookeeper3_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>BROKER_HOST_1</span><span class=o>={</span>broker1_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>BROKER_HOST_2</span><span class=o>={</span>broker2_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>BROKER_HOST_3</span><span class=o>={</span>broker3_endpoint<span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>BURROW_USERNAME</span><span class=o>={</span>user<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=nv>BURROW_PASSWORD</span><span class=o>={</span>password<span class=o>}</span>
</span></span></code></pre></div><h3 id=5-setup-and-launch>5. Setup and Launch<a hidden class=anchor aria-hidden=true href=#5-setup-and-launch>#</a></h3><h4 id=51-clone-the-project>5.1 Clone the Project<a hidden class=anchor aria-hidden=true href=#51-clone-the-project>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>git clone https://github.com/dings-things/msk-monitoring-docker-compose.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> msk-monitoring-docker-compose
</span></span></code></pre></div><h4 id=52-configure-environment-variables>5.2 Configure Environment Variables<a hidden class=anchor aria-hidden=true href=#52-configure-environment-variables>#</a></h4><p>Create a <code>.env</code> file.</p><h4 id=53-run-deployment-script>5.3 Run Deployment Script<a hidden class=anchor aria-hidden=true href=#53-run-deployment-script>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>chmod +x deploy.sh
</span></span><span class=line><span class=cl>./deploy.sh
</span></span></code></pre></div><h4 id=54-manual-startup-optional>5.4 Manual Startup (optional)<a hidden class=anchor aria-hidden=true href=#54-manual-startup-optional>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>make render
</span></span><span class=line><span class=cl>docker compose up -d
</span></span></code></pre></div><h3 id=deployment-tips>Deployment Tips<a hidden class=anchor aria-hidden=true href=#deployment-tips>#</a></h3><p>For detailed usage, see the <a href=https://github.com/dings-things/msk-monitoring-docker-compose>GitHub repo</a>.</p><p>In production environments, you can use <a href=https://docs.gitlab.com/user/snippets/>GitLab Snippets</a> to manage environment variables dynamically via API.</p><p><img loading=lazy src=/posts/dance-with-burrow/image-2.png></p><h2 id=building-the-dashboard>Building the Dashboard<a hidden class=anchor aria-hidden=true href=#building-the-dashboard>#</a></h2><p>Here are the key metrics you should monitor:</p><ul><li><strong>Status per Topic/Partition</strong>: Detect anomalies per partition<ul><li>Use <code>burrow_kafka_topic_partition_status</code></li></ul></li><li><strong>Disk Usage</strong>: Alert when nearing disk limits<ul><li>Use <code>node_filesystem_avail_bytes</code> vs. <code>size_bytes</code> for disk utilization</li></ul></li><li><strong>CPU Usage</strong>: Alert on CPU threshold breaches (may require partition scaling)<ul><li>Use <code>node_cpu_seconds_total</code> to measure user vs idle CPU</li></ul></li><li><strong>Consumer Group Health</strong>: Overall health of consumers (apps)<ul><li>Use <code>burrow_kafka_consumer_status</code></li></ul></li><li><strong>Group/Topic Lag</strong>: Lag per topic/group<ul><li>Use <code>burrow_kafka_consumer_partition_lag</code></li></ul></li><li><strong>Lag per Partition</strong>: Granular lag analysis<ul><li>Use tabular view of <code>burrow_kafka_consumer_partition_lag</code></li></ul></li><li><strong>Current Offset</strong>: Latest committed offset<ul><li>Use <code>burrow_kafka_consumer_status</code></li></ul></li></ul><p><img loading=lazy src=/posts/dance-with-burrow/msk-monitoring-dashboard.png></p><h1 id=final-architecture>Final Architecture<a hidden class=anchor aria-hidden=true href=#final-architecture>#</a></h1><p><img loading=lazy src=/posts/dance-with-burrow/msk-monitoring-full.png></p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li><a href=https://github.com/linkedin/Burrow>Burrow Official Docs</a></li><li><a href=https://prometheus.io/docs/>Prometheus Documentation</a></li><li><a href=https://bcho.tistory.com/1375>Thanos for Prometheus Scaling</a></li><li><a href=https://oliveyoung.tech/2023-10-04/oliveyoung-b2b-msk-connect-introduction/>Operating AWS MSK Connect Effectively</a></li><li><a href=https://techblog.gccompany.co.kr/aws-msk-part3-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81%EC%9D%84-%EA%B5%AC%EC%B6%95%ED%95%B4%EB%B3%BC%EA%B9%8C%EC%9A%94-fe9a7109f4d>MSK Monitoring at Yanolja</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/en/tags/burrow/>Burrow</a></li><li><a href=https://dingyu.dev/en/tags/monitoring/>Monitoring</a></li><li><a href=https://dingyu.dev/en/tags/prometheus/>Prometheus</a></li><li><a href=https://dingyu.dev/en/tags/thanos/>Thanos</a></li><li><a href=https://dingyu.dev/en/tags/lag/>Lag</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/en/posts/local-sasl-kafka/><span class=title>« Prev</span><br><span>[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)</span>
</a><a class=next href=https://dingyu.dev/en/posts/schema-registry/><span class=title>Next »</span><br><span>[EDA] Schema Registry</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
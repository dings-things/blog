<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[DB] Redlock and Lease in Distributed Systems | Ding's Coding Forge</title>
<meta name=keywords content="redis,distributed,lock,lease,Fault tolerance,Correctness,Availability"><meta name=description content="A deep dive into Redlock and Lease mechanisms for managing distributed locks and ownership safely in asynchronous environments."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/distributed-locking/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/distributed-locking/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/distributed-locking/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/distributed-locking/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[DB] Redlock and Lease in Distributed Systems"><meta property="og:description" content="A deep dive into Redlock and Lease mechanisms for managing distributed locks and ownership safely in asynchronous environments."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-29T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-29T00:00:00+00:00"><meta property="article:tag" content="Redis"><meta property="article:tag" content="Distributed"><meta property="article:tag" content="Lock"><meta property="article:tag" content="Lease"><meta property="article:tag" content="Fault Tolerance"><meta property="article:tag" content="Correctness"><meta property="og:image" content="https://dingyu.dev/en/posts/distributed-locking/img/redis.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/distributed-locking/img/redis.png"><meta name=twitter:title content="[DB] Redlock and Lease in Distributed Systems"><meta name=twitter:description content="A deep dive into Redlock and Lease mechanisms for managing distributed locks and ownership safely in asynchronous environments."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[DB] Redlock and Lease in Distributed Systems","item":"https://dingyu.dev/en/posts/distributed-locking/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[DB] Redlock and Lease in Distributed Systems","name":"[DB] Redlock and Lease in Distributed Systems","description":"A deep dive into Redlock and Lease mechanisms for managing distributed locks and ownership safely in asynchronous environments.","keywords":["redis","distributed","lock","lease","Fault tolerance","Correctness","Availability"],"articleBody":"Background One day, a colleague introduced a session about Redlock in a study group I participate in.\nIt was such great content that I wanted to dig deeper with my own understanding.\nIt would be helpful to review Redlock Algorithm beforehand.\nLock for what? Locks are mainly used to ensure efficiency and correctness.\nEfficiency Prevent redundant work from being executed unnecessarily.\nex. N nodes performing the same heavy task (taking 10 minutes) simultaneously, leading to cost/time waste. Correctness Enable consistent and accurate data processing on shared resources across concurrent processes.\nex. N nodes processing a user’s withdrawal logic simultaneously, causing the user’s account to be charged N times. According to Martin Kleppmann, if you’re considering using Redis Lock for efficiency, it is recommended not to use Redlock.\nItem Single Redis Lock Redis Redlock Algorithm Lock Target Single Redis instance 5 independent Redis instances Lock Creation Method SET key value NX PX Attempt SET key value NX PX on all 5 nodes Success Condition Successful lock on one Redis Successful lock on majority (3 out of 5) nodes Failure Handling Lock information lost if Redis fails Majority lock remains safe even if some nodes fail Split Brain Handling Impossible Partially possible (not perfect) Consistency Weak consistency (single instance) Strengthened consistency during lock acquisition (multi-instance) Complexity Simple (easy to implement) Complex (requires handling lock acquisition time, clock drift) Fault Tolerance Low Relatively higher Performance Fast (single node access) May be slower (communication with 5 nodes) Main Use Case Small systems, single-server environments Global distributed systems, high-availability lock systems If the Redis node crashes unexpectedly\nTimeout occurs while trying to acquire the lock → application response delay or business logic execution failure\nIncomplete Lock Using a single Redis node cannot guarantee high availability and stability during failure scenarios.\nFail case 1: Lock release due to GC Stop-the-World pause Duration of STW is unpredictable. Even Concurrent GC cannot avoid STW. Fail case 2: After acquiring lock, external port operations (API, DB, HDFS…) experience packet loss After acquiring lock, delays during IO operations → TTL (lease) expiration → another thread may acquire the lock and perform the same operation. Delays caused by packet loss in external network operations → TTL (lease) expiration … SPoF Solution: Master - Slave Structure During failover, TTL expiration may lead to unlock, causing data corruption. Stability Solution: Safe Lock with Fencing Similar to first commit wins in MVCC, transaction handling at the storage level is based on version (token).\nclient 1 successfully acquires the lock (with token33) but encounters delay during storage write (GC, network delay, etc.) client 1’s lock lease expires. client 2 acquires the lock (with token34) and completes the write operation before client 1 finishes. client 1 attempts storage write → storage rejects token33 because it’s older than token34 (transaction fail). The biggest problem is: who generates the fencing token? In a distributed environment, implementing a counter requires another leader election… (an infinite loop)\nRedlock Operation Flow Record the current time in milliseconds. Try to acquire the lock on all N Redis instances sequentially with the same key and a random value. Set a short timeout for each attempt so that if a node is down, move to the next instance immediately. Calculate the time taken to acquire locks, and if locks are successfully acquired on the majority of instances and the time taken is less than the lock’s validity time, the lock is considered acquired. If the lock is acquired, set the new validity time as (initial validity − elapsed time). If the lock is not acquired, or if the remaining validity time is negative (exceeded during acquisition), release the locks from all instances. Bad Timing Issue Category Description General Distributed System Assumes “cannot trust time” → ensures safety unconditionally, only liveness depends on timing Redlock Relies on time (clock accuracy, network delay) to guarantee lock safety Problem If clocks jump forward/backward (GC, NTP, network delay), lock expiration calculations may fail and lock can be broken Result Not just liveness degradation — safety violations (e.g., data corruption, duplicate execution) can occur Scenario Description First (Clock Jump) Redis C node’s clock jumps forward, causing early TTL expiration. Client 1 thinks it still holds the lock, but Client 2 acquires it again, leading both to believe they own the lock. Second (GC Pause) Client 1 sends lock requests but pauses (GC), during which locks expire. Client 2 acquires new locks, while Client 1 later processes stale success responses. Synchrony assumptions of Redlock Condition Description Bounded Network Delay Packets must arrive within a guaranteed maximum delay Bounded Process Pause GC or system pauses must stay within a limited time Bounded Clock Drift Clock drift must be small; NTP synchronization must be reliable ➔ That is, all delays, pauses, and clock drifts must be much smaller than the lock’s TTL (time-to-live) for Redlock to function correctly.\nIs it realistic to expect such conditions? Remember GitHub’s 90-second packet delay.\nUltimately… Redlock is an algorithm that relies on time, and due to clock jumps, GC STW, and network packet loss, it cannot guarantee correctness.\nSince Redis was never designed for “consensus” but rather as a key-value store, for truly reliable locks, it is better to use solutions like Zookeeper or Raft instead of Redlock.\n","wordCount":"874","inLanguage":"en","image":"https://dingyu.dev/en/posts/distributed-locking/img/redis.png","datePublished":"2025-04-29T00:00:00Z","dateModified":"2025-04-29T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/distributed-locking/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[DB] Redlock and Lease in Distributed Systems</h1><div class=post-description>A deep dive into Redlock and Lease mechanisms for managing distributed locks and ownership safely in asynchronous environments.</div><div class=post-meta><span title='2025-04-29 00:00:00 +0000 UTC'>April 29, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;874 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/distributed-locking/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/distributed-locking/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/redis.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#background aria-label=Background>Background</a><ul><li><a href=#lock-for-what aria-label="Lock for what?">Lock for what?</a><ul><li><a href=#efficiency aria-label=Efficiency>Efficiency</a></li><li><a href=#correctness aria-label=Correctness>Correctness</a></li></ul></li><li><a href=#incomplete-lock aria-label="Incomplete Lock">Incomplete Lock</a><ul><li><a href=#spof-solution-master---slave-structure aria-label="SPoF Solution: Master - Slave Structure">SPoF Solution: Master - Slave Structure</a></li><li><a href=#stability-solution-safe-lock-with-fencing aria-label="Stability Solution: Safe Lock with Fencing">Stability Solution: Safe Lock with Fencing</a></li></ul></li><li><a href=#redlock aria-label=Redlock>Redlock</a><ul><li><a href=#operation-flow aria-label="Operation Flow">Operation Flow</a></li><li><a href=#bad-timing-issue aria-label="Bad Timing Issue">Bad Timing Issue</a></li><li><a href=#synchrony-assumptions-of-redlock aria-label="Synchrony assumptions of Redlock">Synchrony assumptions of Redlock</a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h1><p>One day, a colleague introduced a session about Redlock in a study group I participate in.</p><p>It was such great content that I wanted to dig deeper with my own understanding.</p><blockquote><p>It would be helpful to review <a href=https://chaewonkong.github.io/posts/2025-03-13-dist-lock-with-redis/>Redlock Algorithm</a> beforehand.</p></blockquote><h2 id=lock-for-what>Lock for what?<a hidden class=anchor aria-hidden=true href=#lock-for-what>#</a></h2><p>Locks are mainly used to ensure <code>efficiency</code> and <code>correctness</code>.</p><h3 id=efficiency>Efficiency<a hidden class=anchor aria-hidden=true href=#efficiency>#</a></h3><p>Prevent redundant work from being executed unnecessarily.</p><ul><li>ex. N nodes performing the same heavy task (taking 10 minutes) simultaneously, leading to cost/time waste.</li></ul><h3 id=correctness>Correctness<a hidden class=anchor aria-hidden=true href=#correctness>#</a></h3><p>Enable consistent and accurate data processing on shared resources across concurrent processes.</p><ul><li>ex. N nodes processing a user&rsquo;s withdrawal logic simultaneously, causing the user&rsquo;s account to be charged N times.</li></ul><p>According to <a href=https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html>Martin Kleppmann</a>, if you&rsquo;re considering using Redis Lock for efficiency, it is recommended <strong>not to use Redlock</strong>.</p><p><img loading=lazy src=/posts/distributed-locking/redilock.png></p><table><thead><tr><th style=text-align:left>Item</th><th style=text-align:left>Single Redis Lock</th><th style=text-align:left>Redis Redlock Algorithm</th></tr></thead><tbody><tr><td style=text-align:left>Lock Target</td><td style=text-align:left>Single Redis instance</td><td style=text-align:left>5 independent Redis instances</td></tr><tr><td style=text-align:left>Lock Creation Method</td><td style=text-align:left><code>SET key value NX PX &lt;TTL></code></td><td style=text-align:left>Attempt <code>SET key value NX PX &lt;TTL></code> on all 5 nodes</td></tr><tr><td style=text-align:left>Success Condition</td><td style=text-align:left>Successful lock on one Redis</td><td style=text-align:left>Successful lock on majority (3 out of 5) nodes</td></tr><tr><td style=text-align:left>Failure Handling</td><td style=text-align:left>Lock information lost if Redis fails</td><td style=text-align:left>Majority lock remains safe even if some nodes fail</td></tr><tr><td style=text-align:left>Split Brain Handling</td><td style=text-align:left>Impossible</td><td style=text-align:left>Partially possible (not perfect)</td></tr><tr><td style=text-align:left>Consistency</td><td style=text-align:left>Weak consistency (single instance)</td><td style=text-align:left>Strengthened consistency during lock acquisition (multi-instance)</td></tr><tr><td style=text-align:left>Complexity</td><td style=text-align:left>Simple (easy to implement)</td><td style=text-align:left>Complex (requires handling lock acquisition time, clock drift)</td></tr><tr><td style=text-align:left>Fault Tolerance</td><td style=text-align:left>Low</td><td style=text-align:left>Relatively higher</td></tr><tr><td style=text-align:left>Performance</td><td style=text-align:left>Fast (single node access)</td><td style=text-align:left>May be slower (communication with 5 nodes)</td></tr><tr><td style=text-align:left>Main Use Case</td><td style=text-align:left>Small systems, single-server environments</td><td style=text-align:left>Global distributed systems, high-availability lock systems</td></tr></tbody></table><p><img loading=lazy src=/posts/distributed-locking/spof.png></p><blockquote><p><strong>If the Redis node crashes unexpectedly</strong></p><p>Timeout occurs while trying to acquire the lock → application response delay or business logic execution failure</p></blockquote><h2 id=incomplete-lock>Incomplete Lock<a hidden class=anchor aria-hidden=true href=#incomplete-lock>#</a></h2><p>Using a single Redis node cannot guarantee <code>high availability</code> and <code>stability</code> during failure scenarios.</p><ol><li>Fail case 1: Lock release due to GC Stop-the-World pause<ul><li>Duration of STW is unpredictable.</li><li>Even Concurrent GC cannot avoid STW.</li></ul></li><li>Fail case 2: After acquiring lock, external port operations (API, DB, HDFS&mldr;) experience packet loss<ul><li>After acquiring lock, delays during IO operations → TTL (lease) expiration → another thread may acquire the lock and perform the same operation.</li><li>Delays caused by packet loss in external network operations → TTL (lease) expiration &mldr;</li></ul></li></ol><h3 id=spof-solution-master---slave-structure>SPoF Solution: Master - Slave Structure<a hidden class=anchor aria-hidden=true href=#spof-solution-master---slave-structure>#</a></h3><p>During failover, TTL expiration may lead to unlock, causing data corruption.
<img loading=lazy src=/posts/distributed-locking/image-1.png></p><h3 id=stability-solution-safe-lock-with-fencing>Stability Solution: Safe Lock with Fencing<a hidden class=anchor aria-hidden=true href=#stability-solution-safe-lock-with-fencing>#</a></h3><p>Similar to <code>first commit wins</code> in <strong>MVCC</strong>, transaction handling at the storage level is based on version (token).</p><p><img loading=lazy src=/posts/distributed-locking/image.png></p><ol><li>client 1 successfully acquires the lock (with token33) but encounters delay during storage write (GC, network delay, etc.)</li><li>client 1&rsquo;s lock lease expires.</li><li>client 2 acquires the lock (with token34) and completes the write operation before client 1 finishes.</li><li>client 1 attempts storage write → storage rejects token33 because it&rsquo;s older than token34 (transaction fail).</li></ol><p>The biggest problem is: <strong>who generates the fencing token?</strong> In a distributed environment, implementing a counter requires another leader election&mldr; (an infinite loop)</p><h2 id=redlock>Redlock<a hidden class=anchor aria-hidden=true href=#redlock>#</a></h2><h3 id=operation-flow>Operation Flow<a hidden class=anchor aria-hidden=true href=#operation-flow>#</a></h3><ol><li>Record the current time in milliseconds.</li><li>Try to acquire the lock on all N Redis instances sequentially with the same key and a random value. Set a short timeout for each attempt so that if a node is down, move to the next instance immediately.</li><li>Calculate the time taken to acquire locks, and if locks are successfully acquired on the majority of instances and the time taken is less than the lock&rsquo;s validity time, the lock is considered acquired.</li><li>If the lock is acquired, set the new validity time as (initial validity − elapsed time).</li><li>If the lock is not acquired, or if the remaining validity time is negative (exceeded during acquisition), release the locks from all instances.</li></ol><h3 id=bad-timing-issue>Bad Timing Issue<a hidden class=anchor aria-hidden=true href=#bad-timing-issue>#</a></h3><table><thead><tr><th style=text-align:left>Category</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left>General Distributed System</td><td style=text-align:left>Assumes &ldquo;cannot trust time&rdquo; → ensures safety unconditionally, only liveness depends on timing</td></tr><tr><td style=text-align:left>Redlock</td><td style=text-align:left><strong>Relies on time</strong> (clock accuracy, network delay) to guarantee lock safety</td></tr><tr><td style=text-align:left>Problem</td><td style=text-align:left>If clocks jump forward/backward (GC, NTP, network delay), lock expiration calculations may fail and <strong>lock can be broken</strong></td></tr><tr><td style=text-align:left>Result</td><td style=text-align:left>Not just liveness degradation — <strong>safety violations</strong> (e.g., data corruption, duplicate execution) can occur</td></tr></tbody></table><p><img loading=lazy src=/posts/distributed-locking/image-2.png></p><table><thead><tr><th style=text-align:left>Scenario</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left>First (Clock Jump)</td><td style=text-align:left>Redis C node&rsquo;s clock jumps forward, causing early TTL expiration. Client 1 thinks it still holds the lock, but Client 2 acquires it again, leading both to believe they own the lock.</td></tr><tr><td style=text-align:left>Second (GC Pause)</td><td style=text-align:left>Client 1 sends lock requests but pauses (GC), during which locks expire. Client 2 acquires new locks, while Client 1 later processes stale success responses.</td></tr></tbody></table><h3 id=synchrony-assumptions-of-redlock>Synchrony assumptions of Redlock<a hidden class=anchor aria-hidden=true href=#synchrony-assumptions-of-redlock>#</a></h3><table><thead><tr><th style=text-align:left>Condition</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left>Bounded Network Delay</td><td style=text-align:left>Packets must arrive within a guaranteed maximum delay</td></tr><tr><td style=text-align:left>Bounded Process Pause</td><td style=text-align:left>GC or system pauses must stay within a limited time</td></tr><tr><td style=text-align:left>Bounded Clock Drift</td><td style=text-align:left>Clock drift must be small; NTP synchronization must be reliable</td></tr></tbody></table><p>➔ That is, all delays, pauses, and clock drifts must be much smaller than the lock&rsquo;s TTL (time-to-live) for Redlock to function correctly.</p><p>Is it realistic to expect such conditions? Remember GitHub&rsquo;s <a href=https://github.blog/news-insights/the-library/downtime-last-saturday/>90-second packet delay</a>.</p><p>Ultimately&mldr; Redlock is an algorithm that <strong>relies on time</strong>, and due to clock jumps, GC STW, and network packet loss, it cannot guarantee correctness.</p><p>Since Redis was never designed for &ldquo;consensus&rdquo; but rather as a <strong>key-value store</strong>, for truly reliable locks, it is better to use solutions like <strong>Zookeeper</strong> or <strong>Raft</strong> instead of Redlock.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/redis/>Redis</a></li><li><a href=https://dingyu.dev/en/tags/distributed/>Distributed</a></li><li><a href=https://dingyu.dev/en/tags/lock/>Lock</a></li><li><a href=https://dingyu.dev/en/tags/lease/>Lease</a></li><li><a href=https://dingyu.dev/en/tags/fault-tolerance/>Fault Tolerance</a></li><li><a href=https://dingyu.dev/en/tags/correctness/>Correctness</a></li><li><a href=https://dingyu.dev/en/tags/availability/>Availability</a></li></ul><nav class=paginav><a class=next href=https://dingyu.dev/en/posts/local-sasl-kafka/><span class=title>Next »</span><br><span>[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
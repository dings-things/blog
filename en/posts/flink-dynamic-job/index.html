<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Flink Dynamic Job Case Study | Ding's Coding Forge</title>
<meta name=keywords content="kafka,flink,apache,fds,dynamic job"><meta name=description content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/flink-dynamic-job/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/flink-dynamic-job/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/flink-dynamic-job/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/flink-dynamic-job/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Flink Dynamic Job Case Study"><meta property="og:description" content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-06T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Flink"><meta property="article:tag" content="Apache"><meta property="article:tag" content="Fds"><meta property="article:tag" content="Dynamic Job"><meta property="og:image" content="https://dingyu.dev/en/posts/flink-dynamic-job/img/flink.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/flink-dynamic-job/img/flink.png"><meta name=twitter:title content="[EDA] Flink Dynamic Job Case Study"><meta name=twitter:description content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Flink Dynamic Job Case Study","item":"https://dingyu.dev/en/posts/flink-dynamic-job/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Flink Dynamic Job Case Study","name":"[EDA] Flink Dynamic Job Case Study","description":"This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system.","keywords":["kafka","flink","apache","fds","dynamic job"],"articleBody":" REFS Rules Based Stream Processing with Apache Flink’s Broadcast Pattern Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System Build a dynamic rules engine with Amazon Managed Service for Apache Flink Research Background We needed a case study on building a frequency-based detection policy using filtering conditions within a Window Time. Research was necessary on how to handle all policy processing within a single job code. Allocating instances per policy—even when using container virtualization—is resource inefficient. Policies are managed by admins and should not require job redeployment upon updates. Prerequisites Dynamic Partitioning Kafka uses the event key to hash and modulo into partitions.\nIn frameworks like Kafka Streams and Flink, using a non-key field for group by (keyBy) causes reshuffling, which involves cross-network data movement among Task Managers—posing a significant overhead.\nTo solve this, ensure that transactions with the same grouping key are handled by the same subtask.\nExample: Pre-partitioning by target key (e.g., ID or IP) via separate Kafka topics.\nTerminology (Abbreviated explanation of JobManager, TaskManager, SubTask, Broadcast, etc.)\nImplementation Strategy Merge action events with active policy events (via CDC from rule DB) and publish to a topic. If there’s 1 action and N active policies → publish N merged events. Use DynamicKeyFunction to dynamically partition source stream by group-by condition. Handles reshuffling dynamically without job redeployment. Existing keyBy still processed by current TaskSlots. In DynamicEvaluationFunction, evaluate whether each event satisfies a rule → emit restriction event if it does. Broadcast State Broadcast one stream to all parallel subtasks so they can share consistent configuration/rules.\nTypical use case: low-throughput control/config stream broadcasted to high-throughput action stream.\nBroadcast Architecture Source stream: Payment events Broadcast stream: Policy rules (with infinite retention) Merge both → evaluate Dynamic Data Partitioning Create a system that can add/remove rules at runtime without redeploying jobs.\nStatic vs. Dynamic Keys Type Static Key Dynamic Key Definition Pre-defined field Runtime-decided field Flexibility Low High Implementation Simple Complex (rule parsing required) Performance Optimized Slight overhead Example: If rules are grouped by id, all relevant events will go to the same subtask, even if the logic per rule differs.\nPolicies can share subtasks if their groupingKey is the same.\nRule Broadcasting Use a broadcast source (e.g., from a rule DB CDC topic) to continuously update the active rules.\nEach time a rule is added/modified, it is inserted into the broadcast state.\nIf rule.disabled = true, it is removed.\nCustom Window Processing Flink offers multiple window types: Tumbling, Sliding, Session.\nBut… each has limitations for fraud detection.\nTumbling: May miss events at window boundaries. Sliding: Has inherent delay and overlapping evaluations. → Solution: Implement Custom Windowing using state and timestamps.\nEvents stored as:\nMapState\u0026lt;Long, Set\u0026lt;PaymentEvent\u0026gt;\u0026gt; windowState; Since the state backend is a key-value store, it doesn’t support list types directly. This means we need to iterate over all timestamps in the map to find valid entries… More research is needed here, but since we’re only iterating timestamps (not full events), memory impact may be minimal — though CPU usage could be a concern depending on loop cost.\nConsiderations on Event Retention (TTL) How should we determine the retention period, i.e., the Time-To-Live (TTL) for each event?\nIn DynamicEvaluationFunction(), it is possible to receive payment events with the same key scope but evaluate them under different rules with different time windows.\nTherefore, at the time a rule is consumed from the Rule Stream (Broadcast Stream), we must update and store the longest rule duration for that key.\nExample: UpdateWidestWindow @Override public void processBroadcastElement(Rule rule, Context ctx, Collector\u0026lt;Alert\u0026gt; out) { ... updateWidestWindowRule(rule, broadcastState); } private void updateWidestWindowRule(Rule rule, BroadcastState\u0026lt;Integer, Rule\u0026gt; broadcastState) { Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY); if (widestWindowRule == null) { broadcastState.put(WIDEST_RULE_KEY, rule); return; } if (widestWindowRule.getWindowMillis() \u0026lt; rule.getWindowMillis()) { broadcastState.put(WIDEST_RULE_KEY, rule); } } In summary, Dynamic Evaluation uses the rule with the longest duration to determine the TTL for the event.\nSince the state backend is a key-value store, it doesn’t support list types directly.\nThis means we need to iterate over all timestamps in the map to find valid entries…\nMore research is needed here, but since we’re only iterating timestamps (not full events), memory impact may be minimal — though CPU usage could be a concern depending on loop cost.\n","wordCount":"703","inLanguage":"en","image":"https://dingyu.dev/en/posts/flink-dynamic-job/img/flink.png","datePublished":"2024-12-06T00:00:00Z","dateModified":"2024-12-06T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/flink-dynamic-job/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Flink Dynamic Job Case Study</h1><div class=post-description>This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system.</div><div class=post-meta><span title='2024-12-06 00:00:00 +0000 UTC'>December 6, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;703 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/flink-dynamic-job/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/flink-dynamic-job/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/flink.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><ul><ul><ul><li><a href=#refs aria-label=REFS>REFS</a></li></ul></ul></ul><li><a href=#research-background aria-label="Research Background">Research Background</a></li><li><a href=#prerequisites aria-label=Prerequisites>Prerequisites</a><ul><ul><li><a href=#dynamic-partitioning aria-label="Dynamic Partitioning">Dynamic Partitioning</a></li><li><a href=#terminology aria-label=Terminology>Terminology</a></li></ul></ul></li><li><a href=#implementation-strategy aria-label="Implementation Strategy">Implementation Strategy</a><ul><li><a href=#broadcast-state aria-label="Broadcast State">Broadcast State</a><ul><li><a href=#broadcast-architecture aria-label="Broadcast Architecture">Broadcast Architecture</a></li></ul></li><li><a href=#dynamic-data-partitioning aria-label="Dynamic Data Partitioning">Dynamic Data Partitioning</a><ul><li><a href=#static-vs-dynamic-keys aria-label="Static vs. Dynamic Keys">Static vs. Dynamic Keys</a></li></ul></li><li><a href=#rule-broadcasting aria-label="Rule Broadcasting">Rule Broadcasting</a></li><li><a href=#custom-window-processing aria-label="Custom Window Processing">Custom Window Processing</a><ul><ul><li><a href=#considerations-on-event-retention-ttl aria-label="Considerations on Event Retention (TTL)">Considerations on Event Retention (TTL)</a><ul><li><a href=#example-updatewidestwindow aria-label="Example: UpdateWidestWindow">Example: <code>UpdateWidestWindow</code></a></li></ul></li></ul></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><blockquote><h4 id=refs>REFS<a hidden class=anchor aria-hidden=true href=#refs>#</a></h4></blockquote><ul><li><a href=https://brggs.co.uk/blog/broadcast-state-pattern-rules-based-flink/>Rules Based Stream Processing with Apache Flink&rsquo;s Broadcast Pattern</a></li><li><a href=https://flink.apache.org/2020/01/15/advanced-flink-application-patterns-vol.1-case-study-of-a-fraud-detection-system/>Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></li><li><a href=https://aws.amazon.com/ko/blogs/big-data/build-a-dynamic-rules-engine-with-amazon-managed-service-for-apache-flink/>Build a dynamic rules engine with Amazon Managed Service for Apache Flink</a></li></ul><h1 id=research-background>Research Background<a hidden class=anchor aria-hidden=true href=#research-background>#</a></h1><ul><li>We needed a case study on building a frequency-based detection policy using filtering conditions within a <code>Window Time</code>.</li><li>Research was necessary on how to handle all policy processing within a <strong>single job code</strong>.<ul><li>Allocating instances per policy—even when using container virtualization—is resource inefficient.</li></ul></li><li>Policies are managed by admins and should not require job redeployment upon updates.</li></ul><h1 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>#</a></h1><h3 id=dynamic-partitioning>Dynamic Partitioning<a hidden class=anchor aria-hidden=true href=#dynamic-partitioning>#</a></h3><p>Kafka uses the <strong>event key</strong> to <strong>hash</strong> and <strong>modulo</strong> into partitions.</p><p>In frameworks like Kafka Streams and Flink, using a <strong>non-key field for group by (keyBy)</strong> causes <strong>reshuffling</strong>, which involves cross-network data movement among Task Managers—posing a significant overhead.</p><p>To solve this, ensure that <strong>transactions with the same grouping key</strong> are handled by the <strong>same subtask</strong>.</p><p>Example: Pre-partitioning by target key (e.g., ID or IP) via separate Kafka topics.</p><h3 id=terminology>Terminology<a hidden class=anchor aria-hidden=true href=#terminology>#</a></h3><p>(Abbreviated explanation of JobManager, TaskManager, SubTask, Broadcast, etc.)</p><h1 id=implementation-strategy>Implementation Strategy<a hidden class=anchor aria-hidden=true href=#implementation-strategy>#</a></h1><ol><li>Merge <strong>action events</strong> with <strong>active policy events</strong> (via CDC from rule DB) and publish to a topic.<ul><li>If there’s 1 action and N active policies → publish N merged events.</li></ul></li><li>Use <code>DynamicKeyFunction</code> to dynamically partition source stream by group-by condition.<ul><li>Handles reshuffling <strong>dynamically</strong> without job redeployment.</li><li>Existing keyBy still processed by current TaskSlots.</li></ul></li><li>In <code>DynamicEvaluationFunction</code>, evaluate whether each event satisfies a rule → emit restriction event if it does.</li></ol><h2 id=broadcast-state>Broadcast State<a hidden class=anchor aria-hidden=true href=#broadcast-state>#</a></h2><p>Broadcast one stream to all parallel subtasks so they can share consistent configuration/rules.</p><p>Typical use case: low-throughput control/config stream broadcasted to high-throughput action stream.</p><h3 id=broadcast-architecture>Broadcast Architecture<a hidden class=anchor aria-hidden=true href=#broadcast-architecture>#</a></h3><ul><li>Source stream: Payment events</li><li>Broadcast stream: Policy rules (with infinite retention)</li><li>Merge both → evaluate</li></ul><h2 id=dynamic-data-partitioning>Dynamic Data Partitioning<a hidden class=anchor aria-hidden=true href=#dynamic-data-partitioning>#</a></h2><p>Create a system that can <strong>add/remove rules at runtime</strong> without redeploying jobs.</p><h3 id=static-vs-dynamic-keys>Static vs. Dynamic Keys<a hidden class=anchor aria-hidden=true href=#static-vs-dynamic-keys>#</a></h3><table><thead><tr><th>Type</th><th>Static Key</th><th>Dynamic Key</th></tr></thead><tbody><tr><td>Definition</td><td>Pre-defined field</td><td>Runtime-decided field</td></tr><tr><td>Flexibility</td><td>Low</td><td>High</td></tr><tr><td>Implementation</td><td>Simple</td><td>Complex (rule parsing required)</td></tr><tr><td>Performance</td><td>Optimized</td><td>Slight overhead</td></tr></tbody></table><p>Example: If rules are grouped by <code>id</code>, all relevant events will go to the same subtask, even if the logic per rule differs.</p><p>Policies can share subtasks if their <code>groupingKey</code> is the same.</p><h2 id=rule-broadcasting>Rule Broadcasting<a hidden class=anchor aria-hidden=true href=#rule-broadcasting>#</a></h2><p>Use a broadcast source (e.g., from a rule DB CDC topic) to continuously update the active rules.</p><p>Each time a rule is added/modified, it is inserted into the broadcast state.</p><p>If <code>rule.disabled = true</code>, it is removed.</p><h2 id=custom-window-processing>Custom Window Processing<a hidden class=anchor aria-hidden=true href=#custom-window-processing>#</a></h2><p>Flink offers multiple window types: Tumbling, Sliding, Session.</p><p>But&mldr; <strong>each has limitations</strong> for fraud detection.</p><ul><li>Tumbling: May miss events at window boundaries.</li><li>Sliding: Has inherent delay and overlapping evaluations.</li></ul><p>→ Solution: Implement <strong>Custom Windowing</strong> using state and timestamps.</p><p>Events stored as:</p><pre tabindex=0><code class=language-java>MapState&amp;lt;Long, Set&amp;lt;PaymentEvent&amp;gt;&amp;gt; windowState;</code></pre><blockquote><p>Since the state backend is a key-value store, it doesn&rsquo;t support list types directly.
This means we need to iterate over all timestamps in the map to find valid entries&mldr;
More research is needed here, but since we’re only iterating timestamps (not full events), memory impact may be minimal — though CPU usage could be a concern depending on loop cost.</p></blockquote><hr><h4 id=considerations-on-event-retention-ttl>Considerations on Event Retention (TTL)<a hidden class=anchor aria-hidden=true href=#considerations-on-event-retention-ttl>#</a></h4><p><img loading=lazy src=/posts/flink-dynamic-job/image-12.png></p><p>How should we determine the retention period, i.e., the <strong>Time-To-Live (TTL)</strong> for each event?</p><p>In <code>DynamicEvaluationFunction()</code>, it is possible to receive payment events with the same key scope but evaluate them under <strong>different rules</strong> with <strong>different time windows</strong>.</p><p>Therefore, at the time a rule is consumed from the <code>Rule Stream (Broadcast Stream)</code>, we must <strong>update and store the longest rule duration</strong> for that key.</p><h5 id=example-updatewidestwindow>Example: <code>UpdateWidestWindow</code><a hidden class=anchor aria-hidden=true href=#example-updatewidestwindow>#</a></h5><pre tabindex=0><code class=language-java>@Override
public void processBroadcastElement(Rule rule, Context ctx, Collector&amp;lt;Alert&amp;gt; out) {
  ...
  updateWidestWindowRule(rule, broadcastState);
}

private void updateWidestWindowRule(Rule rule, BroadcastState&amp;lt;Integer, Rule&amp;gt; broadcastState) {
  Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY);
  if (widestWindowRule == null) {
    broadcastState.put(WIDEST_RULE_KEY, rule);
    return;
  }
  if (widestWindowRule.getWindowMillis() &amp;lt; rule.getWindowMillis()) {
    broadcastState.put(WIDEST_RULE_KEY, rule);
  }
}</code></pre><p>In summary, <strong>Dynamic Evaluation</strong> uses the rule with the longest duration to determine the TTL for the event.</p><blockquote><p>Since the state backend is a key-value store, it doesn&rsquo;t support list types directly.</p><p>This means we need to iterate over all timestamps in the map to find valid entries…</p><p>More research is needed here, but since we’re only iterating timestamps (not full events), memory impact may be minimal — though CPU usage could be a concern depending on loop cost.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/en/tags/flink/>Flink</a></li><li><a href=https://dingyu.dev/en/tags/apache/>Apache</a></li><li><a href=https://dingyu.dev/en/tags/fds/>Fds</a></li><li><a href=https://dingyu.dev/en/tags/dynamic-job/>Dynamic Job</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/en/posts/es-to-loki/><span class=title>« Prev</span><br><span>[LGTM] Elasticsearch to Loki Migration Story</span>
</a><a class=next href=https://dingyu.dev/en/posts/gopher-con-2024-minimalistic-go/><span class=title>Next »</span><br><span>[Go] Gophercon 2024 - Building Minimalistic Backend Microservice in Go</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
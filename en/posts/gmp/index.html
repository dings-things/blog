<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[Go] Is It Okay to Run 100 Million Goroutines? | Ding's Coding Forge</title>
<meta name=keywords content="go,async,channel,gmp,thread,goroutine,pprof"><meta name=description content="Based on Go's runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/gmp/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/gmp/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/gmp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/gmp/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[Go] Is It Okay to Run 100 Million Goroutines?"><meta property="og:description" content="Based on Go's runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-20T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-20T00:00:00+00:00"><meta property="article:tag" content="Go"><meta property="article:tag" content="Async"><meta property="article:tag" content="Channel"><meta property="article:tag" content="Gmp"><meta property="article:tag" content="Thread"><meta property="article:tag" content="Goroutine"><meta property="og:image" content="https://dingyu.dev/en/posts/gmp/img/go-thumbnail.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/gmp/img/go-thumbnail.png"><meta name=twitter:title content="[Go] Is It Okay to Run 100 Million Goroutines?"><meta name=twitter:description content="Based on Go's runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[Go] Is It Okay to Run 100 Million Goroutines?","item":"https://dingyu.dev/en/posts/gmp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[Go] Is It Okay to Run 100 Million Goroutines?","name":"[Go] Is It Okay to Run 100 Million Goroutines?","description":"Based on Go's runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state.","keywords":["go","async","channel","gmp","thread","goroutine","pprof"],"articleBody":"This article is about testing… What happens to the server if tens of millions of API requests per second are received, and these APIs communicate with an external API that responds in 10 seconds?\n⨳ Assume that the TCP connection timeout is not configured separately.\nWhat is a Goroutine? Goroutines are often called lightweight threads… So is it just a thread with less memory?\nAdvantages of Goroutines Low Context Switching Cost As hardware has advanced, the concepts of *multithreading and *multitasking have emerged to utilize it efficiently.\nMultithreading: Multiple threads running within a single process (In a single-core environment, multithreading might be multitasking)\nMultitasking: Simultaneously executing multiple tasks (appearing so)\nOther Languages (C/C++/Java) Go Language The Go runtime performs lightweight context switching by using its own G (Goroutine), M (OS Thread), and P (Scheduler Context), without switching the kernel-level TCB (Task Control Block) directly.\nCreation and Destruction Cost Creating and destroying an OS Thread after use requires high cost. To avoid paying this cost every time, thread pools are often used.\nWhat about in Go?\nThe M in Go’s GMP model corresponds to the OS Thread. While a goroutine runs through the connection of a P(processor) and an M, the M can be created or destroyed as needed.\n※ G refers to a user-level thread, and M refers to an OS thread. These are mapped in an m:n relationship.\nHowever, this is optimized by the Go runtime scheduler, allowing it to be managed with much lower cost compared to general programming languages.\nLow Memory Consumption When created as threads, they require around 1MB of stack including memory protection between threads.\nIn contrast, a goroutine only needs 2KB of stack initially, resulting in significant lightweighting. (Of course, additional memory allocation may be required depending on the code executed by the goroutine—this applies to other languages as well.)\nHere’s a numerical comparison:\nLanguage Basic Execution Unit Default Stack Size Estimated Total Memory Use C/C++ pthread 8MB About 8MB or more Java java.lang.Thread 1MB About 1MB or more Go goroutine (G) 2KB (initial) Several KB GMP: Go Scheduler Architecture The Go runtime efficiently assigns, schedules, and manages goroutines using a system known as GMP:\nG: Goroutine (logical execution unit) M: Machine (an OS thread) P: Processor (scheduling context) This architecture allows Go to perform lightweight context switching and schedule massive numbers of goroutines across a limited set of OS threads.\nComponent Meaning Role Key Information G (Goroutine) Logical execution unit Code that needs to be executed Stores stack, instruction pointer, goroutine status, etc. M (Machine) OS thread Executes G Binds to P, executes G, and may handle syscalls P (Processor) Scheduling context Schedules G onto M Owns a Local Run Queue (LRQ), can access GRQ and perform work stealing LRQ (Local Run Queue) Per-P queue Stores Gs owned by a P Lower contention, faster scheduling GRQ (Global Run Queue) Shared queue Backup storage of runnable Gs Used when LRQs are empty or overflown Each P can be thought of as a “logical core” limited by GOMAXPROCS. It binds to an M (OS thread) and pulls Gs from its LRQ first, falling back to GRQ if needed.\nThe system is designed to:\nReduce kernel-level context switching Avoid excessive OS threads Enable highly scalable I/O concurrency P (Processor) P defaults to GOMAXPROCS = number of CPU cores P is assigned to one M, and each P owns its own Local Run Queue P holds context info of G It calls findRunnable() to decide which G to run next [runtime/proc.go]\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) { mp := getg().m pp := mp.p.ptr() // local runq if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, false } // global runq if sched.runqsize != 0 { lock(\u0026sched.lock) gp := globrunqget(pp, 0) unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } // Poll network. if netpollinited() \u0026\u0026 netpollAnyWaiters() \u0026\u0026 sched.lastpoll.Load() != 0 { if list, delta := netpoll(0); !list.empty() { gp := list.pop() injectglist(\u0026list) netpollAdjustWaiters(delta) casgstatus(gp, _Gwaiting, _Grunnable) return gp, false, false } } // Spinning Ms: steal work from other Ps. if mp.spinning || 2*sched.nmspinning.Load() \u003c gomaxprocs-sched.npidle.Load() { if !mp.spinning { mp.becomeSpinning() } gp, inheritTime, _, _, _ := stealWork(nanotime()) if gp != nil { return gp, inheritTime, false } } // fallback: no G found return nil, false, false } Order Source Description Use case ① Local Run Queue (LRQ) Unique queue per P Fastest and lowest cost → first ② Global Run Queue (GRQ) Shared queue among all Ps Used when LRQ is empty ③ Network Poller (Netpoll) Gs woken by epoll/kqueue/I/O events Revives Gs after network I/O ④ Work Stealing (other P’s LRQ) Steal Gs from another P’s LRQ Used when own LRQ \u0026 GRQ are empty Then naturally, this question arises…\nAfter a blocking operation completes, how does the G return to P? This is the process of goroutine switching within a single P (processor).\nG1 is a goroutine performing a syscall (e.g., HTTPRequest)\nStep Description ① G1 enters a syscall (net.Read() is called) ② M1 blocks on the syscall → calls entersyscall(), P1 is detached ③ P1 is handed over to M2 → M2 is either idle or created via newm() ④ M2 picks and executes G2 from P1’s run queue ⑤ The OS detects syscall completion via epoll, kqueue, or IOCP ⑥ netpoller marks G1 as runnable → G1.status = _Grunnable ⑦ Scheduler later selects and resumes G1 through schedule() What if no runnable Goroutine is found in findRunnable()? The current M (OS thread) has no G to run stopm() is called → the current M is parked The P held by M is returned via releasep() The returned P is placed into the idle P queue Ps created up to the number of GOMAXPROCS do not disappear and stay in the idle state When a new runnable G appears, it reuses an idle P to resume execution M may be created again or an idle M reused if needed M (Machine) M receives a G and actually executes it as an OS Thread The default value for maxcount is 10000 What happens to M1 when its G (running a blocking operation) enters a syscall?\n[runtime/proc.go]\nfunc exitsyscall() { gp := getg() // Validate syscall stack frame if sys.GetCallerSP() \u003e gp.syscallsp { throw(\"exitsyscall: syscall frame is no longer valid\") } gp.waitsince = 0 oldp := gp.m.oldp.ptr() gp.m.oldp = 0 // Fast path: try to reacquire P and resume execution // if P is IDLE, return true and resume running goroutine if exitsyscallfast(oldp) { ... casgstatus(gp, _Gsyscall, _Grunning) // mark G as running return } // Slow path: failed to reacquire P // Call scheduler (park M and let scheduler run G later) mcall(exitsyscall0) } Condition Handling P can be reacquired G1 resumes immediately (execute(g)) P cannot be reacquired G1 is enqueued as runnable, M1 is stopped (stopm()) Too many idle Ms M1 may be completely terminated Lack of idle Ms M1 may be reused (newm() is avoided if possible) Multithreading with M (OS Thread) in other languages One OS thread is created per request, and that thread performs epoll_wait/syscall N worker threads are created, each handling epoll_wait or read Cons To handle 1,000 concurrent requests, up to 1,000 threads are required Each M (epoll_wait) blocks in syscall → leads to context switches *Cache misses, kernel entry cost, and scheduling overhead increase sharply Cache miss: After a context switch, if the required data is no longer in the CPU cache, it must be reloaded from memory (which is slower)\nNetpoller M The Netpoller M is a dedicated OS thread (M) maintained by the Go runtime, connected to the kernel’s I/O readiness monitoring systems like epoll, kqueue, etc.\nWhen goroutines use non-blocking I/O (fd), this M exclusively monitors the readable/writable status of those fds A single M can monitor thousands of fds, efficiently handling a large number of I/O goroutines with minimal resources Flow of two goroutines that include syscalls and the Netpoller M\nWhy can’t M make a syscall directly? Example: Assume G1 calls conn.Read() on a TCP socket\nIf the peer suddenly disconnects or NAT timeout occurs but the kernel does not send an EOF signal?\nThe read(fd) syscall never returns (remains in a blocked state) The M executing G1 becomes blocked on the syscall The P owned by that M is also released, reducing overall concurrency Because of this, Go checks the fd’s readiness using epoll before calling read() to avoid indefinite blocking.\nWhy does the Netpoller M exclusively handle epoll? Example: 1,000 Ms each calling epoll_wait(fd)\nAll 1,000 Ms independently call epoll_wait() epoll_wait is also a syscall, which incurs kernel-to-user space transition overhead We must also consider how frequently to perform epoll → adds polling interval overhead G (Goroutine) Goroutine Scheduling Let’s look at the execution flow of a goroutine.\ngo dosomething() is called to spawn a new goroutine.\nCurrent status\nLRQ is full A new goroutine is spawned A new goroutine (G0) checks if there’s space in the left P’s LRQ The current P’s LRQ is full (in practice, LRQ size = 256)\nHalf of the current LRQ is moved to GRQ (e.g., G2 → GRQ) G0 is inserted into the LRQ as P is now available\nG1 runs and G0 is set as runnext Since LRQ is empty, a G is taken from GRQ (fetches GRQ length / GOMAXPROCS + 1)\nG0 runs on M and sends a request to the socket G0 registers readiness using epoll_ctl(..., EPOLLIN)\nTo avoid blocking, it detaches from the current P Netpoller M checks readiness using epoll_wait\nM returns to IDLE state, and G0 waits via Gopark (later deleted or reattached to a P) Netpoller M detects readiness of G0’s fd\nNetpoller M marks G0 as Goready after detecting readiness P fails to find a G in LRQ and GRQ\nP directly fetches the ready G from netpoll and executes it Caveats GRQ Starvation Only LRQs may be checked repeatedly, causing GRQ starvation schedTick variable ensures GRQ is checked every 61 ticks Why 61? It’s a prime number experimentally proven to perform well. Like hash map sizing, prime numbers help avoid distribution conflicts with application patterns [runtime/proc.go]\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) { mp := getg().m pp := mp.p.ptr() // Check the global runnable queue once in a while to ensure fairness if pp.schedtick%61 == 0 \u0026\u0026 !sched.runq.empty() { lock(\u0026sched.lock) gp := globrunqget() unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } // local runq if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, false } ... } Time slice based preemption To prevent one goroutine from monopolizing a processor, Go defines a default 10ms time slice. After this time, the running G is preempted and returned to GRQ.\n[runtime/proc.go]\nfunc sysmon() { ... for { ... lock(\u0026sched.sysmonlock) now = nanotime() ... // retake P's blocked in syscalls // and preempt long running G's if retake(now) != 0 { idle = 0 } else { idle++ } ... unlock(\u0026sched.sysmonlock) } } What happens when handling tens of millions of network I/O? Go’s goroutines can perform efficiently even under large-scale network I/O thanks to lightweight context switching, small memory usage, and epoll-based polling architecture.\nHowever, if the external API response is slow (e.g., 10 seconds), and tens of millions of requests per second flood in, the following bottlenecks and risks arise:\nPotential Error Cases 1. Explosive increase in goroutine count If every request waits \u003e10s due to external API, goroutines pile up in waiting state 10M req/s × 10s = up to 100M concurrent goroutines At 2KB per goroutine, memory usage = 100M × 2KB ≒ 200GB+ System memory gets exhausted → OOM 2. File descriptor (fd) limit Each TCP connection consumes an fd Linux ulimit -n typically limits open files to thousands or tens of thousands New requests eventually fail due to fd exhaustion Reference – Default FD Limits by OS Operating System Soft Limit (Default) Hard Limit Notes Ubuntu (20.04~) 1024 1048576 Can be adjusted in /etc/security/limits.conf Debian 1024 4096 May vary depending on the system CentOS 7 1024 4096 or 1024 Can be configured via systemd or limits.conf macOS 256 10240 As of Ventura: soft=256, hard=10240 (varies per app/terminal) Test: Is running 100M goroutines okay? func init() { http.HandleFunc(\"/slow\", func(w http.ResponseWriter, r *http.Request) { time.Sleep(10 * time.Second) }) go func() { log.Println(\"slow API server start in :18080\") http.ListenAndServe(\":18080\", nil) }() } func main() { // ===== trace start ===== traceFile, err := os.Create(\"trace.out\") if err != nil { log.Fatalf(\"trace file creation failed: %v\", err) } if err := trace.Start(traceFile); err != nil { log.Fatalf(\"trace start failed: %v\", err) } defer func() { trace.Stop() traceFile.Close() }() // ===================== startProfiler() for i := 0; i \u003c 100000000; i++ { go func(i int) { client := \u0026http.Client{} resp, err := client.Get(\"http://localhost:18080/slow\") if err != nil { fmt.Printf(\"[%d] Error: %v\", i, err) return } io.Copy(io.Discard, resp.Body) resp.Body.Close() }(i) if i%100000 == 0 { fmt.Printf( \"Current Request Count: %d, Goroutine Count: %d\", i, runtime.NumGoroutine(), ) } } select {} } heap profile net/http.(*Transport).getConn: Fails to reuse connections → FD surge → heap grows runtime.malg: Goroutines wait → their stacks remain → heap inflates cpu profile runtime.cgocall: Bursts of HTTP syscalls runtime.(*timers).adjust: Too many timers from time.Sleep increase min-heap ops Reason for Connection Timeout\nAfter the default HTTP client’s MaxConnectionPool is fully consumed, a new connection must be created, which involves the 3-way TCP handshake process.\nClient Request Server Handling -------------- ---------------------------- SYN ───────────▶ [Waiting in the SYN queue] (Before `accept()` is called) `accept()` is called → connection accepted ⇩ SYN-ACK ◀────────── Connection accepted ACK ───────────▶ Connection established (3-way handshake complete) If the server's SYN queue is full, the connection cannot be established and remains blocked, eventually leading to a timeout. Unbounded goroutines waiting = heap bloat = OOM = crash Even with connection pooling:\nclient := \u0026http.Client{ Transport: \u0026http.Transport{ MaxIdleConns: 10000, MaxIdleConnsPerHost: 10000, IdleConnTimeout: 90 * time.Second, DisableKeepAlives: false, }, Timeout: 30 * time.Second, } Still ends in OOM due to: REFS Dmitry Vtukov GopherCon 2021: Madhav Jivrajani - Queues, Fairness, and The Go Scheduler ","wordCount":"2346","inLanguage":"en","image":"https://dingyu.dev/en/posts/gmp/img/go-thumbnail.png","datePublished":"2025-05-20T00:00:00Z","dateModified":"2025-05-20T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/gmp/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[Go] Is It Okay to Run 100 Million Goroutines?</h1><div class=post-description>Based on Go's runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state.</div><div class=post-meta><span title='2025-05-20 00:00:00 +0000 UTC'>May 20, 2025</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2346 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/gmp/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/gmp/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/go-thumbnail.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#what-is-a-goroutine aria-label="What is a Goroutine?">What is a Goroutine?</a><ul><li><a href=#advantages-of-goroutines aria-label="Advantages of Goroutines">Advantages of Goroutines</a><ul><li><a href=#low-context-switching-cost aria-label="Low Context Switching Cost">Low Context Switching Cost</a><ul><li><a href=#other-languages-ccjava aria-label="Other Languages (C/C++/Java)">Other Languages (C/C++/Java)</a></li><li><a href=#go-language aria-label="Go Language">Go Language</a></li></ul></li><li><a href=#creation-and-destruction-cost aria-label="Creation and Destruction Cost">Creation and Destruction Cost</a></li><li><a href=#low-memory-consumption aria-label="Low Memory Consumption">Low Memory Consumption</a></li></ul></li></ul></li><li><a href=#gmp-go-scheduler-architecture aria-label="GMP: Go Scheduler Architecture">GMP: Go Scheduler Architecture</a><ul><li><a href=#p-processor aria-label="P (Processor)">P (Processor)</a><ul><ul><li><a href=#after-a-blocking-operation-completes-how-does-the-g-return-to-p aria-label="After a blocking operation completes, how does the G return to P?">After a blocking operation completes, how does the G return to P?</a></li><li><a href=#what-if-no-runnable-goroutine-is-found-in-findrunnable aria-label="What if no runnable Goroutine is found in findRunnable()?">What if no runnable Goroutine is found in <code>findRunnable()</code>?</a></li></ul></ul></li><li><a href=#m-machine aria-label="M (Machine)">M (Machine)</a><ul><li><a href=#multithreading-with-m-os-thread-in-other-languages aria-label="Multithreading with M (OS Thread) in other languages">Multithreading with M (OS Thread) in other languages</a><ul><li><a href=#cons aria-label=Cons>Cons</a></li></ul></li><li><a href=#netpoller-m aria-label="Netpoller M">Netpoller M</a><ul><li><a href=#why-cant-m-make-a-syscall-directly aria-label="Why can’t M make a syscall directly?">Why can’t M make a syscall directly?</a></li><li><a href=#why-does-the-netpoller-m-exclusively-handle-epoll aria-label="Why does the Netpoller M exclusively handle epoll?">Why does the Netpoller M exclusively handle epoll?</a></li></ul></li></ul></li><li><a href=#g-goroutine aria-label="G (Goroutine)">G (Goroutine)</a><ul><li><a href=#goroutine-scheduling aria-label="Goroutine Scheduling">Goroutine Scheduling</a></li></ul></li><li><a href=#caveats aria-label=Caveats>Caveats</a><ul><li><a href=#grq-starvation aria-label="GRQ Starvation">GRQ Starvation</a></li><li><a href=#time-slice-based-preemption aria-label="Time slice based preemption">Time slice based preemption</a></li></ul></li></ul></li><li><a href=#what-happens-when-handling-tens-of-millions-of-network-io aria-label="What happens when handling tens of millions of network I/O?">What happens when handling tens of millions of network I/O?</a><ul><li><a href=#potential-error-cases aria-label="Potential Error Cases">Potential Error Cases</a><ul><li><a href=#1-explosive-increase-in-goroutine-count aria-label="1. Explosive increase in goroutine count">1. Explosive increase in goroutine count</a></li><li><a href=#2-file-descriptor-fd-limit aria-label="2. File descriptor (fd) limit">2. File descriptor (fd) limit</a><ul><li><a href=#reference--default-fd-limits-by-os aria-label="Reference – Default FD Limits by OS">Reference – Default FD Limits by OS</a></li></ul></li></ul></li><li><a href=#test-is-running-100m-goroutines-okay aria-label="Test: Is running 100M goroutines okay?">Test: Is running 100M goroutines okay?</a><ul><li><a href=#heap-profile aria-label="heap profile">heap profile</a></li><li><a href=#cpu-profile aria-label="cpu profile">cpu profile</a></li></ul></li></ul></li><li><a href=#refs aria-label=REFS>REFS</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>This article is about testing&mldr;
<img loading=lazy src=/posts/gmp/test-scenario.png></p><blockquote><p>What happens to the server if tens of millions of API requests per second are received, and these APIs communicate with an external API that responds in 10 seconds?</p><p>⨳ Assume that the TCP connection timeout is not configured separately.</p></blockquote><h1 id=what-is-a-goroutine>What is a Goroutine?<a hidden class=anchor aria-hidden=true href=#what-is-a-goroutine>#</a></h1><p>Goroutines are often called lightweight threads&mldr; So is it just a thread with less memory?</p><h2 id=advantages-of-goroutines>Advantages of Goroutines<a hidden class=anchor aria-hidden=true href=#advantages-of-goroutines>#</a></h2><h3 id=low-context-switching-cost>Low Context Switching Cost<a hidden class=anchor aria-hidden=true href=#low-context-switching-cost>#</a></h3><p>As hardware has advanced, the concepts of *<em>multithreading</em> and *<em>multitasking</em> have emerged to utilize it efficiently.</p><blockquote><p>Multithreading: Multiple threads running within a single process (In a single-core environment, multithreading might be multitasking)</p><p>Multitasking: Simultaneously executing multiple tasks (appearing so)</p></blockquote><h4 id=other-languages-ccjava>Other Languages (C/C++/Java)<a hidden class=anchor aria-hidden=true href=#other-languages-ccjava>#</a></h4><p><img loading=lazy src=/posts/gmp/image.png></p><h4 id=go-language>Go Language<a hidden class=anchor aria-hidden=true href=#go-language>#</a></h4><p>The Go runtime performs <strong>lightweight context switching</strong> by using its own G (Goroutine), M (OS Thread), and P (Scheduler Context), without switching the kernel-level TCB (Task Control Block) directly.</p><hr><h3 id=creation-and-destruction-cost>Creation and Destruction Cost<a hidden class=anchor aria-hidden=true href=#creation-and-destruction-cost>#</a></h3><p>Creating and destroying an <code>OS Thread</code> after use requires high cost. To avoid paying this cost every time, <strong>thread pools</strong> are often used.</p><p>What about in Go?</p><p>The M in Go’s GMP model corresponds to the <code>OS Thread</code>. While a goroutine runs through the connection of a P(processor) and an M, the M can be created or destroyed as needed.</p><p>※ G refers to a user-level thread, and M refers to an OS thread. These are mapped in an m:n relationship.</p><p>However, this is optimized by the Go runtime scheduler, allowing it to be managed with much lower cost compared to general programming languages.</p><hr><h3 id=low-memory-consumption>Low Memory Consumption<a hidden class=anchor aria-hidden=true href=#low-memory-consumption>#</a></h3><p>When created as threads, they require around <code>1MB</code> of stack including memory protection between threads.</p><p>In contrast, a goroutine only needs <code>2KB</code> of stack initially, resulting in significant lightweighting. (Of course, additional memory allocation may be required depending on the code executed by the goroutine—this applies to other languages as well.)</p><p>Here’s a numerical comparison:</p><table><thead><tr><th>Language</th><th>Basic Execution Unit</th><th>Default Stack Size</th><th>Estimated Total Memory Use</th></tr></thead><tbody><tr><td>C/C++</td><td>pthread</td><td>8MB</td><td>About 8MB or more</td></tr><tr><td>Java</td><td>java.lang.Thread</td><td>1MB</td><td>About 1MB or more</td></tr><tr><td>Go</td><td>goroutine (G)</td><td>2KB (initial)</td><td>Several KB</td></tr></tbody></table><hr><h1 id=gmp-go-scheduler-architecture>GMP: Go Scheduler Architecture<a hidden class=anchor aria-hidden=true href=#gmp-go-scheduler-architecture>#</a></h1><p>The Go runtime efficiently assigns, schedules, and manages goroutines using a system known as GMP:</p><ul><li><strong>G</strong>: Goroutine (logical execution unit)</li><li><strong>M</strong>: Machine (an OS thread)</li><li><strong>P</strong>: Processor (scheduling context)</li></ul><p><img loading=lazy src=/posts/gmp/gmp.png></p><p>This architecture allows Go to perform lightweight context switching and schedule massive numbers of goroutines across a limited set of OS threads.</p><table><thead><tr><th>Component</th><th>Meaning</th><th>Role</th><th>Key Information</th></tr></thead><tbody><tr><td><strong>G (Goroutine)</strong></td><td>Logical execution unit</td><td>Code that needs to be executed</td><td>Stores stack, instruction pointer, goroutine status, etc.</td></tr><tr><td><strong>M (Machine)</strong></td><td>OS thread</td><td>Executes G</td><td>Binds to P, executes G, and may handle syscalls</td></tr><tr><td><strong>P (Processor)</strong></td><td>Scheduling context</td><td>Schedules G onto M</td><td>Owns a Local Run Queue (LRQ), can access GRQ and perform work stealing</td></tr><tr><td><strong>LRQ (Local Run Queue)</strong></td><td>Per-P queue</td><td>Stores Gs owned by a P</td><td>Lower contention, faster scheduling</td></tr><tr><td><strong>GRQ (Global Run Queue)</strong></td><td>Shared queue</td><td>Backup storage of runnable Gs</td><td>Used when LRQs are empty or overflown</td></tr></tbody></table><p>Each P can be thought of as a “logical core” limited by <code>GOMAXPROCS</code>. It binds to an M (OS thread) and pulls Gs from its LRQ first, falling back to GRQ if needed.</p><p>The system is designed to:</p><ul><li>Reduce kernel-level context switching</li><li>Avoid excessive OS threads</li><li>Enable highly scalable I/O concurrency</li></ul><hr><h2 id=p-processor>P (Processor)<a hidden class=anchor aria-hidden=true href=#p-processor>#</a></h2><ul><li>P defaults to <code>GOMAXPROCS</code> = number of CPU cores</li><li>P is assigned to one M, and each P owns its own <code>Local Run Queue</code></li><li>P holds context info of G</li><li>It calls <code>findRunnable()</code> to decide which G to run next</li></ul><p><img loading=lazy src=/posts/gmp/findrunnable.png></p><p>[<a href=https://go.dev/src/runtime/proc.go>runtime/proc.go</a>]</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>findRunnable</span><span class=p>()</span> <span class=p>(</span><span class=nx>gp</span> <span class=o>*</span><span class=nx>g</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=nx>tryWakeP</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>mp</span> <span class=o>:=</span> <span class=nf>getg</span><span class=p>().</span><span class=nx>m</span>
</span></span><span class=line><span class=cl>    <span class=nx>pp</span> <span class=o>:=</span> <span class=nx>mp</span><span class=p>.</span><span class=nx>p</span><span class=p>.</span><span class=nf>ptr</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// local runq</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span> <span class=o>:=</span> <span class=nf>runqget</span><span class=p>(</span><span class=nx>pp</span><span class=p>);</span> <span class=nx>gp</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// global runq</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>sched</span><span class=p>.</span><span class=nx>runqsize</span> <span class=o>!=</span> <span class=mi>0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>lock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>lock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nx>gp</span> <span class=o>:=</span> <span class=nf>globrunqget</span><span class=p>(</span><span class=nx>pp</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>unlock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>lock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>gp</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=kc>false</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Poll network.</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nf>netpollinited</span><span class=p>()</span> <span class=o>&amp;&amp;</span> <span class=nf>netpollAnyWaiters</span><span class=p>()</span> <span class=o>&amp;&amp;</span> <span class=nx>sched</span><span class=p>.</span><span class=nx>lastpoll</span><span class=p>.</span><span class=nf>Load</span><span class=p>()</span> <span class=o>!=</span> <span class=mi>0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>list</span><span class=p>,</span> <span class=nx>delta</span> <span class=o>:=</span> <span class=nf>netpoll</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span> <span class=p>!</span><span class=nx>list</span><span class=p>.</span><span class=nf>empty</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>gp</span> <span class=o>:=</span> <span class=nx>list</span><span class=p>.</span><span class=nf>pop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=nf>injectglist</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nf>netpollAdjustWaiters</span><span class=p>(</span><span class=nx>delta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nf>casgstatus</span><span class=p>(</span><span class=nx>gp</span><span class=p>,</span> <span class=nx>_Gwaiting</span><span class=p>,</span> <span class=nx>_Grunnable</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=kc>false</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Spinning Ms: steal work from other Ps.</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>mp</span><span class=p>.</span><span class=nx>spinning</span> <span class=o>||</span> <span class=mi>2</span><span class=o>*</span><span class=nx>sched</span><span class=p>.</span><span class=nx>nmspinning</span><span class=p>.</span><span class=nf>Load</span><span class=p>()</span> <span class=p>&lt;</span> <span class=nx>gomaxprocs</span><span class=o>-</span><span class=nx>sched</span><span class=p>.</span><span class=nx>npidle</span><span class=p>.</span><span class=nf>Load</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>!</span><span class=nx>mp</span><span class=p>.</span><span class=nx>spinning</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>mp</span><span class=p>.</span><span class=nf>becomeSpinning</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=nx>_</span><span class=p>,</span> <span class=nx>_</span><span class=p>,</span> <span class=nx>_</span> <span class=o>:=</span> <span class=nf>stealWork</span><span class=p>(</span><span class=nf>nanotime</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>gp</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// fallback: no G found</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=kc>false</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><table><thead><tr><th>Order</th><th>Source</th><th>Description</th><th>Use case</th></tr></thead><tbody><tr><td>①</td><td><strong>Local Run Queue (LRQ)</strong></td><td>Unique queue per P</td><td>Fastest and lowest cost → <strong>first</strong></td></tr><tr><td>②</td><td><strong>Global Run Queue (GRQ)</strong></td><td>Shared queue among all Ps</td><td>Used when LRQ is empty</td></tr><tr><td>③</td><td><strong>Network Poller (Netpoll)</strong></td><td>Gs woken by epoll/kqueue/I/O events</td><td>Revives Gs after network I/O</td></tr><tr><td>④</td><td><strong>Work Stealing (other P’s LRQ)</strong></td><td>Steal Gs from another P’s LRQ</td><td>Used when own LRQ & GRQ are empty</td></tr></tbody></table><p>Then naturally, this question arises&mldr;</p><hr><h4 id=after-a-blocking-operation-completes-how-does-the-g-return-to-p>After a blocking operation completes, how does the G return to P?<a hidden class=anchor aria-hidden=true href=#after-a-blocking-operation-completes-how-does-the-g-return-to-p>#</a></h4><p>This is the process of goroutine switching within a single P (processor).</p><p>G1 is a goroutine performing a syscall (e.g., <code>HTTPRequest</code>)</p><p><img loading=lazy src=/posts/gmp/gmp-flow.png></p><table><thead><tr><th>Step</th><th>Description</th></tr></thead><tbody><tr><td>①</td><td><code>G1</code> enters a syscall (<code>net.Read()</code> is called)</td></tr><tr><td>②</td><td><code>M1</code> blocks on the syscall → calls <code>entersyscall()</code>, <code>P1</code> is detached</td></tr><tr><td>③</td><td><code>P1</code> is handed over to <code>M2</code> → <code>M2</code> is either idle or created via <code>newm()</code></td></tr><tr><td>④</td><td><code>M2</code> picks and executes <code>G2</code> from <code>P1</code>’s run queue</td></tr><tr><td>⑤</td><td>The OS detects syscall completion via <code>epoll</code>, <code>kqueue</code>, or IOCP</td></tr><tr><td>⑥</td><td><code>netpoller</code> marks G1 as runnable → <code>G1.status = _Grunnable</code></td></tr><tr><td>⑦</td><td>Scheduler later selects and resumes G1 through <code>schedule()</code></td></tr></tbody></table><hr><h4 id=what-if-no-runnable-goroutine-is-found-in-findrunnable>What if no runnable Goroutine is found in <code>findRunnable()</code>?<a hidden class=anchor aria-hidden=true href=#what-if-no-runnable-goroutine-is-found-in-findrunnable>#</a></h4><ol><li>The current M (OS thread) has no G to run</li><li><code>stopm()</code> is called → the current M is parked</li><li>The P held by M is returned via <code>releasep()</code></li><li>The returned P is placed into the idle P queue</li></ol><ul><li>Ps created up to the number of <code>GOMAXPROCS</code> do not disappear and stay in the idle state</li><li>When a new runnable G appears, it reuses an idle P to resume execution</li><li>M may be created again or an idle M reused if needed</li></ul><hr><h2 id=m-machine>M (Machine)<a hidden class=anchor aria-hidden=true href=#m-machine>#</a></h2><ul><li>M receives a G and actually executes it as an <code>OS Thread</code></li><li>The default value for maxcount is <strong>10000</strong></li></ul><p>What happens to M1 when its G (running a blocking operation) enters a syscall?</p><p>[<a href=https://go.dev/src/runtime/proc.go>runtime/proc.go</a>]</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>exitsyscall</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>gp</span> <span class=o>:=</span> <span class=nf>getg</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Validate syscall stack frame</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>sys</span><span class=p>.</span><span class=nf>GetCallerSP</span><span class=p>()</span> <span class=p>&gt;</span> <span class=nx>gp</span><span class=p>.</span><span class=nx>syscallsp</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>throw</span><span class=p>(</span><span class=s>&#34;exitsyscall: syscall frame is no longer valid&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nx>gp</span><span class=p>.</span><span class=nx>waitsince</span> <span class=p>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=nx>oldp</span> <span class=o>:=</span> <span class=nx>gp</span><span class=p>.</span><span class=nx>m</span><span class=p>.</span><span class=nx>oldp</span><span class=p>.</span><span class=nf>ptr</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nx>gp</span><span class=p>.</span><span class=nx>m</span><span class=p>.</span><span class=nx>oldp</span> <span class=p>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Fast path: try to reacquire P and resume execution</span>
</span></span><span class=line><span class=cl>    <span class=c1>// if P is IDLE, return true and resume running goroutine</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nf>exitsyscallfast</span><span class=p>(</span><span class=nx>oldp</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>        <span class=nf>casgstatus</span><span class=p>(</span><span class=nx>gp</span><span class=p>,</span> <span class=nx>_Gsyscall</span><span class=p>,</span> <span class=nx>_Grunning</span><span class=p>)</span> <span class=c1>// mark G as running</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Slow path: failed to reacquire P</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Call scheduler (park M and let scheduler run G later)</span>
</span></span><span class=line><span class=cl>    <span class=nf>mcall</span><span class=p>(</span><span class=nx>exitsyscall0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><table><thead><tr><th>Condition</th><th>Handling</th></tr></thead><tbody><tr><td>P can be reacquired</td><td>G1 resumes immediately (<code>execute(g)</code>)</td></tr><tr><td>P cannot be reacquired</td><td>G1 is enqueued as runnable, M1 is stopped (<code>stopm()</code>)</td></tr><tr><td>Too many idle Ms</td><td>M1 may be completely terminated</td></tr><tr><td>Lack of idle Ms</td><td>M1 may be reused (<code>newm()</code> is avoided if possible)</td></tr></tbody></table><h3 id=multithreading-with-m-os-thread-in-other-languages>Multithreading with M (OS Thread) in other languages<a hidden class=anchor aria-hidden=true href=#multithreading-with-m-os-thread-in-other-languages>#</a></h3><ul><li>One OS thread is created per request, and that thread performs <code>epoll_wait/syscall</code></li><li>N worker threads are created, each handling <code>epoll_wait</code> or <code>read</code></li></ul><h4 id=cons>Cons<a hidden class=anchor aria-hidden=true href=#cons>#</a></h4><ul><li>To handle 1,000 concurrent requests, <strong>up to 1,000 threads are required</strong></li><li>Each M (<code>epoll_wait</code>) blocks in syscall → leads to context switches</li><li>*<em>Cache misses</em>, kernel entry cost, and scheduling overhead increase sharply</li></ul><blockquote><p>Cache miss: After a context switch, if the required data is no longer in the CPU cache, it must be reloaded from memory (which is slower)</p></blockquote><hr><h3 id=netpoller-m>Netpoller M<a hidden class=anchor aria-hidden=true href=#netpoller-m>#</a></h3><p><img loading=lazy src=/posts/gmp/netpoller.png></p><p>The Netpoller M is a dedicated OS thread (M) maintained by the Go runtime, connected to the kernel&rsquo;s I/O readiness monitoring systems like <code>epoll</code>, <code>kqueue</code>, etc.</p><ul><li>When goroutines use non-blocking I/O (fd), this M exclusively <strong>monitors the readable/writable status</strong> of those fds</li><li>A single M can monitor thousands of fds, efficiently handling a large number of I/O goroutines with minimal resources</li></ul><blockquote><p>Flow of two goroutines that include syscalls and the Netpoller M</p></blockquote><p><img loading=lazy src=/posts/gmp/image-4.png></p><hr><h4 id=why-cant-m-make-a-syscall-directly>Why can’t M make a syscall directly?<a hidden class=anchor aria-hidden=true href=#why-cant-m-make-a-syscall-directly>#</a></h4><blockquote><p>Example: Assume G1 calls <code>conn.Read()</code> on a TCP socket<br>If the peer suddenly disconnects or NAT timeout occurs but the kernel does not send an EOF signal?</p></blockquote><ul><li>The <code>read(fd)</code> syscall never returns (remains in a blocked state)</li><li>The M executing G1 becomes blocked on the syscall</li><li>The P owned by that M is also released, reducing overall concurrency</li></ul><p>Because of this, Go checks the fd’s readiness using <code>epoll</code> before calling <code>read()</code> to avoid indefinite blocking.</p><hr><h4 id=why-does-the-netpoller-m-exclusively-handle-epoll>Why does the Netpoller M exclusively handle epoll?<a hidden class=anchor aria-hidden=true href=#why-does-the-netpoller-m-exclusively-handle-epoll>#</a></h4><blockquote><p>Example: 1,000 Ms each calling <code>epoll_wait(fd)</code></p></blockquote><ul><li>All 1,000 Ms independently call <code>epoll_wait()</code></li><li><code>epoll_wait</code> is also a syscall, which incurs kernel-to-user space transition overhead</li><li>We must also consider how frequently to perform epoll → adds polling interval overhead</li></ul><hr><h2 id=g-goroutine>G (Goroutine)<a hidden class=anchor aria-hidden=true href=#g-goroutine>#</a></h2><h3 id=goroutine-scheduling>Goroutine Scheduling<a hidden class=anchor aria-hidden=true href=#goroutine-scheduling>#</a></h3><p>Let’s look at the execution flow of a goroutine.</p><blockquote><p><code>go dosomething()</code> is called to spawn a new goroutine.</p><p><strong>Current status</strong></p><ul><li>LRQ is full</li><li>A new goroutine is spawned</li></ul></blockquote><p><img loading=lazy src=/posts/gmp/gmp1.png></p><ol><li>A new goroutine (G0) checks if there’s space in the left P’s LRQ</li><li>The current P&rsquo;s LRQ is full (in practice, LRQ size = 256)<br><img loading=lazy src=/posts/gmp/gmp2.png></li><li>Half of the current LRQ is moved to GRQ (e.g., G2 → GRQ)</li><li>G0 is inserted into the LRQ as P is now available<br><img loading=lazy src=/posts/gmp/gmp3.png></li><li>G1 runs and G0 is set as <code>runnext</code></li><li>Since LRQ is empty, a G is taken from GRQ (fetches <code>GRQ length / GOMAXPROCS + 1</code>)<br><img loading=lazy src=/posts/gmp/gmp4.png></li><li>G0 runs on M and sends a request to the socket</li><li>G0 registers readiness using <code>epoll_ctl(..., EPOLLIN)</code><br><img loading=lazy src=/posts/gmp/gmp5-1.png></li><li>To avoid blocking, it detaches from the current P</li><li>Netpoller M checks readiness using <code>epoll_wait</code><br><img loading=lazy src=/posts/gmp/gmp6.png></li><li>M returns to IDLE state, and G0 waits via <code>Gopark</code> (later deleted or reattached to a P)</li><li>Netpoller M detects readiness of G0’s fd<br><img loading=lazy src=/posts/gmp/gmp7.png></li><li>Netpoller M marks G0 as Goready after detecting readiness</li><li>P fails to find a G in LRQ and GRQ<br><img loading=lazy src=/posts/gmp/gmp8.png></li><li>P directly fetches the ready G from <code>netpoll</code> and executes it</li></ol><h2 id=caveats>Caveats<a hidden class=anchor aria-hidden=true href=#caveats>#</a></h2><h3 id=grq-starvation>GRQ Starvation<a hidden class=anchor aria-hidden=true href=#grq-starvation>#</a></h3><ul><li>Only LRQs may be checked repeatedly, causing GRQ starvation</li><li><code>schedTick</code> variable ensures GRQ is checked every 61 ticks</li><li>Why 61? It’s a prime number experimentally proven to perform well. Like hash map sizing, prime numbers help avoid distribution conflicts with application patterns</li></ul><p>[<a href=https://go.dev/src/runtime/proc.go>runtime/proc.go</a>]</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>findRunnable</span><span class=p>()</span> <span class=p>(</span><span class=nx>gp</span> <span class=o>*</span><span class=nx>g</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=nx>tryWakeP</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>mp</span> <span class=o>:=</span> <span class=nf>getg</span><span class=p>().</span><span class=nx>m</span>
</span></span><span class=line><span class=cl>    <span class=nx>pp</span> <span class=o>:=</span> <span class=nx>mp</span><span class=p>.</span><span class=nx>p</span><span class=p>.</span><span class=nf>ptr</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Check the global runnable queue once in a while to ensure fairness</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>pp</span><span class=p>.</span><span class=nx>schedtick</span><span class=o>%</span><span class=mi>61</span> <span class=o>==</span> <span class=mi>0</span> <span class=o>&amp;&amp;</span> <span class=p>!</span><span class=nx>sched</span><span class=p>.</span><span class=nx>runq</span><span class=p>.</span><span class=nf>empty</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>lock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>lock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nx>gp</span> <span class=o>:=</span> <span class=nf>globrunqget</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nf>unlock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>lock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>gp</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=kc>false</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// local runq</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span> <span class=o>:=</span> <span class=nf>runqget</span><span class=p>(</span><span class=nx>pp</span><span class=p>);</span> <span class=nx>gp</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nx>gp</span><span class=p>,</span> <span class=nx>inheritTime</span><span class=p>,</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=time-slice-based-preemption>Time slice based preemption<a hidden class=anchor aria-hidden=true href=#time-slice-based-preemption>#</a></h3><p>To prevent one goroutine from monopolizing a processor, Go defines a default 10ms time slice. After this time, the running G is preempted and returned to GRQ.</p><p>[<a href=https://go.dev/src/runtime/proc.go>runtime/proc.go</a>]</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>sysmon</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>        <span class=nf>lock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>sysmonlock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nx>now</span> <span class=p>=</span> <span class=nf>nanotime</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// retake P&#39;s blocked in syscalls</span>
</span></span><span class=line><span class=cl>        <span class=c1>// and preempt long running G&#39;s</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nf>retake</span><span class=p>(</span><span class=nx>now</span><span class=p>)</span> <span class=o>!=</span> <span class=mi>0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>idle</span> <span class=p>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>idle</span><span class=o>++</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>        <span class=nf>unlock</span><span class=p>(</span><span class=o>&amp;</span><span class=nx>sched</span><span class=p>.</span><span class=nx>sysmonlock</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h1 id=what-happens-when-handling-tens-of-millions-of-network-io>What happens when handling tens of millions of network I/O?<a hidden class=anchor aria-hidden=true href=#what-happens-when-handling-tens-of-millions-of-network-io>#</a></h1><p>Go&rsquo;s goroutines can perform efficiently even under large-scale network I/O thanks to lightweight context switching, small memory usage, and epoll-based polling architecture.</p><p>However, if the external API response is slow (e.g., 10 seconds), and tens of millions of requests per second flood in, the following bottlenecks and risks arise:</p><h2 id=potential-error-cases>Potential Error Cases<a hidden class=anchor aria-hidden=true href=#potential-error-cases>#</a></h2><h3 id=1-explosive-increase-in-goroutine-count>1. Explosive increase in goroutine count<a hidden class=anchor aria-hidden=true href=#1-explosive-increase-in-goroutine-count>#</a></h3><ul><li>If every request waits >10s due to external API, goroutines pile up in waiting state</li><li>10M req/s × 10s = up to 100M concurrent goroutines</li><li>At 2KB per goroutine, memory usage = 100M × 2KB ≒ 200GB+</li><li>System memory gets exhausted → OOM</li></ul><h3 id=2-file-descriptor-fd-limit>2. File descriptor (fd) limit<a hidden class=anchor aria-hidden=true href=#2-file-descriptor-fd-limit>#</a></h3><ul><li>Each TCP connection consumes an fd</li><li>Linux ulimit -n typically limits open files to thousands or tens of thousands</li><li>New requests eventually fail due to fd exhaustion</li></ul><h4 id=reference--default-fd-limits-by-os>Reference – Default FD Limits by OS<a hidden class=anchor aria-hidden=true href=#reference--default-fd-limits-by-os>#</a></h4><table><thead><tr><th>Operating System</th><th>Soft Limit (Default)</th><th>Hard Limit</th><th>Notes</th></tr></thead><tbody><tr><td><strong>Ubuntu (20.04~)</strong></td><td>1024</td><td>1048576</td><td>Can be adjusted in <code>/etc/security/limits.conf</code></td></tr><tr><td><strong>Debian</strong></td><td>1024</td><td>4096</td><td>May vary depending on the system</td></tr><tr><td><strong>CentOS 7</strong></td><td>1024</td><td>4096 or 1024</td><td>Can be configured via systemd or <code>limits.conf</code></td></tr><tr><td><strong>macOS</strong></td><td>256</td><td>10240</td><td>As of Ventura: soft=256, hard=10240 (varies per app/terminal)</td></tr></tbody></table><h2 id=test-is-running-100m-goroutines-okay>Test: Is running 100M goroutines okay?<a hidden class=anchor aria-hidden=true href=#test-is-running-100m-goroutines-okay>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>init</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>http</span><span class=p>.</span><span class=nf>HandleFunc</span><span class=p>(</span><span class=s>&#34;/slow&#34;</span><span class=p>,</span> <span class=kd>func</span><span class=p>(</span><span class=nx>w</span> <span class=nx>http</span><span class=p>.</span><span class=nx>ResponseWriter</span><span class=p>,</span> <span class=nx>r</span> <span class=o>*</span><span class=nx>http</span><span class=p>.</span><span class=nx>Request</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>time</span><span class=p>.</span><span class=nf>Sleep</span><span class=p>(</span><span class=mi>10</span> <span class=o>*</span> <span class=nx>time</span><span class=p>.</span><span class=nx>Second</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>    <span class=k>go</span> <span class=kd>func</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>log</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;slow API server start in :18080&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nx>http</span><span class=p>.</span><span class=nf>ListenAndServe</span><span class=p>(</span><span class=s>&#34;:18080&#34;</span><span class=p>,</span> <span class=kc>nil</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}()</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// ===== trace start =====</span>
</span></span><span class=line><span class=cl>    <span class=nx>traceFile</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>os</span><span class=p>.</span><span class=nf>Create</span><span class=p>(</span><span class=s>&#34;trace.out&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>log</span><span class=p>.</span><span class=nf>Fatalf</span><span class=p>(</span><span class=s>&#34;trace file creation failed: %v&#34;</span><span class=p>,</span> <span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>trace</span><span class=p>.</span><span class=nf>Start</span><span class=p>(</span><span class=nx>traceFile</span><span class=p>);</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>log</span><span class=p>.</span><span class=nf>Fatalf</span><span class=p>(</span><span class=s>&#34;trace start failed: %v&#34;</span><span class=p>,</span> <span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>defer</span> <span class=kd>func</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>trace</span><span class=p>.</span><span class=nf>Stop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nx>traceFile</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>}()</span>
</span></span><span class=line><span class=cl>    <span class=c1>// =====================</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>startProfiler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=nx>i</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>i</span> <span class=p>&lt;</span> <span class=mi>100000000</span><span class=p>;</span> <span class=nx>i</span><span class=o>++</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>go</span> <span class=kd>func</span><span class=p>(</span><span class=nx>i</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>client</span> <span class=o>:=</span> <span class=o>&amp;</span><span class=nx>http</span><span class=p>.</span><span class=nx>Client</span><span class=p>{}</span>
</span></span><span class=line><span class=cl>            <span class=nx>resp</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>client</span><span class=p>.</span><span class=nf>Get</span><span class=p>(</span><span class=s>&#34;http://localhost:18080/slow&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=nx>fmt</span><span class=p>.</span><span class=nf>Printf</span><span class=p>(</span><span class=s>&#34;[%d] Error: %v&#34;</span><span class=p>,</span> <span class=nx>i</span><span class=p>,</span> <span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=nx>io</span><span class=p>.</span><span class=nf>Copy</span><span class=p>(</span><span class=nx>io</span><span class=p>.</span><span class=nx>Discard</span><span class=p>,</span> <span class=nx>resp</span><span class=p>.</span><span class=nx>Body</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nx>resp</span><span class=p>.</span><span class=nx>Body</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=p>}(</span><span class=nx>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>i</span><span class=o>%</span><span class=mi>100000</span> <span class=o>==</span> <span class=mi>0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>fmt</span><span class=p>.</span><span class=nf>Printf</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s>&#34;Current Request Count: %d, Goroutine Count: %d&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=nx>i</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=nx>runtime</span><span class=p>.</span><span class=nf>NumGoroutine</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>select</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><img loading=lazy src=/posts/gmp/image-5.png></p><h3 id=heap-profile>heap profile<a hidden class=anchor aria-hidden=true href=#heap-profile>#</a></h3><p><img loading=lazy src=/posts/gmp/image-7.png></p><ul><li><code>net/http.(*Transport).getConn</code>: Fails to reuse connections → FD surge → heap grows</li><li><code>runtime.malg</code>: Goroutines wait → their stacks remain → heap inflates</li></ul><h3 id=cpu-profile>cpu profile<a hidden class=anchor aria-hidden=true href=#cpu-profile>#</a></h3><p><img loading=lazy src=/posts/gmp/image-9.png></p><ul><li><code>runtime.cgocall</code>: Bursts of HTTP syscalls</li><li><code>runtime.(*timers).adjust</code>: Too many timers from <code>time.Sleep</code> increase min-heap ops</li></ul><p><img loading=lazy src=/posts/gmp/image-10.png></p><blockquote><p><strong>Reason for Connection Timeout</strong></p><p>After the default HTTP client&rsquo;s <code>MaxConnectionPool</code> is fully consumed, a new connection must be created, which involves the 3-way TCP handshake process.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Client Request         Server Handling
</span></span><span class=line><span class=cl>--------------         ----------------------------
</span></span><span class=line><span class=cl>SYN  ───────────▶      [Waiting in the SYN queue]
</span></span><span class=line><span class=cl>                           (Before `accept()` is called)
</span></span><span class=line><span class=cl>                           `accept()` is called → connection accepted
</span></span><span class=line><span class=cl>                                 ⇩
</span></span><span class=line><span class=cl>SYN-ACK ◀──────────     Connection accepted
</span></span><span class=line><span class=cl>ACK     ───────────▶     Connection established (3-way handshake complete)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>If the server&#39;s SYN queue is full, the connection cannot be established and remains blocked, eventually leading to a timeout.
</span></span></code></pre></div></blockquote><ul><li>Unbounded goroutines waiting = heap bloat = OOM = crash</li></ul><p>Even with connection pooling:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=nx>client</span> <span class=o>:=</span> <span class=o>&amp;</span><span class=nx>http</span><span class=p>.</span><span class=nx>Client</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>Transport</span><span class=p>:</span> <span class=o>&amp;</span><span class=nx>http</span><span class=p>.</span><span class=nx>Transport</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>MaxIdleConns</span><span class=p>:</span>        <span class=mi>10000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nx>MaxIdleConnsPerHost</span><span class=p>:</span> <span class=mi>10000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nx>IdleConnTimeout</span><span class=p>:</span>     <span class=mi>90</span> <span class=o>*</span> <span class=nx>time</span><span class=p>.</span><span class=nx>Second</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nx>DisableKeepAlives</span><span class=p>:</span>   <span class=kc>false</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=nx>Timeout</span><span class=p>:</span> <span class=mi>30</span> <span class=o>*</span> <span class=nx>time</span><span class=p>.</span><span class=nx>Second</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Still ends in OOM due to:
<img loading=lazy src=/posts/gmp/image-12.png>
<img loading=lazy src=/posts/gmp/image-13.png></p><h1 id=refs>REFS<a hidden class=anchor aria-hidden=true href=#refs>#</a></h1><ul><li><a href="https://www.youtube.com/watch?v=-K11rY57K7k">Dmitry Vtukov</a></li><li><a href=https://velog.io/@sunaookamisiroko/Goroutine-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81>GopherCon 2021: Madhav Jivrajani - Queues, Fairness, and The Go Scheduler</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/go/>Go</a></li><li><a href=https://dingyu.dev/en/tags/async/>Async</a></li><li><a href=https://dingyu.dev/en/tags/channel/>Channel</a></li><li><a href=https://dingyu.dev/en/tags/gmp/>Gmp</a></li><li><a href=https://dingyu.dev/en/tags/thread/>Thread</a></li><li><a href=https://dingyu.dev/en/tags/goroutine/>Goroutine</a></li><li><a href=https://dingyu.dev/en/tags/pprof/>Pprof</a></li></ul><nav class=paginav><a class=next href=https://dingyu.dev/en/posts/distributed-locking/><span class=title>Next »</span><br><span>[DB] Redlock and Lease in Distributed Systems</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
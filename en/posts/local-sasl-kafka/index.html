<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose) | Ding's Coding Forge</title>
<meta name=keywords content="kafka,sasl,bitnami,kafka ui,local test"><meta name=description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers‚Äîall without modifying code or relying on external infrastructure."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/local-sasl-kafka/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.ba0de23ad40e17ca82720b577f8ae6ec11a26fb07407316cff70888e344ad129.css integrity="sha256-ug3iOtQOF8qCcgtXf4rm7BGib7B0BzFs/3CIjjRK0Sk=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/local-sasl-kafka/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/local-sasl-kafka/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/local-sasl-kafka/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)"><meta property="og:description" content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers‚Äîall without modifying code or relying on external infrastructure."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-28T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Sasl"><meta property="article:tag" content="Bitnami"><meta property="article:tag" content="Kafka Ui"><meta property="article:tag" content="Local Test"><meta property="og:image" content="https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:title content="[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)"><meta name=twitter:description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers‚Äîall without modifying code or relying on external infrastructure."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","item":"https://dingyu.dev/en/posts/local-sasl-kafka/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","name":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","description":"This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers‚Äîall without modifying code or relying on external infrastructure.","keywords":["kafka","sasl","bitnami","kafka ui","local test"],"articleBody":"Why This Setup? Debugging on development servers was cumbersome due to lack of access/log visibility. Kafka in our environment enforces SASL authentication. We needed to test with different SASL mechanisms (SCRAM-256 and 512) without changing application code. Our Event Dispatcher consumes from one Kafka and produces to another‚Äîall on the same cluster but under different authentication methods. For availability testing (e.g., ISR=2), a 3-node Kafka cluster is used. Features Kafka cluster with SCRAM-SHA-256 and SCRAM-SHA-512 authentication Zookeeper-based Kafka cluster with 3 brokers Kafka UI for producing and inspecting topics Event Dispatcher that uses SCRAM-256 for consumer and SCRAM-512 for producer Why Bitnami Kafka? Bitnami‚Äôs image provides flexible environment-based configuration:\nSASL users auto-registration: KAFKA_CLIENT_USERS=user256,user512 KAFKA_CLIENT_PASSWORDS=pass256,pass512 SASL protocol setup without editing server.properties. Deployment \u0026 Teardown docker compose --env-file .env up --build docker compose down -v .env Example: 256_SASL_USER=user256 256_SASL_PASSWORD=pass256 512_SASL_USER=user512 512_SASL_PASSWORD=pass512 KAFKA_BROKER_0_PORT=9092 KAFKA_BROKER_1_PORT=9093 KAFKA_BROKER_2_PORT=9094 Sequence Overview Zookeeper starts, no user state yet Kafka Brokers register SCRAM users via env Controller elected, brokers stabilize Kafka UI connects using SCRAM-512 for admin operations Event Dispatcher: Consumes with SCRAM-256 Produces with SCRAM-512 Common Issues \u0026 Fixes 1. Misconfigured ADVERTISED_LISTENERS Symptom: UI and clients can‚Äôt connect to Kafka Fix: Use host.docker.internal not localhost\nKAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092 2. Mixed SCRAM mechanism auth failures Symptom: UI works, dispatcher fails with EOF or Failed to authenticate Fix: Double-check user/mechanism pairs and registration\n3. Kafka UI produce failure Symptom: UI can‚Äôt send messages Fix: Ensure correct JAAS SASL configs passed into UI\n4. Cluster ID mismatch Symptom: Broker startup fails after a restart Fix: Teardown volumes fully:\ndocker compose down -v 5. Producer/Consumer config missing SASL Symptom: no brokers to talk to error Fix: Ensure SASL mechanism and credentials are passed correctly into the Kafka config\nFinal Thoughts Building a SASL-based Kafka setup locally is extremely helpful for validating production-like authentication scenarios. Bitnami‚Äôs Kafka image simplifies user registration and protocol setup. Combined with Kafka UI and an app like Event Dispatcher, you can simulate consumer-producer flows entirely within Docker.\nHaving both SCRAM-256 and SCRAM-512 supported in the same cluster without duplicating infrastructure is a game changer.\n","wordCount":"344","inLanguage":"en","image":"https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png","datePublished":"2025-03-28T00:00:00Z","dateModified":"2025-03-28T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/local-sasl-kafka/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://dingyu.dev/ title=ÌïúÍµ≠Ïñ¥ aria-label=ÌïúÍµ≠Ïñ¥>Ko</a></li></ul></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title=üîç><span>üîç</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;¬ª&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)</h1><div class=post-description>This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers‚Äîall without modifying code or relying on external infrastructure.</div><div class=post-meta><span title='2025-03-28 00:00:00 +0000 UTC'>March 28, 2025</span>&nbsp;¬∑&nbsp;2 min&nbsp;¬∑&nbsp;344 words&nbsp;¬∑&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/local-sasl-kafka/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/local-sasl-kafka/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/kafka.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#why-this-setup aria-label="Why This Setup?">Why This Setup?</a></li><li><a href=#features aria-label=Features>Features</a></li><li><a href=#why-bitnami-kafka aria-label="Why Bitnami Kafka?">Why Bitnami Kafka?</a></li><li><a href=#deployment--teardown aria-label="Deployment & Teardown">Deployment & Teardown</a><ul><li><a href=#env-example aria-label=".env Example:"><code>.env</code> Example:</a></li></ul></li><li><a href=#sequence-overview aria-label="Sequence Overview">Sequence Overview</a></li><li><a href=#common-issues--fixes aria-label="Common Issues & Fixes">Common Issues & Fixes</a><ul><li><a href=#1-misconfigured-advertised_listeners aria-label="1. Misconfigured ADVERTISED_LISTENERS">1. Misconfigured <code>ADVERTISED_LISTENERS</code></a></li><li><a href=#2-mixed-scram-mechanism-auth-failures aria-label="2. Mixed SCRAM mechanism auth failures">2. Mixed SCRAM mechanism auth failures</a></li><li><a href=#3-kafka-ui-produce-failure aria-label="3. Kafka UI produce failure">3. Kafka UI produce failure</a></li><li><a href=#4-cluster-id-mismatch aria-label="4. Cluster ID mismatch">4. Cluster ID mismatch</a></li><li><a href=#5-producerconsumer-config-missing-sasl aria-label="5. Producer/Consumer config missing SASL">5. Producer/Consumer config missing SASL</a></li></ul></li><li><a href=#final-thoughts aria-label="Final Thoughts">Final Thoughts</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=why-this-setup>Why This Setup?<a hidden class=anchor aria-hidden=true href=#why-this-setup>#</a></h2><ul><li>Debugging on development servers was cumbersome due to lack of access/log visibility.</li><li>Kafka in our environment enforces SASL authentication.</li><li>We needed to test with different SASL mechanisms (SCRAM-256 and 512) <strong>without changing application code</strong>.</li><li>Our Event Dispatcher consumes from one Kafka and produces to another‚Äîall on the same cluster but under different authentication methods.</li><li>For availability testing (e.g., ISR=2), a <strong>3-node Kafka cluster</strong> is used.</li></ul><p><img loading=lazy src=img/kafka.png></p><h2 id=features>Features<a hidden class=anchor aria-hidden=true href=#features>#</a></h2><ul><li>Kafka cluster with <strong>SCRAM-SHA-256</strong> and <strong>SCRAM-SHA-512</strong> authentication</li><li><strong>Zookeeper-based</strong> Kafka cluster with 3 brokers</li><li><strong>Kafka UI</strong> for producing and inspecting topics</li><li><strong>Event Dispatcher</strong> that uses SCRAM-256 for consumer and SCRAM-512 for producer</li></ul><h2 id=why-bitnami-kafka>Why Bitnami Kafka?<a hidden class=anchor aria-hidden=true href=#why-bitnami-kafka>#</a></h2><p>Bitnami‚Äôs image provides flexible environment-based configuration:</p><ol><li><strong>SASL users auto-registration</strong>:</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_USERS</span><span class=o>=</span>user256,user512
</span></span><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_PASSWORDS</span><span class=o>=</span>pass256,pass512
</span></span></code></pre></div><ol start=2><li><strong>SASL protocol setup</strong> without editing <code>server.properties</code>.</li></ol><p><img loading=lazy src=img/kafka-ui.png></p><h2 id=deployment--teardown>Deployment & Teardown<a hidden class=anchor aria-hidden=true href=#deployment--teardown>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker compose --env-file .env up --build
</span></span><span class=line><span class=cl>docker compose down -v
</span></span></code></pre></div><h3 id=env-example><code>.env</code> Example:<a hidden class=anchor aria-hidden=true href=#env-example>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>256_SASL_USER</span><span class=o>=</span>user256
</span></span><span class=line><span class=cl><span class=nv>256_SASL_PASSWORD</span><span class=o>=</span>pass256
</span></span><span class=line><span class=cl><span class=nv>512_SASL_USER</span><span class=o>=</span>user512
</span></span><span class=line><span class=cl><span class=nv>512_SASL_PASSWORD</span><span class=o>=</span>pass512
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_0_PORT</span><span class=o>=</span><span class=m>9092</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_1_PORT</span><span class=o>=</span><span class=m>9093</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_2_PORT</span><span class=o>=</span><span class=m>9094</span>
</span></span></code></pre></div><h2 id=sequence-overview>Sequence Overview<a hidden class=anchor aria-hidden=true href=#sequence-overview>#</a></h2><ol><li><strong>Zookeeper starts</strong>, no user state yet</li><li>Kafka Brokers register <strong>SCRAM users</strong> via env</li><li>Controller elected, brokers stabilize</li><li>Kafka UI connects using <strong>SCRAM-512</strong> for admin operations</li><li>Event Dispatcher:<ul><li>Consumes with <strong>SCRAM-256</strong></li><li>Produces with <strong>SCRAM-512</strong></li></ul></li></ol><p><img loading=lazy src=/posts/local-sasl-kafka/image.png></p><h2 id=common-issues--fixes>Common Issues & Fixes<a hidden class=anchor aria-hidden=true href=#common-issues--fixes>#</a></h2><h3 id=1-misconfigured-advertised_listeners>1. Misconfigured <code>ADVERTISED_LISTENERS</code><a hidden class=anchor aria-hidden=true href=#1-misconfigured-advertised_listeners>#</a></h3><p><strong>Symptom:</strong> UI and clients can&rsquo;t connect to Kafka
<strong>Fix:</strong> Use <code>host.docker.internal</code> not <code>localhost</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=o>=</span>PLAINTEXT://host.docker.internal:9092
</span></span></code></pre></div><h3 id=2-mixed-scram-mechanism-auth-failures>2. Mixed SCRAM mechanism auth failures<a hidden class=anchor aria-hidden=true href=#2-mixed-scram-mechanism-auth-failures>#</a></h3><p><strong>Symptom:</strong> UI works, dispatcher fails with <code>EOF</code> or <code>Failed to authenticate</code>
<strong>Fix:</strong> Double-check user/mechanism pairs and registration</p><h3 id=3-kafka-ui-produce-failure>3. Kafka UI produce failure<a hidden class=anchor aria-hidden=true href=#3-kafka-ui-produce-failure>#</a></h3><p><strong>Symptom:</strong> UI can&rsquo;t send messages
<strong>Fix:</strong> Ensure correct JAAS SASL configs passed into UI</p><h3 id=4-cluster-id-mismatch>4. Cluster ID mismatch<a hidden class=anchor aria-hidden=true href=#4-cluster-id-mismatch>#</a></h3><p><strong>Symptom:</strong> Broker startup fails after a restart
<strong>Fix:</strong> Teardown volumes fully:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker compose down -v
</span></span></code></pre></div><h3 id=5-producerconsumer-config-missing-sasl>5. Producer/Consumer config missing SASL<a hidden class=anchor aria-hidden=true href=#5-producerconsumer-config-missing-sasl>#</a></h3><p><strong>Symptom:</strong> <code>no brokers to talk to</code> error
<strong>Fix:</strong> Ensure SASL mechanism and credentials are passed correctly into the Kafka config</p><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>Building a SASL-based Kafka setup locally is extremely helpful for validating production-like authentication scenarios. Bitnami‚Äôs Kafka image simplifies user registration and protocol setup. Combined with Kafka UI and an app like Event Dispatcher, you can simulate consumer-producer flows entirely within Docker.</p><blockquote><p>Having both SCRAM-256 and SCRAM-512 supported in the same cluster without duplicating infrastructure is a game changer.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/en/tags/sasl/>Sasl</a></li><li><a href=https://dingyu.dev/en/tags/bitnami/>Bitnami</a></li><li><a href=https://dingyu.dev/en/tags/kafka-ui/>Kafka Ui</a></li><li><a href=https://dingyu.dev/en/tags/local-test/>Local Test</a></li></ul><nav class=paginav><a class=next href=https://dingyu.dev/en/posts/dance-with-burrow/><span class=title>Next ¬ª</span><br><span>[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose) | Ding's Coding Forge</title>
<meta name=keywords content="kafka,sasl,bitnami,kafka ui,local test"><meta name=description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/local-sasl-kafka/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/local-sasl-kafka/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/local-sasl-kafka/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/local-sasl-kafka/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)"><meta property="og:description" content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-28T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Sasl"><meta property="article:tag" content="Bitnami"><meta property="article:tag" content="Kafka Ui"><meta property="article:tag" content="Local Test"><meta property="og:image" content="https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:title content="[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)"><meta name=twitter:description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","item":"https://dingyu.dev/en/posts/local-sasl-kafka/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","name":"[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)","description":"This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure.","keywords":["kafka","sasl","bitnami","kafka ui","local test"],"articleBody":"Setting Up Local SASL Mechanism Kafka Cluster with Docker Compose When using Kafka with SASL-based authentication, it’s important to replicate a similar authentication environment locally for testing.\nThis post documents how to build a Kafka cluster in a local environment that simultaneously supports both SCRAM-SHA-256 and SCRAM-SHA-512, and how to test the Event Dispatcher application on top of it.\nIt was extremely difficult to find references for setting up SASL and TLS locally…\nSo while struggling through the setup, I decided to leave this guide as a gift for my future self.\n(TLS setup with Makefile for certificates was a bit too complex, so I’ll cover that in a separate post later.)\nGoals The Event Dispatcher consumes events from a source Kafka and produces to a destination Kafka depending on event types. Source and Destination Kafka are on the same cluster, but differentiated by different SASL mechanisms. Source Kafka uses SCRAM-SHA-256, Destination Kafka uses SCRAM-SHA-512. The goal is to replicate the production environment structure without modifying the application code even during tests. Kafka cluster has 3 brokers to set ISR (in-sync replicas) to 2. Kafka UI should allow manual produce tests to verify application behavior. Why Set Up a Local Environment? Debugging on a shared dev server was inconvenient because of limited stack trace access and the need to go through VPN/Bastion gateways. All internal Kafka clusters use SASL, so creating a reusable setup would benefit many projects. Configuration should be modifiable for testing (like transaction settings, exactly-once semantics, ISR tuning) without code changes or deployments. A local infrastructure was necessary to maintain identical codebases during testing. Docker Compose Configuration version: '3.9' networks: kafka_network: volumes: kafka_data_0: kafka_data_1: kafka_data_2: services: zookeeper: image: bitnami/zookeeper:3.8.1 container_name: zookeeper environment: - ALLOW_ANONYMOUS_LOGIN=yes ports: - '2181:2181' networks: - kafka_network kafka-0: image: bitnami/kafka:3.7.0 container_name: kafka-0 depends_on: - zookeeper ports: - '${KAFKA_BROKER_0_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_0_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_0:/bitnami/kafka networks: - kafka_network hostname: kafka kafka-1: image: bitnami/kafka:3.7.0 container_name: kafka-1 depends_on: - zookeeper ports: - '${KAFKA_BROKER_1_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_1_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_1:/bitnami/kafka networks: - kafka_network hostname: kafka-1 kafka-2: image: bitnami/kafka:3.7.0 container_name: kafka-2 depends_on: - zookeeper ports: - '${KAFKA_BROKER_2_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_2:/bitnami/kafka networks: - kafka_network hostname: kafka-2 kafka-ui: image: provectuslabs/kafka-ui:latest container_name: kafka-ui depends_on: - kafka-0 ports: - '8080:8080' environment: KAFKA_CLUSTERS_0_NAME: Local-Zookeeper-Cluster KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: SCRAM-SHA-512 KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${512_SASL_USER}\" password=\"${512_SASL_PASSWORD}\"; networks: - kafka_network your-app: env_file: - .env build: context: . dockerfile: dev.Dockerfile args: - VERSION=dev environment: - BOOTSTRAP_SERVERS_256=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} - BOOTSTRAP_SERVERS_512=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} image: your-app container_name: your-app networks: - kafka_network restart: always depends_on: - kafka-0 - kafka-1 - kafka-2 Why Bitnami? Simple User Registration with Environment Variables Bitnami Kafka allows automatic SASL user registration simply by setting the following environment variables:\nKAFKA_CLIENT_USERS=user256,user512 KAFKA_CLIENT_PASSWORDS=pass256,pass512 In contrast, the official Kafka image requires manually running kafka-configs.sh or creating a custom entrypoint.\nExample with official Kafka:\nbash -c ' /opt/bitnami/scripts/kafka/setup.sh \u0026\u0026 kafka-configs.sh --zookeeper zookeeper:2181 --alter \\ --add-config \"SCRAM-SHA-512=[iterations=8192,password=pass]\" \\ --entity-type users --entity-name user \u0026\u0026 /opt/bitnami/scripts/kafka/run.sh' Bitnami handles user registration automatically during container startup.\nBuilt-in SASL and Zookeeper Integration Bitnami allows setting SASL and Zookeeper configurations through environment variables without editing server.properties:\nKAFKA_CFG_SASL_ENABLED_MECHANISMS KAFKA_CFG_LISTENER_NAME__SASL_ENABLED_MECHANISMS KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL Environment Variable Description Purpose KAFKA_CFG_ZOOKEEPER_CONNECT Address of Zookeeper (host:port) Required for Kafka to store/share cluster metadata KAFKA_CFG_LISTENERS Protocol and port for external connections Defines how clients and brokers communicate KAFKA_CFG_ADVERTISED_LISTENERS Address advertised to clients Provides connection info to Kafka clients KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP Maps listener names to security protocols Activates SASL authentication KAFKA_CFG_INTER_BROKER_LISTENER_NAME Listener used for broker-to-broker communication Sets which listener (auth method) is used internally KAFKA_CFG_SASL_ENABLED_MECHANISMS List of allowed SASL mechanisms Defines available SASL mechanisms KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL SASL mechanism for inter-broker communication Selects SCRAM algorithm for internal authentication KAFKA_CLIENT_USERS Comma-separated list of users Registers users in Kafka KAFKA_CLIENT_PASSWORDS Comma-separated list of passwords Associates passwords with users KAFKA_INTER_BROKER_USER User for inter-broker authentication Specifies the user for broker-to-broker SASL authentication KAFKA_INTER_BROKER_PASSWORD Password for inter-broker user Password for the above user The environment includes:\n3-node Bitnami Kafka cluster (supporting both SCRAM-SHA-256 and SCRAM-SHA-512) Zookeeper Kafka UI for management and testing Event Dispatcher application (Kafka Consumer/Producer) After setting up the .env file, start the infrastructure with:\ndocker compose --env-file .env up --build To stop and clean up the cluster (including volumes):\ndocker compose down -v Example .env file:\n256_SASL_USER=user256 256_SASL_PASSWORD=pass256 512_SASL_USER=user512 512_SASL_PASSWORD=pass512 # Kafka Settings KAFKA_BROKER_0_PORT=9092 KAFKA_BROKER_1_PORT=9093 KAFKA_BROKER_2_PORT=9094 Detailed Component Overview The diagram below summarizes how the Kafka cluster, Event Dispatcher, and Kafka UI interact within the local environment. It describes the initialization and authentication sequences based on actual startup logs.\n1. Zookeeper Initialization Zookeeper container starts in standalone mode, acting as metadata storage for Kafka brokers. Kafka brokers automatically register SCRAM users via KAFKA_CLIENT_USERS and KAFKA_CLIENT_PASSWORDS. user256 (SCRAM-SHA-256) and user512 (SCRAM-SHA-512) are registered in Zookeeper. 2. Kafka Broker Startup and Zookeeper Connection Brokers (kafka-0, kafka-1, kafka-2) connect sequentially to Zookeeper. Once connected, brokers participate in controller election and become ready to serve requests. 3. Controller Election One broker is elected as the controller. The controller synchronizes broker states, partition metadata, and leader elections. Messages like LeaderAndIsr and UpdateMetadataRequest are exchanged to stabilize the cluster. 4. Kafka UI Connection Kafka UI connects to the brokers using user512 via SCRAM-SHA-512 authentication. After authentication, topics can be browsed, and test messages can be produced. 5. Event Dispatcher Connection Event Dispatcher connects to the source Kafka using SCRAM-SHA-256 (user256) and starts consuming. It connects to the destination Kafka using SCRAM-SHA-512 (user512) and produces processed messages. Full Sequence Diagram Troubleshooting and Solutions 1. Incorrect KAFKA_CFG_ADVERTISED_LISTENERS Initially, setting localhost caused connection failures from Kafka UI and Event Dispatcher.\nSymptoms:\nKafka UI or Event Dispatcher couldn’t connect. connection refused or EOF errors. Solution:\nUse host.docker.internal or the actual host IP instead of localhost. KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092 2. Authentication Failures with Different SASL Mechanisms User registrations weren’t properly set for both SCRAM mechanisms.\nSymptoms:\nKafka UI succeeds, Event Dispatcher fails with EOF or auth error. Kafka logs show Failed to authenticate user. Solution:\nEnsure users are registered properly using --mechanism option. Verify using logs or kafka-configs.sh. --entity-type users --entity-name user512 --alter --add-config 'SCRAM-SHA-512=[iterations=4096,password=pass512]' Eventually switched to setting KAFKA_CLIENT_USERS and KAFKA_CLIENT_PASSWORDS.\n3. Produce Failures in Kafka UI Kafka UI failed to produce messages due to auth or metadata issues.\nSymptoms:\nProduce attempts failed. Topic browse failed or auth errors in logs. Solution:\nCorrectly configure SCRAM authentication in Kafka UI settings. Ensure the user uses SCRAM-SHA-512. 4. ISR and Cluster ID Conflicts Restarting the cluster caused cluster ID mismatch errors.\nSymptoms:\nBroker failed to start or controller election failed. Errors like Cluster ID mismatch or log directory is not empty. Solution:\nTear down volumes completely during reset: docker compose down -v If necessary, manually delete kafka_data_* directories. 5. Missing SASL Config in Producers/Consumers Producers/Consumers were missing SASL configs.\nSymptoms:\nkafka: client has run out of available brokers to talk to Connection attempts ended with EOF. Solution:\nAdd SASL settings in .env and client library configs. (e.g., for Go clients: set Config.Net.SASL.Mechanism properly) Conclusion As security and authentication become essential in Kafka environments, setting up a SASL-authenticated local cluster is highly valuable.\nBy supporting multiple SASL mechanisms within a single cluster, you can replicate production authentication flows without maintaining separate clusters.\nThe Kafka UI was particularly impressive — being able to produce and consume messages via a GUI interface was a huge productivity boost.\n","wordCount":"1257","inLanguage":"en","image":"https://dingyu.dev/en/posts/local-sasl-kafka/img/kafka.png","datePublished":"2025-03-28T00:00:00Z","dateModified":"2025-03-28T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/local-sasl-kafka/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Running a Local Kafka Cluster with SASL SCRAM Authentication (Docker Compose)</h1><div class=post-description>This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure.</div><div class=post-meta><span title='2025-03-28 00:00:00 +0000 UTC'>March 28, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1257 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/local-sasl-kafka/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/local-sasl-kafka/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/kafka.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#setting-up-local-sasl-mechanism-kafka-cluster-with-docker-compose aria-label="Setting Up Local SASL Mechanism Kafka Cluster with Docker Compose">Setting Up Local SASL Mechanism Kafka Cluster with Docker Compose</a><ul><li><a href=#goals aria-label=Goals>Goals</a></li><li><a href=#why-set-up-a-local-environment aria-label="Why Set Up a Local Environment?">Why Set Up a Local Environment?</a></li><li><a href=#docker-compose-configuration aria-label="Docker Compose Configuration">Docker Compose Configuration</a></li><li><a href=#why-bitnami aria-label="Why Bitnami?">Why Bitnami?</a></li><li><a href=#detailed-component-overview aria-label="Detailed Component Overview">Detailed Component Overview</a><ul><li><a href=#1-zookeeper-initialization aria-label="1. Zookeeper Initialization">1. Zookeeper Initialization</a></li><li><a href=#2-kafka-broker-startup-and-zookeeper-connection aria-label="2. Kafka Broker Startup and Zookeeper Connection">2. Kafka Broker Startup and Zookeeper Connection</a></li><li><a href=#3-controller-election aria-label="3. Controller Election">3. Controller Election</a></li><li><a href=#4-kafka-ui-connection aria-label="4. Kafka UI Connection">4. Kafka UI Connection</a></li><li><a href=#5-event-dispatcher-connection aria-label="5. Event Dispatcher Connection">5. Event Dispatcher Connection</a></li><li><a href=#full-sequence-diagram aria-label="Full Sequence Diagram">Full Sequence Diagram</a></li></ul></li><li><a href=#troubleshooting-and-solutions aria-label="Troubleshooting and Solutions">Troubleshooting and Solutions</a><ul><li><a href=#1-incorrect-kafka_cfg_advertised_listeners aria-label="1. Incorrect KAFKA_CFG_ADVERTISED_LISTENERS">1. Incorrect <code>KAFKA_CFG_ADVERTISED_LISTENERS</code></a></li><li><a href=#2-authentication-failures-with-different-sasl-mechanisms aria-label="2. Authentication Failures with Different SASL Mechanisms">2. Authentication Failures with Different SASL Mechanisms</a></li><li><a href=#3-produce-failures-in-kafka-ui aria-label="3. Produce Failures in Kafka UI">3. Produce Failures in Kafka UI</a></li><li><a href=#4-isr-and-cluster-id-conflicts aria-label="4. ISR and Cluster ID Conflicts">4. ISR and Cluster ID Conflicts</a></li><li><a href=#5-missing-sasl-config-in-producersconsumers aria-label="5. Missing SASL Config in Producers/Consumers">5. Missing SASL Config in Producers/Consumers</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=setting-up-local-sasl-mechanism-kafka-cluster-with-docker-compose>Setting Up Local SASL Mechanism Kafka Cluster with Docker Compose<a hidden class=anchor aria-hidden=true href=#setting-up-local-sasl-mechanism-kafka-cluster-with-docker-compose>#</a></h1><p>When using Kafka with SASL-based authentication, it&rsquo;s important to replicate a similar authentication environment locally for testing.<br>This post documents how to build a Kafka cluster in a local environment that simultaneously supports both <code>SCRAM-SHA-256</code> and <code>SCRAM-SHA-512</code>, and how to test the Event Dispatcher application on top of it.</p><p>It was extremely difficult to find references for setting up <code>SASL</code> and <code>TLS</code> locally&mldr;<br>So while struggling through the setup, I decided to leave this guide as a gift for my future self.</p><p>(<em>TLS setup with Makefile for certificates was a bit too complex, so I&rsquo;ll cover that in a separate post later.</em>)</p><hr><h2 id=goals>Goals<a hidden class=anchor aria-hidden=true href=#goals>#</a></h2><ul><li>The Event Dispatcher consumes events from a <strong>source Kafka</strong> and produces to a <strong>destination Kafka</strong> depending on event types.</li><li><strong>Source</strong> and <strong>Destination</strong> Kafka are on the <strong>same cluster</strong>, but differentiated by <strong>different SASL mechanisms</strong>.</li><li><strong>Source Kafka</strong> uses <strong>SCRAM-SHA-256</strong>, <strong>Destination Kafka</strong> uses <strong>SCRAM-SHA-512</strong>.</li><li>The goal is to replicate the production environment structure without modifying the application code even during tests.</li><li>Kafka cluster has 3 brokers to set ISR (in-sync replicas) to 2.</li><li>Kafka UI should allow manual produce tests to verify application behavior.</li></ul><hr><h2 id=why-set-up-a-local-environment>Why Set Up a Local Environment?<a hidden class=anchor aria-hidden=true href=#why-set-up-a-local-environment>#</a></h2><ul><li>Debugging on a shared dev server was inconvenient because of limited stack trace access and the need to go through VPN/Bastion gateways.</li><li>All internal Kafka clusters use SASL, so creating a reusable setup would benefit many projects.</li><li>Configuration should be modifiable for testing (like transaction settings, exactly-once semantics, ISR tuning) <strong>without code changes</strong> or deployments.</li><li>A local infrastructure was necessary to maintain identical codebases during testing.</li></ul><hr><h2 id=docker-compose-configuration>Docker Compose Configuration<a hidden class=anchor aria-hidden=true href=#docker-compose-configuration>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.9&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_1</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_2</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>zookeeper</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/zookeeper:3.8.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>ALLOW_ANONYMOUS_LOGIN=yes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;2181:2181&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_0_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_0_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_0:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-1</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_1_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_1_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_1:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-2</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_2_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_2:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka-2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-ui</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>provectuslabs/kafka-ui:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-ui</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;8080:8080&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_NAME</span><span class=p>:</span><span class=w> </span><span class=l>Local-Zookeeper-Cluster</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class=p>:</span><span class=w> </span><span class=l>host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.security.scram.ScramLoginModule required username=&#34;${512_SASL_USER}&#34; password=&#34;${512_SASL_PASSWORD}&#34;;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>your-app</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>env_file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>.env</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>context</span><span class=p>:</span><span class=w> </span><span class=l>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>dockerfile</span><span class=p>:</span><span class=w> </span><span class=l>dev.Dockerfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>VERSION=dev</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS_256=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS_512=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>your-app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>your-app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>restart</span><span class=p>:</span><span class=w> </span><span class=l>always</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-2</span><span class=w>
</span></span></span></code></pre></div><hr><h2 id=why-bitnami>Why Bitnami?<a hidden class=anchor aria-hidden=true href=#why-bitnami>#</a></h2><ol><li><strong>Simple User Registration with Environment Variables</strong></li></ol><p>Bitnami Kafka allows automatic SASL user registration simply by setting the following environment variables:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_USERS</span><span class=o>=</span>user256,user512
</span></span><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_PASSWORDS</span><span class=o>=</span>pass256,pass512
</span></span></code></pre></div><p>In contrast, the official Kafka image requires manually running <code>kafka-configs.sh</code> or creating a custom entrypoint.</p><p>Example with official Kafka:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>bash -c <span class=s1>&#39;
</span></span></span><span class=line><span class=cl><span class=s1>/opt/bitnami/scripts/kafka/setup.sh &amp;&amp;
</span></span></span><span class=line><span class=cl><span class=s1>kafka-configs.sh --zookeeper zookeeper:2181 --alter \
</span></span></span><span class=line><span class=cl><span class=s1>    --add-config &#34;SCRAM-SHA-512=[iterations=8192,password=pass]&#34; \
</span></span></span><span class=line><span class=cl><span class=s1>    --entity-type users --entity-name user &amp;&amp;
</span></span></span><span class=line><span class=cl><span class=s1>/opt/bitnami/scripts/kafka/run.sh&#39;</span>
</span></span></code></pre></div><p>Bitnami handles user registration automatically during container startup.</p><ol start=2><li><strong>Built-in SASL and Zookeeper Integration</strong></li></ol><p>Bitnami allows setting SASL and Zookeeper configurations through environment variables without editing <code>server.properties</code>:</p><ul><li><code>KAFKA_CFG_SASL_ENABLED_MECHANISMS</code></li><li><code>KAFKA_CFG_LISTENER_NAME_&lt;listener>_SASL_ENABLED_MECHANISMS</code></li><li><code>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</code></li></ul><table><thead><tr><th>Environment Variable</th><th>Description</th><th>Purpose</th></tr></thead><tbody><tr><td><code>KAFKA_CFG_ZOOKEEPER_CONNECT</code></td><td>Address of Zookeeper (<code>host:port</code>)</td><td>Required for Kafka to store/share cluster metadata</td></tr><tr><td><code>KAFKA_CFG_LISTENERS</code></td><td>Protocol and port for external connections</td><td>Defines how clients and brokers communicate</td></tr><tr><td><code>KAFKA_CFG_ADVERTISED_LISTENERS</code></td><td>Address advertised to clients</td><td>Provides connection info to Kafka clients</td></tr><tr><td><code>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</code></td><td>Maps listener names to security protocols</td><td>Activates SASL authentication</td></tr><tr><td><code>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</code></td><td>Listener used for broker-to-broker communication</td><td>Sets which listener (auth method) is used internally</td></tr><tr><td><code>KAFKA_CFG_SASL_ENABLED_MECHANISMS</code></td><td>List of allowed SASL mechanisms</td><td>Defines available SASL mechanisms</td></tr><tr><td><code>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</code></td><td>SASL mechanism for inter-broker communication</td><td>Selects SCRAM algorithm for internal authentication</td></tr><tr><td><code>KAFKA_CLIENT_USERS</code></td><td>Comma-separated list of users</td><td>Registers users in Kafka</td></tr><tr><td><code>KAFKA_CLIENT_PASSWORDS</code></td><td>Comma-separated list of passwords</td><td>Associates passwords with users</td></tr><tr><td><code>KAFKA_INTER_BROKER_USER</code></td><td>User for inter-broker authentication</td><td>Specifies the user for broker-to-broker SASL authentication</td></tr><tr><td><code>KAFKA_INTER_BROKER_PASSWORD</code></td><td>Password for inter-broker user</td><td>Password for the above user</td></tr></tbody></table><p>The environment includes:</p><ul><li>3-node Bitnami Kafka cluster (supporting both SCRAM-SHA-256 and SCRAM-SHA-512)</li><li>Zookeeper</li><li>Kafka UI for management and testing</li><li>Event Dispatcher application (Kafka Consumer/Producer)</li></ul><p>After setting up the <code>.env</code> file, start the infrastructure with:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker compose --env-file .env up --build
</span></span></code></pre></div><p>To stop and clean up the cluster (including volumes):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker compose down -v
</span></span></code></pre></div><p>Example <code>.env</code> file:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>256_SASL_USER</span><span class=o>=</span>user256
</span></span><span class=line><span class=cl><span class=nv>256_SASL_PASSWORD</span><span class=o>=</span>pass256
</span></span><span class=line><span class=cl><span class=nv>512_SASL_USER</span><span class=o>=</span>user512
</span></span><span class=line><span class=cl><span class=nv>512_SASL_PASSWORD</span><span class=o>=</span>pass512
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kafka Settings</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_0_PORT</span><span class=o>=</span><span class=m>9092</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_1_PORT</span><span class=o>=</span><span class=m>9093</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_2_PORT</span><span class=o>=</span><span class=m>9094</span>
</span></span></code></pre></div><hr><h2 id=detailed-component-overview>Detailed Component Overview<a hidden class=anchor aria-hidden=true href=#detailed-component-overview>#</a></h2><p>The diagram below summarizes how the Kafka cluster, Event Dispatcher, and Kafka UI interact within the local environment. It describes the initialization and authentication sequences based on actual startup logs.</p><h3 id=1-zookeeper-initialization>1. Zookeeper Initialization<a hidden class=anchor aria-hidden=true href=#1-zookeeper-initialization>#</a></h3><ul><li>Zookeeper container starts in standalone mode, acting as metadata storage for Kafka brokers.</li><li>Kafka brokers automatically register SCRAM users via <code>KAFKA_CLIENT_USERS</code> and <code>KAFKA_CLIENT_PASSWORDS</code>.</li><li><code>user256</code> (SCRAM-SHA-256) and <code>user512</code> (SCRAM-SHA-512) are registered in Zookeeper.</li></ul><h3 id=2-kafka-broker-startup-and-zookeeper-connection>2. Kafka Broker Startup and Zookeeper Connection<a hidden class=anchor aria-hidden=true href=#2-kafka-broker-startup-and-zookeeper-connection>#</a></h3><ul><li>Brokers (kafka-0, kafka-1, kafka-2) connect sequentially to Zookeeper.</li><li>Once connected, brokers participate in controller election and become ready to serve requests.</li></ul><h3 id=3-controller-election>3. Controller Election<a hidden class=anchor aria-hidden=true href=#3-controller-election>#</a></h3><ul><li>One broker is elected as the controller.</li><li>The controller synchronizes broker states, partition metadata, and leader elections.</li><li>Messages like <code>LeaderAndIsr</code> and <code>UpdateMetadataRequest</code> are exchanged to stabilize the cluster.</li></ul><h3 id=4-kafka-ui-connection>4. Kafka UI Connection<a hidden class=anchor aria-hidden=true href=#4-kafka-ui-connection>#</a></h3><ul><li>Kafka UI connects to the brokers using <code>user512</code> via SCRAM-SHA-512 authentication.</li><li>After authentication, topics can be browsed, and test messages can be produced.</li></ul><h3 id=5-event-dispatcher-connection>5. Event Dispatcher Connection<a hidden class=anchor aria-hidden=true href=#5-event-dispatcher-connection>#</a></h3><ul><li>Event Dispatcher connects to the source Kafka using SCRAM-SHA-256 (<code>user256</code>) and starts consuming.</li><li>It connects to the destination Kafka using SCRAM-SHA-512 (<code>user512</code>) and produces processed messages.</li></ul><h3 id=full-sequence-diagram>Full Sequence Diagram<a hidden class=anchor aria-hidden=true href=#full-sequence-diagram>#</a></h3><p><img alt="Kafka Cluster Interaction" loading=lazy src=/posts/local-sasl-kafka/image.png></p><hr><h2 id=troubleshooting-and-solutions>Troubleshooting and Solutions<a hidden class=anchor aria-hidden=true href=#troubleshooting-and-solutions>#</a></h2><h3 id=1-incorrect-kafka_cfg_advertised_listeners>1. Incorrect <code>KAFKA_CFG_ADVERTISED_LISTENERS</code><a hidden class=anchor aria-hidden=true href=#1-incorrect-kafka_cfg_advertised_listeners>#</a></h3><p>Initially, setting <code>localhost</code> caused connection failures from Kafka UI and Event Dispatcher.</p><p><strong>Symptoms:</strong></p><ul><li>Kafka UI or Event Dispatcher couldn&rsquo;t connect.</li><li><code>connection refused</code> or <code>EOF</code> errors.</li></ul><p><strong>Solution:</strong></p><ul><li>Use <code>host.docker.internal</code> or the actual host IP instead of <code>localhost</code>.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=o>=</span>PLAINTEXT://host.docker.internal:9092
</span></span></code></pre></div><h3 id=2-authentication-failures-with-different-sasl-mechanisms>2. Authentication Failures with Different SASL Mechanisms<a hidden class=anchor aria-hidden=true href=#2-authentication-failures-with-different-sasl-mechanisms>#</a></h3><p>User registrations weren&rsquo;t properly set for both SCRAM mechanisms.</p><p><strong>Symptoms:</strong></p><ul><li>Kafka UI succeeds, Event Dispatcher fails with <code>EOF</code> or auth error.</li><li>Kafka logs show <code>Failed to authenticate user</code>.</li></ul><p><strong>Solution:</strong></p><ul><li>Ensure users are registered properly using <code>--mechanism</code> option.</li><li>Verify using logs or <code>kafka-configs.sh</code>.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>--entity-type users --entity-name user512 --alter --add-config <span class=s1>&#39;SCRAM-SHA-512=[iterations=4096,password=pass512]&#39;</span>
</span></span></code></pre></div><p>Eventually switched to setting <code>KAFKA_CLIENT_USERS</code> and <code>KAFKA_CLIENT_PASSWORDS</code>.</p><h3 id=3-produce-failures-in-kafka-ui>3. Produce Failures in Kafka UI<a hidden class=anchor aria-hidden=true href=#3-produce-failures-in-kafka-ui>#</a></h3><p>Kafka UI failed to produce messages due to auth or metadata issues.</p><p><strong>Symptoms:</strong></p><ul><li>Produce attempts failed.</li><li>Topic browse failed or auth errors in logs.</li></ul><p><strong>Solution:</strong></p><ul><li>Correctly configure SCRAM authentication in Kafka UI settings.</li><li>Ensure the user uses SCRAM-SHA-512.</li></ul><h3 id=4-isr-and-cluster-id-conflicts>4. ISR and Cluster ID Conflicts<a hidden class=anchor aria-hidden=true href=#4-isr-and-cluster-id-conflicts>#</a></h3><p>Restarting the cluster caused cluster ID mismatch errors.</p><p><strong>Symptoms:</strong></p><ul><li>Broker failed to start or controller election failed.</li><li>Errors like <code>Cluster ID mismatch</code> or <code>log directory is not empty</code>.</li></ul><p><strong>Solution:</strong></p><ul><li>Tear down volumes completely during reset:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker compose down -v
</span></span></code></pre></div><ul><li>If necessary, manually delete <code>kafka_data_*</code> directories.</li></ul><h3 id=5-missing-sasl-config-in-producersconsumers>5. Missing SASL Config in Producers/Consumers<a hidden class=anchor aria-hidden=true href=#5-missing-sasl-config-in-producersconsumers>#</a></h3><p>Producers/Consumers were missing SASL configs.</p><p><strong>Symptoms:</strong></p><ul><li><code>kafka: client has run out of available brokers to talk to</code></li><li>Connection attempts ended with <code>EOF</code>.</li></ul><p><strong>Solution:</strong></p><ul><li>Add SASL settings in <code>.env</code> and client library configs.</li><li>(e.g., for Go clients: set <code>Config.Net.SASL.Mechanism</code> properly)</li></ul><hr><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>As security and authentication become essential in Kafka environments, setting up a SASL-authenticated local cluster is highly valuable.</p><p>By supporting multiple SASL mechanisms within a single cluster, you can replicate production authentication flows without maintaining separate clusters.</p><p>The Kafka UI was particularly impressive — being able to produce and consume messages via a GUI interface was a huge productivity boost.</p><hr></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/en/tags/sasl/>Sasl</a></li><li><a href=https://dingyu.dev/en/tags/bitnami/>Bitnami</a></li><li><a href=https://dingyu.dev/en/tags/kafka-ui/>Kafka Ui</a></li><li><a href=https://dingyu.dev/en/tags/local-test/>Local Test</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/en/posts/distributed-locking/><span class=title>« Prev</span><br><span>[DB] Redlock and Lease in Distributed Systems</span>
</a><a class=next href=https://dingyu.dev/en/posts/dance-with-burrow/><span class=title>Next »</span><br><span>[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[Go] Profiling Worker Pool vs. Async Processing | Ding's Coding Forge</title>
<meta name=keywords content="go,async,sync,pprof"><meta name=description content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/en/posts/worker-pool-async/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/worker-pool-async/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/worker-pool-async/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/en/posts/worker-pool-async/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[Go] Profiling Worker Pool vs. Async Processing"><meta property="og:description" content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-27T00:00:00+00:00"><meta property="article:tag" content="Go"><meta property="article:tag" content="Async"><meta property="article:tag" content="Sync"><meta property="article:tag" content="Pprof"><meta property="og:image" content="https://dingyu.dev/en/posts/worker-pool-async/img/go-thumbnail.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/en/posts/worker-pool-async/img/go-thumbnail.png"><meta name=twitter:title content="[Go] Profiling Worker Pool vs. Async Processing"><meta name=twitter:description content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/en/posts/"},{"@type":"ListItem","position":2,"name":"[Go] Profiling Worker Pool vs. Async Processing","item":"https://dingyu.dev/en/posts/worker-pool-async/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[Go] Profiling Worker Pool vs. Async Processing","name":"[Go] Profiling Worker Pool vs. Async Processing","description":"This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks.","keywords":["go","async","sync","pprof"],"articleBody":"Background Service server refers to a server performing business-specific operations.\n[AS-IS] The service server was publishing individual HTTP events for each occurrence.\nAlthough asynchronous HTTP requests were used, the batch loader’s response time increased linearly with the number of HTTP requests.\nProblems Excessive Network Traffic: Every event triggered an HTTP request, overwhelming the network as event frequency increased. Increased Latency: More requests led to queuing and response delays. Lack of Scalability: Each service implemented batch loading differently. Moving to event streaming would require repetitive changes across servers. [TO-BE] Solutions Reduce Network Traffic: Buffer events internally and batch-send them based on buffer limit or interval. Reduce Latency: Gathered events are sent at fixed intervals, solving the queuing delay. Increase Scalability: Use a shared library to minimize repetitive changes and maintain loose coupling with the batch loader server. Solution A shared library was designed, called “Batch Processor”, to buffer and batch-send events.\nRequirements Minimize IO-bound tasks. Control goroutine lifecycle explicitly. Option 1: Worker Pool Multiple workers buffer internally and synchronously send batched events.\nPros No deep copy overhead. Performance tuning possible by adjusting worker pool size. Cons Up to N HTTP requests every interval (where N = number of workers). Tuning required to find the optimal “magic number” of workers. Option 2: Single Worker + Async HTTP Pros Only one HTTP request per interval. No worker tuning necessary. Cons Potential CPU and memory load from deep copies. Memory overhead may trigger GC, leading to “Stop the World” delays. Option 2 was selected due to superior usability despite potential deep copy overheads.\nProfiling Goals Throughput: Handle 2000 RPS for 1 minute. Memory Usage: Measure overhead from deepCopy(). GC Overhead: Check GC impact during memory copy. func deepCopy[T any](src []T) []T { if src == nil { return nil } dst := make([]T, len(src)) copy(dst, src) return dst } Method Compare 10/100 Worker Pool + Sync IO vs 1 Worker + Async IO.\nCPU profiling enabled. Count processed events by logging inside the API send function. func (q *BatchProcessor) send(payload []byte, traceIDs []string) { response, err := q.client.Do(request) q.logger.Info().Int(\"count\", len(traceIDs)).Send() } CPU Profile selectgo: Go runtime’s internal event selection from multiple channels.\n100 Worker Pool + Sync IO runWithSync() analysis: Overhead from channel locking (sellock) and scheduling (acquireSudog) 85%. 10 Worker Pool + Sync IO Overhead reduced to 66%. 1 Worker + Async IO deepCopy() overhead (runtime.memmove) only 10ms. Runtime and deep copy overhead 50%. Heap Profile Focused on deep copy impact during execution.\nWorker Pool No measurable deep copy overhead. 7.7MB out of 8.2MB used for HTTP requests. Single Worker + Async IO 11.4MB out of 12.21MB used for HTTP requests. Deep copy overhead is 150kB (1.22%), negligible. Test Results Setup Throughput (per minute) CPU Overhead Memory Overhead 10 Worker 83,663 66% 0% 100 Worker 84,042 85% 0% 1 Worker + Async IO 119,720 50% 1.22% Summary Worker Pool introduces significant synchronization overhead. Increasing workers does not linearly increase throughput. Async IO is significantly more efficient for IO-bound tasks. Worker Pools are better for CPU-bound tasks or when strict request ordering is needed. pprof integration:\nFor pprof-based GC tuning, refer to pprof tuning article.\n","wordCount":"521","inLanguage":"en","image":"https://dingyu.dev/en/posts/worker-pool-async/img/go-thumbnail.png","datePublished":"2024-10-27T00:00:00Z","dateModified":"2024-10-27T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/en/posts/worker-pool-async/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/en/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=Translations type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=ko href=https://dingyu.dev/ title=한국어 aria-label=한국어>한국어</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/en/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/en/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[Go] Profiling Worker Pool vs. Async Processing</h1><div class=post-description>This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks.</div><div class=post-meta><span title='2024-10-27 00:00:00 +0000 UTC'>October 27, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;521 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://dingyu.dev/posts/worker-pool-async/>Ko</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/worker-pool-async/index.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/go-thumbnail.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#background aria-label=Background>Background</a><ul><li><a href=#as-is aria-label=[AS-IS]>[AS-IS]</a><ul><li><a href=#problems aria-label=Problems>Problems</a></li></ul></li><li><a href=#to-be aria-label=[TO-BE]>[TO-BE]</a><ul><li><a href=#solutions aria-label=Solutions>Solutions</a></li></ul></li></ul></li><li><a href=#solution aria-label=Solution>Solution</a><ul><ul><li><a href=#requirements aria-label=Requirements>Requirements</a></li><li><a href=#option-1-worker-pool aria-label="Option 1: Worker Pool">Option 1: Worker Pool</a><ul><li><a href=#pros aria-label=Pros>Pros</a></li><li><a href=#cons aria-label=Cons>Cons</a></li></ul></li><li><a href=#option-2-single-worker--async-http aria-label="Option 2: Single Worker + Async HTTP">Option 2: Single Worker + Async HTTP</a><ul><li><a href=#pros-1 aria-label=Pros>Pros</a></li><li><a href=#cons-1 aria-label=Cons>Cons</a></li></ul></li></ul></ul></li><li><a href=#profiling aria-label=Profiling>Profiling</a><ul><li><a href=#goals aria-label=Goals>Goals</a></li><li><a href=#method aria-label=Method>Method</a></li><li><a href=#cpu-profile aria-label="CPU Profile">CPU Profile</a><ul><ul><li><a href=#100-worker-pool--sync-io aria-label="100 Worker Pool + Sync IO">100 Worker Pool + Sync IO</a></li><li><a href=#10-worker-pool--sync-io aria-label="10 Worker Pool + Sync IO">10 Worker Pool + Sync IO</a></li><li><a href=#1-worker--async-io aria-label="1 Worker + Async IO">1 Worker + Async IO</a></li></ul></ul></li><li><a href=#heap-profile aria-label="Heap Profile">Heap Profile</a><ul><ul><li><a href=#worker-pool aria-label="Worker Pool">Worker Pool</a></li><li><a href=#single-worker--async-io aria-label="Single Worker + Async IO">Single Worker + Async IO</a></li></ul></ul></li></ul></li><li><a href=#test-results aria-label="Test Results">Test Results</a><ul><li><a href=#summary aria-label=Summary>Summary</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h1><blockquote><p><strong>Service server</strong> refers to a server performing business-specific operations.</p></blockquote><h2 id=as-is>[AS-IS]<a hidden class=anchor aria-hidden=true href=#as-is>#</a></h2><p>The service server was publishing individual HTTP events for each occurrence.</p><p>Although asynchronous HTTP requests were used, the batch loader&rsquo;s response time increased linearly with the number of HTTP requests.</p><p><img loading=lazy src=/posts/worker-pool-async/image-1.png></p><h3 id=problems>Problems<a hidden class=anchor aria-hidden=true href=#problems>#</a></h3><ol><li><strong>Excessive Network Traffic</strong>: Every event triggered an HTTP request, overwhelming the network as event frequency increased.</li><li><strong>Increased Latency</strong>: More requests led to queuing and response delays.</li><li><strong>Lack of Scalability</strong>: Each service implemented batch loading differently. Moving to event streaming would require repetitive changes across servers.</li></ol><h2 id=to-be>[TO-BE]<a hidden class=anchor aria-hidden=true href=#to-be>#</a></h2><p><img loading=lazy src=/posts/worker-pool-async/image-2.png></p><h3 id=solutions>Solutions<a hidden class=anchor aria-hidden=true href=#solutions>#</a></h3><ol><li><strong>Reduce Network Traffic</strong>: Buffer events internally and batch-send them based on buffer limit or interval.</li><li><strong>Reduce Latency</strong>: Gathered events are sent at fixed intervals, solving the queuing delay.</li><li><strong>Increase Scalability</strong>: Use a shared library to minimize repetitive changes and maintain <strong>loose coupling</strong> with the batch loader server.</li></ol><hr><h1 id=solution>Solution<a hidden class=anchor aria-hidden=true href=#solution>#</a></h1><blockquote><p>A shared library was designed, called <strong>&ldquo;Batch Processor&rdquo;</strong>, to buffer and batch-send events.</p></blockquote><h3 id=requirements>Requirements<a hidden class=anchor aria-hidden=true href=#requirements>#</a></h3><ul><li>Minimize <strong>IO-bound tasks</strong>.</li><li><strong>Control goroutine lifecycle</strong> explicitly.</li></ul><h3 id=option-1-worker-pool>Option 1: Worker Pool<a hidden class=anchor aria-hidden=true href=#option-1-worker-pool>#</a></h3><p><img loading=lazy src=/posts/worker-pool-async/image-3.png></p><p>Multiple workers buffer internally and synchronously send batched events.</p><h4 id=pros>Pros<a hidden class=anchor aria-hidden=true href=#pros>#</a></h4><ul><li>No deep copy overhead.</li><li>Performance tuning possible by adjusting worker pool size.</li></ul><h4 id=cons>Cons<a hidden class=anchor aria-hidden=true href=#cons>#</a></h4><ul><li>Up to N HTTP requests every interval (where N = number of workers).</li><li>Tuning required to find the optimal &ldquo;magic number&rdquo; of workers.</li></ul><h3 id=option-2-single-worker--async-http>Option 2: Single Worker + Async HTTP<a hidden class=anchor aria-hidden=true href=#option-2-single-worker--async-http>#</a></h3><p><img loading=lazy src=/posts/worker-pool-async/image-4.png></p><h4 id=pros-1>Pros<a hidden class=anchor aria-hidden=true href=#pros-1>#</a></h4><ul><li>Only one HTTP request per interval.</li><li>No worker tuning necessary.</li></ul><h4 id=cons-1>Cons<a hidden class=anchor aria-hidden=true href=#cons-1>#</a></h4><ul><li>Potential CPU and memory load from deep copies.</li><li>Memory overhead may trigger GC, leading to &ldquo;Stop the World&rdquo; delays.</li></ul><p><strong>Option 2</strong> was selected due to superior usability despite potential deep copy overheads.</p><h1 id=profiling>Profiling<a hidden class=anchor aria-hidden=true href=#profiling>#</a></h1><h2 id=goals>Goals<a hidden class=anchor aria-hidden=true href=#goals>#</a></h2><ul><li><strong>Throughput</strong>: Handle 2000 RPS for 1 minute.</li><li><strong>Memory Usage</strong>: Measure overhead from <code>deepCopy()</code>.</li><li><strong>GC Overhead</strong>: Check GC impact during memory copy.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nx>deepCopy</span><span class=p>[</span><span class=nx>T</span> <span class=kt>any</span><span class=p>](</span><span class=nx>src</span> <span class=p>[]</span><span class=nx>T</span><span class=p>)</span> <span class=p>[]</span><span class=nx>T</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>src</span> <span class=o>==</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>nil</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nx>dst</span> <span class=o>:=</span> <span class=nb>make</span><span class=p>([]</span><span class=nx>T</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=nx>src</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>copy</span><span class=p>(</span><span class=nx>dst</span><span class=p>,</span> <span class=nx>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nx>dst</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><p>Compare <strong>10/100 Worker Pool + Sync IO</strong> vs <strong>1 Worker + Async IO</strong>.</p><ul><li>CPU profiling enabled.</li><li>Count processed events by logging inside the API send function.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>q</span> <span class=o>*</span><span class=nx>BatchProcessor</span><span class=p>)</span> <span class=nf>send</span><span class=p>(</span><span class=nx>payload</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>traceIDs</span> <span class=p>[]</span><span class=kt>string</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>response</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>q</span><span class=p>.</span><span class=nx>client</span><span class=p>.</span><span class=nf>Do</span><span class=p>(</span><span class=nx>request</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nx>q</span><span class=p>.</span><span class=nx>logger</span><span class=p>.</span><span class=nf>Info</span><span class=p>().</span><span class=nf>Int</span><span class=p>(</span><span class=s>&#34;count&#34;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=nx>traceIDs</span><span class=p>)).</span><span class=nf>Send</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=cpu-profile>CPU Profile<a hidden class=anchor aria-hidden=true href=#cpu-profile>#</a></h2><blockquote><p><strong>selectgo</strong>: Go runtime&rsquo;s internal event selection from multiple channels.</p></blockquote><h4 id=100-worker-pool--sync-io>100 Worker Pool + Sync IO<a hidden class=anchor aria-hidden=true href=#100-worker-pool--sync-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-5.png></p><ul><li><code>runWithSync()</code> analysis:<ul><li>Overhead from channel locking (<code>sellock</code>) and scheduling (<code>acquireSudog</code>) <strong>85%</strong>.</li></ul></li></ul><h4 id=10-worker-pool--sync-io>10 Worker Pool + Sync IO<a hidden class=anchor aria-hidden=true href=#10-worker-pool--sync-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-6.png></p><ul><li>Overhead reduced to <strong>66%</strong>.</li></ul><h4 id=1-worker--async-io>1 Worker + Async IO<a hidden class=anchor aria-hidden=true href=#1-worker--async-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-7.png></p><ul><li><code>deepCopy()</code> overhead (runtime.memmove) only 10ms.</li><li>Runtime and deep copy overhead <strong>50%</strong>.</li></ul><h2 id=heap-profile>Heap Profile<a hidden class=anchor aria-hidden=true href=#heap-profile>#</a></h2><blockquote><p>Focused on deep copy impact during execution.</p></blockquote><h4 id=worker-pool>Worker Pool<a hidden class=anchor aria-hidden=true href=#worker-pool>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-8.png></p><ul><li>No measurable deep copy overhead.</li><li>7.7MB out of 8.2MB used for HTTP requests.</li></ul><h4 id=single-worker--async-io>Single Worker + Async IO<a hidden class=anchor aria-hidden=true href=#single-worker--async-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-9.png></p><ul><li>11.4MB out of 12.21MB used for HTTP requests.</li><li>Deep copy overhead is <strong>150kB (1.22%)</strong>, negligible.</li></ul><h1 id=test-results>Test Results<a hidden class=anchor aria-hidden=true href=#test-results>#</a></h1><table><thead><tr><th>Setup</th><th>Throughput (per minute)</th><th>CPU Overhead</th><th>Memory Overhead</th></tr></thead><tbody><tr><td>10 Worker</td><td>83,663</td><td>66%</td><td>0%</td></tr><tr><td>100 Worker</td><td>84,042</td><td>85%</td><td>0%</td></tr><tr><td>1 Worker + Async IO</td><td>119,720</td><td>50%</td><td>1.22%</td></tr></tbody></table><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><ul><li>Worker Pool introduces significant synchronization overhead.</li><li>Increasing workers does not linearly increase throughput.</li><li><strong>Async IO is significantly more efficient for IO-bound tasks.</strong></li><li><strong>Worker Pools</strong> are better for CPU-bound tasks or when strict request ordering is needed.</li></ul><blockquote><p><strong>pprof integration:</strong><br>For pprof-based GC tuning, refer to <a href=https://dingyu.dev/posts/go-pprof-gc/>pprof tuning article</a>.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/en/tags/go/>Go</a></li><li><a href=https://dingyu.dev/en/tags/async/>Async</a></li><li><a href=https://dingyu.dev/en/tags/sync/>Sync</a></li><li><a href=https://dingyu.dev/en/tags/pprof/>Pprof</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/en/posts/gopher-con-2024-kubernetes-programing/><span class=title>« Prev</span><br><span>[Go] Gophercon 2024 - Kubernetes Platform Programming</span>
</a><a class=next href=https://dingyu.dev/en/posts/coffee-pal/><span class=title>Next »</span><br><span>[DX] Building a Slack Bot for Internal Coffee Chats</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/en/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
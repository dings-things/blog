<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Async on Ding&#39;s Coding Forge</title>
    <link>https://dingyu.dev/en/tags/async/</link>
    <description>Recent content in Async on Ding&#39;s Coding Forge</description>
    <image>
      <title>Ding&#39;s Coding Forge</title>
      <url>https://dingyu.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://dingyu.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.144.0</generator>
    <language>en</language>
    <lastBuildDate>Tue, 20 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://dingyu.dev/en/tags/async/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[Go] Is It Okay to Run 100 Million Goroutines?</title>
      <link>https://dingyu.dev/en/posts/gmp/</link>
      <pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate>
      <guid>https://dingyu.dev/en/posts/gmp/</guid>
      <description>Based on Go&amp;#39;s runtime scheduling model (GMP), this article provides an in-depth analysis of how goroutine parking (`gopark`) and wake-up (`goready`) actually work. It examines various blocking scenarios—such as channels, mutexes, and I/O—and explains how goroutines are parked, when new Ms (OS threads) are spawned, and what performance issues may arise when too many goroutines accumulate in a parked state.</description>
    </item>
    <item>
      <title>[Go] Profiling Worker Pool vs. Async Processing</title>
      <link>https://dingyu.dev/en/posts/worker-pool-async/</link>
      <pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://dingyu.dev/en/posts/worker-pool-async/</guid>
      <description>This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks.</description>
    </item>
  </channel>
</rss>

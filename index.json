[{"content":"본 글은\u0026hellip; 아래 질문에 대한 궁금증으로 작성하게 되었습니다. 만약 초당 수천만건의 API 요청이 들어오며, 해당 API가 외부 API로 통신하는 환경에서 외부 API의 응답이 10초라면 서버는 어떻게 되는가?\n⨳ TCP connection timeout은 별도로 설정되어 있지 않다고 가정한다\n고루틴이 무엇인가? 고루틴을 흔히 경량 스레드라고 부른다\u0026hellip; 그래서 스레드인데 메모리만 낮은 스레드라는 건가?\n고루틴의 장점 낮은 컨텍스트 스위칭 비용 하드웨어가 발전함에 따라 이를 효율적으로 사용하기 위해 *_멀티스레딩_과 *멀티태스킹 개념이 등장한다.\n멀티스레딩 : 하나의 프로세스 안에서 여러 스레드 실행\n멀티태스킹 : 여러 작업을 동시에 실행되는 것처럼 보여줌\n타 언어(C/C++/Java) Go언어 Go 런타임은 커널 수준의 TCB(Task Control Block)를 직접 스위칭하지 않고, 자체적인 G(고루틴), M(OS Thread), P(Scheduler Context)를 활용한 경량 컨텍스트 스위칭을 수행한다\n생성 및 소멸 비용 OS Thread를 생성하고 모두 사용한 뒤에 소멸하는 작업은 높은 비용을 요구한다. 이러한 비용 지불을 매번 하지 않기 위해 스레드 풀을 사용하기도 한다\nGo언어에서는 어떨까?\nGo 런타임의 GMP 모델 M이 바로 OS Thread에 해당된다. P(processor)가 M과 연결되어 고루틴이 수행되는 과정에서 M 또한 새롭게 생성되거나 소멸될 수 있다.\n하지만 이는 go 런타임 스케쥴러에 의해 최적화되기에 일반적인 프로그래밍 언어에 비해 훨씬 저비용으로 관리가 가능해진다\n적은 메모리 소비 스레드로 생성할 경우, 스레드 간 메모리 보호 역할을 하는 공간을 포함하여 1MB 정도의 스택을 필요로 한다.\n반면에 고루틴은 2KB의 스택만 필요하기에 엄청난 경량 효과를 보게 된다 (물론 어떤 코드를 고루틴으로 돌리느냐에 따라, 메모리가 추가적인 할당이 필요함. 이는 다른 언어도 마찬가지)\n수치로 비교하자면 다음과 같다\n언어 기본 실행 단위 기본 스택 크기 총 메모리 소비 추정 C/C++ pthread 8MB 약 8MB 이상 Java java.lang.Thread 1MB 약 1MB 이상 Go goroutine (G) 2KB (초기) 수 KB 수준 GMP Go런타임은 모든 고루틴을 다중화된 스레드들에 할당하고 모니터링하며, 효율적으로 최적화된 스케쥴링을 진행한다. 구성 요소는 다음과 같다. 자세한 구조체는 runtime.runtime2.go 참고\n구성 요소 의미 역할 주요 정보 G (Goroutine) 고루틴 실행 단위 스택 포인터, 고루틴 상태 등 컨텍스트 정보 보유/LRQ 또는 GRQ에 대기 M (Machine) OS 스레드 고루틴 실행 실행 중인 고루틴(G), 연결된 P, 스레드 핸들 정보 보유 P (Processor) 논리 프로세서 고루틴 스케줄링 최대 GOMAXPROCS 개 존재/자신의 LRQ로부터 G를 POP하여 M에 할당 LRQ (Local Run Queue) 지역 실행 큐 고루틴 큐 (P별) 각 P에 하나씩 존재G를 M에 할당/경쟁 조건 줄이기 용이 GRQ (Global Run Queue) 글로벌 실행 큐 고루틴 큐 (공용) 모든 P가 공유/LRQ가 가득 찼거나 실행 시간 초과된 G가 들어감 P (Processor) P는 기본값으로 GOMAXPROCS=(CPU Core)를 가짐 P는 하나의 M에 할당되며 각 P는 자신의 Local Run Queue를 지님 P는 G의 context 정보를 갖는다 findRunnable()을 호출하여 다음 실행 될 G를 결정함 [runtime/proc.go]\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) { mp := getg().m pp := mp.p.ptr() // local runq if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, false } // global runq if sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(pp, 0) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } } // Poll network. if netpollinited() \u0026amp;\u0026amp; netpollAnyWaiters() \u0026amp;\u0026amp; sched.lastpoll.Load() != 0 { if list, delta := netpoll(0); !list.empty() { gp := list.pop() injectglist(\u0026amp;list) netpollAdjustWaiters(delta) casgstatus(gp, _Gwaiting, _Grunnable) return gp, false, false } } // Spinning Ms: steal work from other Ps. if mp.spinning || 2*sched.nmspinning.Load() \u0026lt; gomaxprocs-sched.npidle.Load() { if !mp.spinning { mp.becomeSpinning() } gp, inheritTime, _, _, _ := stealWork(nanotime()) if gp != nil { return gp, inheritTime, false } } // fallback: no G found return nil, false, false } 순서 소스 설명 사용 상황 ① Local Run Queue (LRQ) P마다 존재하는 고유 큐 가장 빠르고 비용이 적음 → 우선 선택 대상 ② Global Run Queue (GRQ) 모든 P가 공유하는 큐 LRQ가 비어있을 때 fallback ③ Network Poller (Netpoll) epoll/kqueue/I/O 이벤트로 wake-up된 G들 네트워크 I/O 완료 후 G를 되살리는 역할 ④ Work Stealing (다른 P의 LRQ) 다른 P의 LRQ에서 G를 훔쳐옴 자신이 빈 상태이고 GRQ도 비어 있을 때 수행 그럼 자연스럽게 이런 생각이 들 것이다..\nI/O 작업을 하는 경우 LRQ와 GRQ가 모두 소비된 후에야 처리될 수 있을까? 우선 아니다. 대표적으로 아래 경우에 netpoll queue에서 GRQ로 inject 된다\n*sysmon() 시스템 모니터 내부\nsysmon : 독립적으로 백그라운드에서 반복 실행하며, P/M/Netpoll 하여 스케쥴링\n[runtime/proc.go]\nfunc sysmon() { for { ... if netpollinited() { list, _ := netpoll(0) // 비차단 injectglist(\u0026amp;list) } ... } } Blocking 작업 완료 후, G는 어떻게 다시 P에게 돌아가는가? 하나의 P(processor)에서 goroutine 스위칭 과정이다\nG1은 syscall을 수행하는 고루틴이다 (ex. HTTPRequest)\n단계 설명 ① G1이 syscall 진입 net.Read() 호출 ② M1은 syscall에 block entersyscall() 호출, P1 분리됨 ③ P1은 M2에게 전달됨 M2가 idle 상태거나 newm()으로 새로 생성됨 ④ M2는 G2를 선택하고 실행 P1의 run queue에서 G2를 선택해 실행 ⑤ OS에서 syscall 완료 감지 epoll, kqueue, IOCP 등에 의해 ⑥ netpoller가 G1을 runnable로 마킹 G1.status = _Grunnable, run queue에 다시 등록 ⑦ 스케줄러가 적절한 시점에 G1을 재실행 이후 schedule()에서 G1이 선택되면 재개됨 findRunnable에서 Runnable한 Goroutine이 없다면? 현재 M(OS thread)은 더 이상 실행할 G가 없음 stopm() 호출 → 현재 M은 park M이 보유하던 P는 releasep()를 통해 반납됨 반납된 P는 idle P 큐에 들어감 GOMAXPROCS 개수만큼 생성된 P는 사라지지 않고 idle 상태 유지 새로운 runnable G가 나타나면, idle한 P를 다시 획득하여 실행 재개 M도 필요 시 다시 생성되거나 idle M을 재사용 M (Machine) M은 G를 받아 실제 수행을 수행하는 OS Thread이다 maxcount는 기본값으로 10000 앞선 P가 Blocking 작업 고루틴으로 수행하는 경우 M1의 운명은? (syscall 실행 이후의 흐름)\n[runtime/proc.go]\nfunc exitsyscall() { gp := getg() // Validate syscall stack frame if sys.GetCallerSP() \u0026gt; gp.syscallsp { throw(\u0026#34;exitsyscall: syscall frame is no longer valid\u0026#34;) } gp.waitsince = 0 oldp := gp.m.oldp.ptr() gp.m.oldp = 0 // Fast path: try to reacquire P and resume execution // if P is IDLE, return true and resume running goroutine if exitsyscallfast(oldp) { ... casgstatus(gp, _Gsyscall, _Grunning) // mark G as running return } // Slow path: failed to reacquire P // Call scheduler (park M and let scheduler run G later) mcall(exitsyscall0) } 조건 처리 P를 reacquire 가능 G1 즉시 실행 (execute(g)) P를 못 얻음 G1은 runnable로 enqueue, M1은 stop (stopm()) M이 많고 idle M1은 완전히 종료될 수도 있음 M이 부족하면서 idle M1은 다시 사용될 수도 있음 (newm() 피함) 다른 언어에서의 M(OS Thread)을 통한 멀티스레딩 매 요청마다 1개의 OS 스레드를 생성하고, 해당 스레드에서 epoll_wait/syscall 수행 N개의 워커 스레드를 만들어 각기 epoll_wait 또는 read 처리 Cons 1000개의 동시 요청을 처리하려면 최대 1000개의 스레드가 필요 각각의 M(epoll_wait)은 syscall blocking이므로 context switch 발생 *캐시 미스, 커널 진입 비용, 스케줄링 오버헤드 등이 급증 캐시 미스 : Context Switch 이후, CPU 캐시에서 자신의 데이터가 없음 → 메모리에서 다시 로드 (느림)\nNetpoller M Netpoller M은 Go 런타임이 하나만 유지하는 전용 OS 쓰레드(M)로, epoll/kqueue 등의 커널 I/O readiness 감시 시스템과 연결되어 있다\n고루틴들이 non-blocking I/O(fd)를 사용할 때, 해당 fd의 readable/writable 상태를 감시하는 역할만 전담 하나의 M만으로 수천 개의 fd를 감시, 적은 자원으로 수많은 I/O 고루틴을 효율적으로 처리 두 개의 syscall을 포함하는 고루틴과 Netpoller M의 flow\n왜 M이 바로 syscall 하면 안되는 거죠? Example : G1이 TCP 소켓을 통해 conn.Read()를 호출했다고 가정 만약 상대방이 갑자기 죽거나, NAT 타임아웃 등으로 연결이 끊겼는데도 커널에서 EOF 신호를 전달하지 않는다면?\nread(fd) syscall은 영원히 반환되지 않는다 (block 상태 지속) G1을 실행한 M은 syscall에서 block 해당 M이 보유한 P도 함께 릴리즈되면서 전체 병렬성에 영향 이러한 이유로 Go는 고루틴이 syscall 전에 fd의 readiness를 epoll 등을 통해 확인하고, 실제 read()는 ready일 때만 호출한다\n왜 Netpoller M이 전담해서 epoll하나요? Example : 1000개의 M이 각자 epoll_wait(fd)를 호출\n1000개가 제각각 epoll_wait() epoll 또한 syscall로, 커널-유저 전환 오버헤드 존재 얼마의 주기로 epoll 할것인가? polling interval도 추가로 고려해야 함 G (Goroutine) Goroutine 스케쥴링 고루틴이 어떠한 흐름으로 실행되는지 살펴봅시다\ngo dosomething()을 통해 신규 고루틴을 생성하게 되었습니다.\n현재 상태\nLRQ가 가득 참 신규 고루틴 생성됨 신규 고루틴(G0)이 생성되어 좌측 P에게 LRQ의 공간이 있는지 확인한다 현재 P의 LRQ가 full인 상태이다 (실제 상황에서는 lrq size = 256) 기존 LRQ의 반을 GRQ에 삽입한다 (G2 → GRQ) G0은 P가 비었기 때문에 LRQ로 삽입된다 G1이 수행되고 G0이 runnext에 위치한다 LRQ가 비었으므로 GRQ에서 고루틴을 가져온다 (global runqueue의 현재 길이/GOMAXPROCS + 1 만큼) G0은 M에서 실행되며 소켓에 요청을 전송한다 G0은 epoll_ctl(..., EPOLLIN)을 통해 readiness 등록한다 blocking 되지 않도록 기존 P와 연결을 끊는다 Netpoller M은 epoll_wait을 통해 readiness fd를 확인한다 M은 IDLE 상태로 돌아가며 G0은 Gopark로 대기한다 (이후 스케쥴러에 의해 삭제 혹은 P와 다시 맺어줌) Netpoller M은 G0 fd의 readiness fd를 확인한다 Netpoller M은 G0 fd의 readiness를 확인하고 Goready 상태로 전환한다 P는 LRQ와 GRQ에서 G를 찾지만 더이상 소비할 G가 없다 P는 netpoll으로 Ready 상태인 G를 바로 가져와 실행한다 몇몇 유의사항 GRQ Starvation LRQ만 계속 확인하고 GRQ polling이 일어나지 않을 수 있다. schedTick 변수가 존재하여, 61번의 polling이 일어날 때마다 LRQ → GRQ 순으로 확인하지 않고 GRQ를 먼저 확인하여 polling한다. schedTick 값이 61인 이유는 일단 실험적으로 성능이 좋았던 값의 범위 안에서 prime number를 고른 것이다. prime number를 사용한 이유는 hash map에서 균일 분포를 위해 prime length를 사용하던 것과 마찬가지로 어플리케이션 패턴과의 충돌을 피하기 위함이다. [runtime/proc.go]\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) { mp := getg().m pp := mp.p.ptr() // Check the global runnable queue once in a while to ensure fairness // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. if pp.schedtick%61 == 0 \u0026amp;\u0026amp; !sched.runq.empty() { lock(\u0026amp;sched.lock) gp := globrunqget() unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } } // local runq if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, false } ... } Time slice based preemption 하나의 고루틴이 프로세서를 오래 점유하는 것을 막기 위해 기본 10ms의 time slice가 정의되어 시간을 넘겼을 때 실행 중이던 고루틴은 preempted되어 GRQ로 들어간다.\n[runtime/proc.go]\nfunc sysmon() { ... for { ... lock(\u0026amp;sched.sysmonlock) now = nanotime() ... // retake P\u0026#39;s blocked in syscalls // and preempt long running G\u0026#39;s if retake(now) != 0 { idle = 0 } else { idle++ } ... unlock(\u0026amp;sched.sysmonlock) } } 수천만건의 네트워크 I/O를 수행하는 작업이 있는 경우 어떻게 되는가? Go의 고루틴은 경량 컨텍스트 스위칭, 작은 메모리 점유, epoll 기반의 네트워크 폴링 구조 덕분에 대규모 네트워크 I/O 환경에서도 효율적으로 작동할 수 있다.\n그러나 외부 API의 응답이 매우 느린 경우 (예: 10초), 그리고 초당 수천만 건의 요청이 쏟아지는 상황에서는 몇 가지 중요한 병목과 리스크가 발생할 수 있다.\n발생 가능 에러 케이스 1. 고루틴 수의 폭발적 증가 모든 요청이 외부 API 호출을 포함하고 있고, 이 API가 10초 이상 block 된다면, 10초 동안 고루틴이 대기 상태로 남음 초당 1,000만 건의 요청이 들어오고 10초 응답이라면, 최대 1억 개의 고루틴이 동시에 존재 고루틴 하나당 초기 스택이 2KB라고 가정해도, 1억 × 2KB ≒ 200GB 이상의 메모리를 소비 고루틴 수가 너무 많아지면 시스템 메모리가 고갈 2. file descriptor(fd) 수 제한 외부 API와 통신하는 각 요청은 TCP 연결을 맺기 때문에, OS는 각각의 fd를 유지 리눅스에서는 기본적으로 ulimit -n(open files 수)이 수천~수만 개로 제한됨 초당 수천만 건의 연결 요청은 결국 fd exhaustion 문제로 새로운 네트워크 요청이 실패하게 됨 고루틴 1억 개 돌려도 괜찮을까? 테스트 func init() { http.HandleFunc(\u0026#34;/slow\u0026#34;, func(w http.ResponseWriter, r *http.Request) { time.Sleep(10 * time.Second) }) go func() { log.Println(\u0026#34;slow API server start in :18080\u0026#34;) http.ListenAndServe(\u0026#34;:18080\u0026#34;, nil) }() } func main() { // ===== trace start ===== traceFile, err := os.Create(\u0026#34;trace.out\u0026#34;) if err != nil { log.Fatalf(\u0026#34;trace file creation failed: %v\u0026#34;, err) } if err := trace.Start(traceFile); err != nil { log.Fatalf(\u0026#34;trace start failed: %v\u0026#34;, err) } defer func() { trace.Stop() traceFile.Close() }() // ===================== startProfiler() // start profiler for i := 0; i \u0026lt; 100000000; i++ { go func(i int) { client := \u0026amp;http.Client{} resp, err := client.Get(\u0026#34;http://localhost:18080/slow\u0026#34;) if err != nil { fmt.Printf(\u0026#34;[%d] Error: %v\\n\u0026#34;, i, err) return } io.Copy(io.Discard, resp.Body) resp.Body.Close() }(i) if i%100000 == 0 { fmt.Printf( \u0026#34;Current Request Count: %d, Goroutine Count: %d\\n\u0026#34;, i, runtime.NumGoroutine(), ) } } select {} // wait forever (trace cancels from defer) } fd 재사용을 막기 위해 http.Client를 매번 생성하여 HTTP 요청 API 서버에서는 10초의 delay가 있다고 가정 heap / cpu 프로파일링 활성화 heap profile net/http.(*Transport).getConn\n내부적으로 HTTP connection pool을 관리하면서, 새로운 연결을 만들거나 재사용하는 함수 connection을 재사용하지 못함 → 계속 dial → new FD → getConn → heap 사용 증가 runtime.malg\nGo 런타임이 고루틴을 생성할 때 사용하는 stack 및 G 구조체 메모리 서버 응답을 기다리는 Waiting 상태의 고루틴 증가 → GC는 사용 중인 goroutine stack을 해제할 수 없음 → runtime.malg 급증 cpu profile runtime.cgocall\nGo에서 C 코드 또는 시스템 호출 (syscall) 을 실행할 때 사용되는 내부 함수 수많은 고루틴이 동시에 http.Client.Get()을 호출 → 각 요청마다 새로운 연결을 시도 → 네트워크 syscall 폭주 runtime.(*timers).adjust\nGo의 타이머 시스템은 내부적으로 min heap 기반으로 동작 테스트 코드 중, time.Sleep이 각 고루틴 별로 수행 → 수십만 개의 타이머가 힙에 삽입되어 힙 정렬 (adjust) 연산이 반복 정리하자면, blocking 되는 처리를 대기하는 고루틴이 무한히 증가하면? → 종료되지 않은 고루틴의 Heap 점유 → OOM으로 Server Down\n번외로 동일한 커넥션을 만들도록 설정하더라도\u0026hellip;\nfunc main() { ... client := \u0026amp;http.Client{ Transport: \u0026amp;http.Transport{ MaxIdleConns: 10000, // 전체 idle 연결 수 MaxIdleConnsPerHost: 10000, // 호스트당 idle 연결 수 IdleConnTimeout: 90 * time.Second, DisableKeepAlives: false, }, Timeout: 30 * time.Second, } for i := 0; i \u0026lt; 100000000; i++ { go func(i int) { ... }(i) ... } select {} // wait forever (trace cancels from defer) } OOM으로 인해 Server Down된다 waiting 중인 goroutine의 heap 점유 connection pool을 초과하는 경우, new connection → getConn → heap 사용 증가 runnable 상태의 goroutine의 스케쥴링 과정에서 CPU 폭주 REFS Dmitry Vtukov GopherCon 2021: Madhav Jivrajani - Queues, Fairness, and The Go Scheduler ","permalink":"https://dingyu.dev/posts/gmp/","summary":"고루틴은 Go 언어의 대표적인 장점 중 하나로, 수십만 개 이상을 생성해도 가볍다고 알려져 있다. 그러나, 이 고루틴들이 파킹(parking) 상태로 계속 쌓인다면 실제로 어떤 문제가 발생할 수 있을까?본 고루틴 파킹의 동작 원리와 Go 런타임(GMP)의 내부 구조를 바탕으로, 고루틴이 실행되지 않고 대기 상태로 많아질 때 시스템이 받는 부하와 성능 영향, 그리고 이를 감지하고 예방하는 실전 전략을 설명한다.","title":"[Go] 고루틴 1억 개 돌려도 괜찮을까?"},{"content":"배경 참여하고 있는 스터디에서 동료가 어느날 Redlock과 관련된 세션을 소개해주셨다.\n너무 좋은 컨텐츠여서 욕심나기에.. 나만의 이해로 더 깊게 파고 들까한다.\nRedlock 알고리즘을 보고 오면 좋을 것 같다.\nLock for what? 주요하게는 효율성과 정확성을 보장하기 위해 Lock을 사용한다\nEfficiency 불필요하게 중복된 작업 수행을 막을 수 있다\nex. N개의 노드에서 동일한 무거운 작업(10분 소요)을 수행 → 비용적/시간적 낭비 Correctness 동시 프로세스가 동일한 공유 자원에 대해 일관되고 정확한 데이터 처리가 가능\nex. N개의 노드에서 사용자의 출금 로직 수행 → 사용자 계좌의 N*요금 만큼 차감 Martin Kleppmann에 따르면 효율성을 위해 Redis Lock을 고려 중이라면 Redlock은 사용하지 않는 것을 추천한다.\n항목 싱글 Redis Lock Redis Redlock 알고리즘 락 획득 대상 하나의 Redis 인스턴스 5개의 독립된 Redis 인스턴스 락 생성 방법 SET key value NX PX \u0026lt;TTL\u0026gt; 5개 노드 각각에 SET key value NX PX \u0026lt;TTL\u0026gt; 시도 성공 조건 단일 Redis에서 락 획득 성공 5개 중 3개 이상 서버(majority) 락 획득 성공 장애 대응성 Redis 서버 장애 시 락 정보 소실 일부 서버 장애에도 majority 락이 유지되면 안전 Split Brain (네트워크 분할) 대응 불가능 일부 방어 가능 (단, 완전하지 않음) 일관성(Consistency) 단일 인스턴스 기반 (약한 일관성) 락을 획득하는 동안 일관성 강화 (multi-instance) 복잡도 단순 (구현 쉬움) 복잡 (락 취득 시간, clock drift 고려 필요) Fault Tolerance 낮음 상대적으로 높음 성능 빠름 (단일 노드 접근) 느릴 수 있음 (5개 노드 통신 필요) 주요 사용 예시 작은 시스템, 단일 서버 환경 글로벌 분산 시스템, 고가용성 락 필요 시스템 Redis 노드가 예기치 못하게 종료된 경우\nlock 취득에서 timeout 발생 → 애플리케이션 응답 지연 또는 비즈니스 로직 수행 불가\n불완전한 Lock 앞서 싱글 Redis 노드를 사용할 경우 장애 상황에서 고가용성과 안정성에 보장을 받을 수 없다.\nFail case 1 : GC Stop the World로 인한 취득한 lock의 release GC의 STW 현상은 얼마나 지속될 지 예상 불가능함 Concurrent GC 또한 STW 현상은 피할 수 없음 Fail case 2 : lock 취득 후 외부 port 작업 (API, DB, HDFS\u0026hellip;)에서 패킷 loss lock 취득 후, IO 작업 수행 간의 지연 → TTL (lease) 만료 → 다른 스레드에서 lock 취득 후 동일 작업 수행 외부 네트워크 작업에서 패킷 유실로 인한 지연 → TTL (lease) 만료 \u0026hellip; SPoF 해결 : Master - Slave 구조 Failover 되는 동안 TTL이 만료 → Unlock으로 인한 데이터 오염 안정성 해결 : Fencing으로 안전한 lock 사용 MVCC에서 first commit wins와 같이, version에 기반하여 storage에서 트랜잭션을 처리하도록 한다. (애초에 그러면 lock을 안써도 되지 않나?)\nclient 1이 lock 획득에 성공(/w token33)하고 storage write를 시도하는 도중 지연이 발생 (GC, 네트워크 지연 등) client 1의 취득한 lock lease 만료 client 2가 lock을 획득(/w token34) 하고 client1의 작업이 종료되기 전에 storage에 write를 완료 client 1이 storage에 write → storage는 token34 이전인 token33은 reject (transaction fail) 가장 큰 문제는.. 과연 pencing token은 누가 생성할 것인가?이다. 분산 환경에서 카운터 증가를 구현하기 위해 또 다른 카운터 리더 선출이 필요해진다.. (무한 굴레)\nRedlock 동작 과정 현재 시간을 밀리초로 기록 동일한 키와 랜덤 값으로 모든 N개의 Redis 인스턴스에서 순차적으로 락을 시도. 각 시도에는 짧은 타임아웃을 설정해, 노드가 다운되면 바로 다음 인스턴스 이동. 락을 획득하는 데 걸린 시간을 계산하고, N개의 인스턴스 중 과반수 이상에서 락을 획득하고, 걸린 시간이 락의 유효 시간보다 짧으면 락을 획득했다고 판단. 락을 획득하면, 유효 시간은 초기 유효 시간에서 걸린 시간을 뺀 값으로 설정. 락을 획득하지 못한 경우, 혹은 락의 유효시간이 마이너스인 경우(획득 과정에서 초과됨), 모든 인스턴스에서 락을 해제. Bad Timing Issue 구분 설명 일반적인 분산 시스템 \u0026ldquo;시간은 믿을 수 없다\u0026quot;고 가정 → 안전성은 무조건 지키고, 성능(liveness)만 시간에 의존 Redlock 시간(클럭 정확성, 네트워크 지연 등)에 의존해서 락의 안전성을 보장하려 함 문제점 클럭이 갑자기 변하거나(GC, NTP, 네트워크 지연), 프로세스가 일시 정지되면, 락 만료 시점 계산이 잘못돼서 락이 깨질 수 있음 결과 성능 문제(liveness degradation)가 아니라, 아예 데이터 손상이나 중복 실행(safety violation) 이 일어날 수 있음 시나리오 설명 첫 번째 (Clock Jump) Redis C 노드의 시계가 갑자기 앞으로 점프하면서 TTL 만료가 빨라진다. Client 1이 락을 잡았다고 생각하지만, Client 2가 동시에 락을 다시 획득하여 둘 다 락을 보유했다고 착각하게 된다. 두 번째 (GC Pause) Client 1이 락을 요청하고 나서 GC로 멈추는 동안 락이 만료된다. Client 2가 락을 다시 획득하고, Client 1은 GC 복귀 후 예전 락 응답을 받아 자신이 락을 잡았다고 착각한다. Synchrony assumptions of Redlock 조건 설명 네트워크 지연 한계(bounded network delay) 패킷이 항상 정해진 최대 시간 내에 도착해야 한다 프로세스 일시정지 한계(bounded process pause) GC나 시스템 중단이 일정 시간 이하로 제한되어야 한다 시계 오차 한계(bounded clock drift) 각 서버의 클럭 오차가 작아야 하고, NTP 동기화가 신뢰할 수 있어야 한다 ➔ 즉, \u0026ldquo;모든 지연, 중단, 클럭 차이\u0026quot;가 lock TTL(time-to-live)보다 훨씬 작아야 Redlock이 제대로 작동합니다.\n현실 세상에서 이러한 가정이 성립할 수 있을까요? 깃헙의 90-second packet delay를 떠올리면 절대라는 가정은 성립할 수 없습니다.\n결론적으로는\u0026hellip; Redlock 알고리즘은 시간을 전재로 하는 알고리즘이며, 이는 클럭 점프/GC STW/네트워크 유실 등등 여러한 이유에서 정확성을 갖지 못한다.\nRedis는 애초에 \u0026ldquo;합의\u0026rdquo; 목적으로 나온 솔루션이 아닌 KV Store에 초점이 맞춰져 있기에 완벽한 Lock 취득을 위해서는 RedLock이 아닌 Zookeeper, Raft와 같은 방안을 선정하도록 한다.\n","permalink":"https://dingyu.dev/posts/distributed-locking/","summary":"분산된 환경에서 리더 선출과 소유권은 어떻게 관리될까? 동시성 제어를 해결하기 위한 두가지 방안을 소개한다","title":"[DB] 분산 환경에서의 Redlock과 Lease"},{"content":"Local SASL Mechanism Kafka Docker compose 구성하기 Kafka를 사용하는 서비스에서 인증 방식이 SASL 기반이라면, 로컬에서도 유사한 인증 환경을 구성할 수 있어야 한다. 이 글에서는 로컬 환경에서 SCRAM-SHA-256, SCRAM-SHA-512를 동시에 지원하는 Kafka 클러스터를 구성하고, 이를 기반으로 Event Dispatcher 애플리케이션을 테스트할 수 있는 인프라 환경을 구축한 내용을 정리했다.\nSASL과 TLS의 경우 레퍼런스를 찾기 매우매우 힘들었다\u0026hellip; 삽질하는 참에 추후 고생할 나에게 선물을 마련하고자 로컬 환경 SASL Kafka 구성하기를 기록한다\nTLS는 인증서 Makefile 등 너무 복잡하여 추후에 시간이 될 때 포스팅하는것으로..\n구성 목표 Event Dispatcher는 source Kafka에서 이벤트를 consume하고, 이벤트 형태에 따라 분류하여 다른 dest Kafka로 produce하는 구조를 갖는다. source Kafka와 dest Kafka는 서로 다른 클러스터가 아닌, 동일한 클러스터 내에서 다른 SASL 인증 메커니즘을 통해 구분한다. source Kafka는 SCRAM-SHA-256 기반 인증을 사용하고, dest Kafka는 SCRAM-SHA-512 기반 인증을 사용한다. 테스트 환경에서도 코드 수정 없이 실제 운영 환경과 유사한 구조를 구축하는 것이 목표였다. ISR(in-sync replicas)을 2로 두기 위해 Kafka 브로커는 3노드로 구성했다. Kafka UI를 통해 produce 테스트가 가능해야 하며, 이를 통해 애플리케이션의 동작 확인도 가능하도록 한다. 로컬 환경 구성을 고려하게 된 이유 개발 서버에서 테스트 시 스택 트레이스 확인이 어려워 디버깅이 불편했으며, Bastion(보안용 게이트웨이) 사용을 위한 VPN 및 SSH 접근이 상대적으로 피로감을 느끼게 했다 사내 Kafka는 모두 SASL 인증 기반이므로 공통 설정을 만들어두면 다양한 프로젝트에 활용할 수 있다. 설정 값을 테스트할 때 코드 수정과 DEV 환경 배포 없이 변경 가능해야 했다. (트랜잭션 설정, exactly-once, ISR 등) 코드 레벨 수정 없이 테스트하려면 로컬 인프라 구성이 필요했다. Docker Compose 기반 환경 구성 version: \u0026#39;3.9\u0026#39; networks: kafka_network: volumes: kafka_data_0: kafka_data_1: kafka_data_2: services: zookeeper: image: bitnami/zookeeper:3.8.1 container_name: zookeeper environment: - ALLOW_ANONYMOUS_LOGIN=yes ports: - \u0026#39;2181:2181\u0026#39; networks: - kafka_network kafka-0: image: bitnami/kafka:3.7.0 container_name: kafka-0 depends_on: - zookeeper ports: - \u0026#39;${KAFKA_BROKER_0_PORT}:9092\u0026#39; environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_0_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_0:/bitnami/kafka networks: - kafka_network hostname: kafka kafka-1: image: bitnami/kafka:3.7.0 container_name: kafka-1 depends_on: - zookeeper ports: - \u0026#39;${KAFKA_BROKER_1_PORT}:9092\u0026#39; environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_1_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_1:/bitnami/kafka networks: - kafka_network hostname: kafka-1 kafka-2: image: bitnami/kafka:3.7.0 container_name: kafka-2 depends_on: - zookeeper ports: - \u0026#39;${KAFKA_BROKER_2_PORT}:9092\u0026#39; environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_2:/bitnami/kafka networks: - kafka_network hostname: kafka-2 kafka-ui: image: provectuslabs/kafka-ui:latest container_name: kafka-ui depends_on: - kafka-0 ports: - \u0026#39;8080:8080\u0026#39; environment: KAFKA_CLUSTERS_0_NAME: Local-Zookeeper-Cluster KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: SCRAM-SHA-512 KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: org.apache.kafka.common.security.scram.ScramLoginModule required username=\u0026#34;${512_SASL_USER}\u0026#34; password=\u0026#34;${512_SASL_PASSWORD}\u0026#34;; networks: - kafka_network # user 정보가 broker에 저장이 되어야 정상적으로 시작될 수 있음 your-app: env_file: - .env build: context: . dockerfile: dev.Dockerfile args: - VERSION=dev environment: - BOOTSTRAP_SERVERS_256=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} - BOOTSTRAP_SERVERS_512=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} image: your-app container_name: your-app networks: - kafka_network restart: always depends_on: - kafka-0 - kafka-1 - kafka-2 어째서 bitnami? 환경 변수 기반의 간편한 사용자 등록 Bitnami Kafka는 다음과 같은 환경 변수만 설정하면 자동으로 SASL 사용자 등록을 수행 KAFKA_CLIENT_USERS=user256,user512 KAFKA_CLIENT_PASSWORDS=pass256,pass512 이는 일반 Kafka 공식 이미지에서는 수동으로 kafka-configs.sh 스크립트를 실행하거나 custom entrypoint를 만들어야 가능!\nex.\nbash -c \u0026#39; /opt/bitnami/scripts/kafka/setup.sh \u0026amp;\u0026amp; kafka-configs.sh --zookeeper zookeeper:2181 --alter \\ --add-config \u0026#34;SCRAM-SHA-512=[iterations=8192,password=pass]\u0026#34; \\ --entity-type users --entity-name user \u0026amp;\u0026amp; /opt/bitnami/scripts/kafka/run.sh\u0026#39; Bitnami는 컨테이너 기동 시점에 사용자 등록 로직을 자동 수행해줘서 훨씬 편리\nSASL 설정 및 Zookeeper 연동이 기본 내장 Bitnami는 다음 설정들을 Docker 환경변수로 설정 가능 KAFKA_CFG_SASL_ENABLED_MECHANISMS KAFKA_CFG_LISTENER_NAME__SASL_ENABLED_MECHANISMS KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL 즉, 복잡한 server.properties 없이도 docker-compose.yml만으로 SASL 클러스터 구성 가능!\n환경변수 설명 사용처 KAFKA_CFG_ZOOKEEPER_CONNECT Kafka가 사용할 Zookeeper의 주소 (host:port) Kafka가 Zookeeper 기반으로 클러스터 메타데이터를 저장/공유하기 위해 필요함 KAFKA_CFG_LISTENERS 브로커가 어떤 프로토콜과 포트로 외부 연결을 수신할지 설정 (ex: SASL_PLAINTEXT://:9092) 클라이언트 또는 브로커 간 통신을 어떤 방식으로 받을지 정의함 KAFKA_CFG_ADVERTISED_LISTENERS 브로커가 클라이언트에게 자신을 알릴 때 사용하는 주소 (host.docker.internal:${PORT}) Kafka 클라이언트가 브로커에 접속할 때 사용할 외부 IP 또는 호스트명과 포트 정보를 제공함 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP 각 리스너 이름에 대해 사용할 보안 프로토콜을 매핑 (ex: SASL_PLAINTEXT:SASL_PLAINTEXT) 리스너 이름과 보안 프로토콜을 매칭하여 SASL 인증을 활성화하기 위해 사용 KAFKA_CFG_INTER_BROKER_LISTENER_NAME 브로커 간 통신에 사용할 리스너 이름 클러스터 내의 브로커 간 통신을 어떤 리스너(인증 방식)로 할지 지정함 KAFKA_CFG_SASL_ENABLED_MECHANISMS Kafka에서 허용할 SASL 인증 메커니즘 목록 (ex: SCRAM-SHA-512,SCRAM-SHA-256) Kafka 클라이언트와 브로커 간 인증에 사용할 수 있는 SASL 방식들을 정의함 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL 브로커 간 통신에서 사용할 SASL 인증 메커니즘 브로커들끼리 통신 시 어떤 SCRAM 알고리즘으로 인증할지 설정함 KAFKA_CLIENT_USERS SASL 인증에 사용할 사용자 목록 (쉼표로 구분) Kafka 사용자 등록을 위해 필요하며, 각 사용자마다 비밀번호가 필요함 KAFKA_CLIENT_PASSWORDS 사용자 목록에 대응되는 비밀번호 목록 (쉼표로 구분) 위의 사용자 각각에 대응되는 비밀번호를 정의하여 Kafka 서버에 등록함 KAFKA_INTER_BROKER_USER 브로커 간 통신에서 사용할 사용자 이름 브로커들끼리 SCRAM 인증을 위해 사용하는 사용자 지정 KAFKA_INTER_BROKER_PASSWORD 브로커 간 통신에 사용할 사용자의 비밀번호 위의 사용자와 함께 브로커 간 인증을 위해 사용됨 해당 환경은 다음의 구성 요소로 이루어진다:\nBitnami Kafka 3노드 클러스터 (SCRAM-SHA-256, SCRAM-SHA-512 동시 지원) Zookeeper Kafka UI (관리 및 테스트 용도) Event Dispatcher 애플리케이션 (Kafka Consumer/Producer) .env와 파일을 구성한 후, 다음 명령어로 전체 인프라를 실행할 수 있다\ndocker compose --env-file .env up --build 종료 및 클러스터 초기화를 위해서는 아래 명령어를 사용한다:\ndocker compose down -v .env example:\n256_SASL_USER=user256 256_SASL_PASSWORD=pass256 512_SASL_USER=user512 512_SASL_PASSWORD=pass512 # Kafka Settings KAFKA_BROKER_0_PORT=9092 KAFKA_BROKER_1_PORT=9093 KAFKA_BROKER_2_PORT=9094 구성 세부 내용 요약 아래 다이어그램은 로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름을 정리한 것이다. 내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 이해할 수 있다. 각 단계는 실제 로그 흐름에 기반하여 순서대로 설명하였다.\n1. Zookeeper 초기화 Zookeeper 컨테이너가 standalone 모드로 기동되며 Kafka 브로커의 메타데이터 저장소로 동작한다. 사용자 정보 등록은 Zookeeper가 직접 수행하지 않으며, Kafka 브로커가 기동 시 KAFKA_CLIENT_USERS, KAFKA_CLIENT_PASSWORDS 환경변수를 통해 SCRAM 사용자 정보를 자동으로 등록한다. Zookeeper 컨테이너가 standalone 모드로 기동되며 사용자 정보를 등록할 준비를 한다. user256 (SCRAM-SHA-256), user512 (SCRAM-SHA-512)에 대한 사용자 정보가 Zookeeper에 등록된다. 2. Kafka 브로커 기동 및 Zookeeper 연결 Kafka 브로커 3개(kafka-0, kafka-1, kafka-2)가 순차적으로 Zookeeper와 연결을 시도한다. 연결이 완료되면 각 브로커는 controller 선출에 참여하고, request 처리 준비가 완료되었음을 로그로 출력한다. 3. Controller 동작 Kafka 클러스터 내에서 한 브로커가 controller로 선출된다. controller는 각 브로커의 상태를 확인하고, 토픽 메타데이터를 동기화하며, Partition 할당과 Leader 선출을 수행한다. 내부적으로 LeaderAndIsr, UpdateMetadataRequest 등의 메시지를 각 브로커에 전파하며 클러스터 상태를 안정화시킨다. 4. Kafka UI 연결 Kafka UI는 SASL-SHA-512 사용자(user512)를 이용해 Kafka 브로커에 AdminClient로 연결한다. 인증 후 topic 목록 조회 및 메시지 produce 테스트를 수행한다. 5. Event Dispatcher 연결 Event Dispatcher는 source Kafka에 SCRAM-SHA-256 방식(user256)으로 Consumer 연결을 시도하고 consume을 시작한다. 이후 dest Kafka에는 SCRAM-SHA-512 방식(user512)으로 Producer 연결하여 메시지를 produce한다. 전체 시퀀스 다이어그램 로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름은 다음과 같다\n내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 확인해보자!\nKafka 클러스터는 Zookeeper 기반이며, 3개의 브로커로 구성 SCRAM-SHA-256을 사용하는 user256과 SCRAM-SHA-512를 사용하는 user512가 생성 Kafka UI를 통해 user512 인증으로 접근하여 메시지를 직접 produce 가능 Event Dispatcher는 SASL 256/512 User/Password 설정을 기반으로 source/dest Kafka 각각 다른 인증 방식으로 접근하여 동작한다. 트러블슈팅 및 해결 과정 Kafka SASL 인증 기반 환경을 처음부터 구성하다 보면 여러 트러블을 겪게 된다. 실제 테스트 환경에서 마주쳤던 문제와 그에 대한 해결 과정을 아래에 정리했다.\n1. KAFKA_CFG_ADVERTISED_LISTENERS 설정 오류 초기 구성 시 KAFKA_CFG_ADVERTISED_LISTENERS 값을 잘못 설정하여 Kafka UI 및 Event Dispatcher에서 브로커 접근에 실패했다. localhost로 설정할 경우 Docker 내부의 컨테이너 외부에서는 Kafka 브로커에 접근할 수 없었다.\n현상:\nKafka UI 또는 Event Dispatcher가 브로커와 통신할 수 없음 connection refused 또는 EOF 에러 발생 해결 방법:\nlocalhost 대신 host.docker.internal 또는 실제 호스트 IP로 설정 .env 또는 compose 파일 내 브로커 설정 확인 KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092 2. 서로 다른 SASL 메커니즘을 가진 사용자 인증 실패 Kafka 클러스터 하나에서 SCRAM-SHA-256, SCRAM-SHA-512를 동시에 지원하게끔 설정했지만, 사용자 등록이 제대로 되지 않아 인증에 실패했다.\n현상:\nKafka UI는 인증에 성공하나, Event Dispatcher는 EOF 또는 인증 실패 Kafka 로그에 Failed to authenticate user 메시지 출력 해결 방법:\nKafka 초기화 스크립트에서 사용자 추가 시 --mechanism 플래그 명확히 지정 사용자 등록 확인을 위해 Kafka 실행 로그 확인 또는 kafka-configs.sh 이용해 확인 --entity-type users --entity-name user512 --alter --add-config \u0026#39;SCRAM-SHA-512=[iterations=4096,password=pass512]\u0026#39; 추후에는 Broker에서 직접 실행할 필요가 없었음을 느끼고 KAFKA_CLIENT_USERS, KAFKA_CLIENT_PASSWORDS 설정! 3. Kafka UI를 통한 produce가 동작하지 않음 Kafka UI를 통해 메시지를 produce할 수 있어야 Event Dispatcher의 consume 확인이 가능하지만, 인증 실패나 메타데이터 조회 실패로 UI가 제대로 동작하지 않았다.\n현상:\nUI 상에서 produce 시도했지만 메시지가 전송되지 않음 토픽 조회 실패 또는 사용자 인증 실패 로그 해결 방법:\nUI 클러스터 설정에 SCRAM 인증 정보를 추가하고 SASL 메커니즘을 정확히 지정 인증에 사용하는 사용자 계정이 SCRAM-SHA-512를 사용하고 있어야 함 4. ISR 설정과 클러스터 ID 충돌 문제 Kafka 브로커를 3개로 구성하여 ISR=2 설정을 테스트하던 중, 클러스터를 재기동하면 클러스터 ID 충돌로 인해 broker가 기동되지 않는 문제가 발생했다.\n현상:\nKafka broker가 기동 중단 또는 controller election 실패 Cluster ID mismatch 또는 log directory is not empty 오류 해결 방법:\n클러스터 재기동 시 아래 명령어로 볼륨까지 완전 제거 docker compose down -v 필요 시 kafka_data_* 디렉터리를 수동으로 삭제하여 클린 상태 유지 5. SASL 메커니즘에 맞는 Producer/Consumer 설정 누락 Event Dispatcher 설정 중 Kafka Producer와 Consumer 설정 시 SASL 인증 방식 지정이 빠져 인증 실패가 발생했다.\n현상:\nkafka: client has run out of available brokers to talk to 에러 접속 시도는 하나 서버에서 연결을 끊음 (EOF) 해결 방법:\n.env에 SASL 관련 설정 추가하고, 라이브러리 설정에 반영 Go 클라이언트 기준으로는 Config.Net.SASL.Mechanism 명시 필요 이러한 문제들을 하나씩 해결해가면서 현재와 같은 안정적인 로컬 테스트 환경을 구성할 수 있었다.\n마무리 Kafka 환경이 점차 보안과 인증 요구사항을 갖게 되면서, SASL 기반 인증 환경을 로컬에서도 구축해보는 것은 매우 의미 있는 작업이었다.\n단일 클러스터에서 다중 SASL 메커니즘을 지원함으로써, 더 이상 클러스터를 이중으로 구성할 필요 없이 하나의 테스트 환경으로 다양한 인증 흐름을 재현할 수 있게 되었다.\n특히\u0026hellip; 감동받은 부분은 Kafka UI! GUI로 Message 생성하고 Consume 됨을 확인할 수 있음에 감격했다\n","permalink":"https://dingyu.dev/posts/local-sasl-kafka/","summary":"E2E 테스트는 마지막 테스트로서 개발자가 애플리케이션을 잘 개발하였는지 확인하기 위해 꼭 필요한 테스트이다. Kafka를 로컬 환경에서 테스트하고자 한다면 어떻게 할까? SASL 인증 방식을 사용한다면?","title":"[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기"},{"content":"배경 비동기 프로그래밍과 동기 프로그래밍의 가장 큰 트레이드오프(Trade-off)를 꼽자면, 성능을 확보하는 대신 추적이 어려워진다는 점이다.\nKafka를 활용한 이벤트 기반 아키텍처(EDA, Event-Driven Architecture)에서도 마찬가지로, 비동기적으로 처리되는 데이터의 흐름을 실시간으로 파악하는 것은 쉽지 않다.\n특히 이슈가 발생한 후에야 문제를 인지하는 상황이 반복되면서, Kafka 모니터링의 필요성이 더욱 절실해졌다.\n이벤트 기반 시스템에서 중요한 것은 퍼포먼스(Performance) 모니터링이다.\nREST API 기반의 아키텍처에서는 CPU/메모리 사용량 및 요청량을 기반으로 Kubernetes Horizontal Pod Autoscaler(HPA)를 이용해 트래픽을 견디는 방식이 일반적이다.\n그러나 Kafka 기반 아키텍처에서는 파티션(Partition)의 개수와 Consumer의 처리 속도가 성능을 결정하는 핵심 요소다.\n만약 파티션이 적거나 Consumer의 처리 속도가 느려 Lag이 발생한다면?\n→ 개발자가 직접 퍼포먼스를 분석하고, 파티션 확장(Partition Scaling) 및 Consumer 증설(Scale-out)을 수행해야 한다.\n이러한 문제를 사전에 감지하고 해결할 수 있도록 Kafka 모니터링 시스템을 구축하게 되었다.\nKafka의 성능을 모니터링하는 방법으로 아래 3가지 옵션을 고려했다.\n설계 Kafka 모니터링 솔루션 비교 AWS CloudWatch AWS에서 제공하는 CloudWatch의 Kafka 모니터링 기능을 사용하면\nPER_TOPIC_PER_PARTITION 단위로 지표를 수집할 수 있다.\n주요 모니터링 지표 지표명 (AWS/MSK) 설명 EstimatedTimeLag Consumer Group이 데이터를 소비한 후, 파티션의 Offset 지연시간(초) OffsetLag Consumer Group이 데이터를 소비한 후, 파티션의 Offset 지연 개수 항목 설명 ✅ 간편한 설정 AWS MSK와 기본 연동 가능 ✅ CloudWatch Alarm + SNS 활용 가능 손쉽게 경고(Alert) 설정 가능 ❌ AWS 콘솔에서만 데이터 확인 가능 외부 모니터링 툴과 연동 어려움 ❌ 비용 부담 토픽 수준 모니터링은 추가 비용 발생 EKS 기반 Helm 모니터링 (사내 솔루션, 실패) 기존에 사내에서 운영 중인 Helm Chart를 활용하여 Kafka 모니터링을 시도했으나,\nMSK와 EKS가 서로 다른 리전에 존재하여 사용이 불가능했다.\n항목 설명 ✅ 사내 시스템과 통합 가능 사내 시스템과 원활한 연동 가능 ❌ MSK와 EKS가 서로 다른 리전에 위치 연동 불가 문제 발생 ❌ EKS를 MSK와 동일 리전에 구축할 경우 비용 부담 발생 추가적인 비용이 발생할 수 있음 결과적으로 도입을 포기하게 되었다.\nEC2 기반 Docker Compose 모니터링 (최종 채택) 결국, MSK와 동일한 VPC 내에 EC2를 배포하고 Kafka 모니터링 스택을 직접 구성하는 방식을 선택했다.\nJMX Exporter \u0026amp; Node Exporter를 활용하여 Kafka 메트릭 수집 Burrow를 활용하여 Consumer Lag 모니터링 Thanos 및 Prometheus를 통해 장기적인 모니터링 가능 항목 설명 ✅ 비용 효율성 저렴한 T 시리즈 EC2 인스턴스를 활용하여 운영 가능 ✅ 확장성 커스터마이징이 자유로우며 필요에 따라 확장 가능 ✅ 보다 세밀한 Kafka 모니터링 가능 Burrow를 활용하여 Consumer Lag 추적 가능 ❌ 초기 세팅 부담 직접 설정해야 하며 시행착오가 발생할 가능성이 있음 ❌ Burrow 및 Thanos 운영 경험 부족 팀 내에서 Kafka 모니터링 노드를 운영한 경험이 없어 직접 해결해야 했음 오히려 좋아..! 바닥부터 새롭게 알아갈 수 있다는 것이 오히려 장점이 되어 EC2 기반 모니터링을 직접 구축하기로 했다\n아키텍처 구성하기 MSK 관련 배경 정보 zookeeper: 카프카의 메타 데이터 정보를 주키퍼에 저장하고, 카프카의 상태를 관리 broker: 카프카가 설치되어 있는 서버 또는 노드 JMX Exporter: JMX(Java Management Extensions) Exporter를 사용하여 Apache Kafka(브로커, 프로듀서, 컨슈머)의 성능과 상태를 모니터링할 수 있도록 다양한 메트릭을 제공 Node Exporter: Node Exporter를 사용하여 CPU 및 디스크 메트릭 노출이 가능 Kafka 모니터링 아키텍처 발전 과정: Prometheus, Thanos, Burrow 연동 Kafka 모니터링 시스템을 구축하는 과정에서 Prometheus 단독 운영(V1) → Thanos를 통한 확장(V2) → Burrow를 활용한 Kafka Consumer 모니터링 추가(V3)로 발전해 나갔다.\n각 버전별 아키텍처를 비교하며, 각 접근 방식의 장단점을 정리한다.\nV1: Prometheus 단독 구성으로 Metric 수집 Prometheus를 이용하여 Kafka 메트릭을 수집하고, Grafana에서 CloudWatch와 Prometheus를 데이터 소스로 추가하여 모니터링을 진행했다.\n구성 아키텍처 Pros (장점) Prometheus만 설정하면 별도 복잡한 설정 없이 Kafka 모니터링 가능 Grafana에서 Prometheus와 CloudWatch를 동시에 활용 가능하여 메트릭 비교 가능 Cons (단점) Prometheus가 다운되면 모니터링 시스템 전체가 중단되며, Single Point of Failure (SPOF) 문제가 발생 Prometheus는 모든 메트릭을 메모리(TSDB)에서 처리하므로, 수집하는 메트릭이 많아질수록 메모리 사용량 급증 TSDB의 크기가 증가할수록 Prometheus의 성능 저하 및 장애 가능성 증가 V2: Prometheus + Thanos Sidecar 구성으로 HA 보장 고가용성을 확보하기 위해 2대의 Prometheus 인스턴스를 운영하고, Thanos Sidecar를 추가하여 Thanos 중앙 서버(Query + Store)와 연동했다.\n구성 아키텍처 Thanos를 도입한 이유 Prometheus의 중복 적재 방지: N대의 Prometheus가 동일한 Metric을 수집할 경우, Thanos Query가 중복 데이터를 제거(Deduplication)하여 처리 TSDB 단기 저장(Short-term) + Thanos Store 장기 저장(Long-term) 분리: Prometheus는 단기적인 메트릭만 보관하고, 장기적인 데이터는 Thanos Store(S3 등)에 저장하여 복구 가능 Prometheus의 TSDB 크기를 줄일 수 있어, 메모리 사용량 감소 및 비용 절감 가능 Pros (장점) 고가용성(HA) 확보: 2대의 Prometheus + Thanos Query 구성으로 Prometheus 한 대가 장애가 나더라도 모니터링 지속 가능 장기적인 데이터 보존 가능: Prometheus TSDB는 단기 데이터만 저장하고, 장기 데이터는 Thanos Store에 저장 가능하여 S3, GCS 등 Object Storage를 활용하여 저비용으로 장기 보존 가능 Prometheus 리소스 최적화 가능: Prometheus의 TSDB 크기를 줄일 수 있어, 메모리 사용량 감소로 비용 절감 가능 Cons (단점) Thanos 추가 구성 필요로 인해 운영 복잡도 증가: 기존 Prometheus 단독 운영보다 Thanos Sidecar, Query, Store 설정이 추가로 필요하며, Thanos Store를 위한 Object Storage(S3 등) 연동이 필요함 Thanos Query의 성능 한계: 여러 Prometheus 인스턴스에서 메트릭을 조회하는데, 과도한 요청이 발생하면 성능 저하 가능성 있음 V3: Burrow + Prometheus + Thanos Sidecar로 Kafka Consumer 모니터링 강화 비용 절감 및 Kafka Consumer Lag 모니터링을 강화하기 위해, CloudWatch 대신 Burrow를 도입하여 Kafka Consumer 메트릭을 수집했다.\nCloudWatch를 걷어내고, Burrow + Prometheus + Thanos로 Kafka 모니터링을 최적화하였다.\n구성 아키텍처 burrow가 주기적으로 kafka Consumer 메트릭을 수집하고, prometheus가 burrow metric을 수집하도록 하여 최종적으로 thanos query가 thanos-sidecar를 통해 kafka 관련 메트릭을 모두 수집하도록 구성\nBurrow를 도입한 이유 CloudWatch 비용 절감: Kafka 모니터링을 CloudWatch에서 Burrow + Prometheus로 전환하여 비용 절감 가능 Kafka Consumer Lag 모니터링 강화: Burrow는 Kafka Consumer Group의 Offset 정보를 실시간으로 수집하며, Consumer Lag을 모니터링하여 Kafka가 정상적으로 동작하는지 추적 가능 ACL(Access Control) 기반 모니터링 가능: CloudWatch는 Kafka ACL을 기반으로 세부적인 Consumer 모니터링이 어려운 반면, Burrow는 Consumer Group 및 Topic 별로 상세한 Lag 정보를 제공 Pros (장점) CloudWatch 비용 절감: Kafka 모니터링을 CloudWatch에서 Burrow + Prometheus로 전환하여 비용 절감 가능 Kafka Consumer Group의 상세 모니터링 가능: Burrow를 통해 각 Consumer의 Offset, Lag, Partition 상태까지 상세 분석 가능 기존 Prometheus + Thanos와 원활한 연동 가능: Burrow에서 /metrics 엔드포인트를 제공하여, Prometheus에서 손쉽게 데이터 수집 가능하며, Thanos Query를 통해 Kafka 관련 메트릭을 Grafana에서 단일 인터페이스로 조회 가능 Cons (단점) Burrow 초기 설정 및 운영 부담 증가: Burrow는 Kafka Consumer Lag을 모니터링하는 강력한 도구지만, 처음 설정할 때 Kafka 클러스터와 연동하는 과정이 필요하며, Kafka ACL이 적용된 환경에서는 Burrow의 접근 권한 설정이 필요함 Burrow의 자체 Alerting 기능 한계: Burrow는 기본적으로 Alert 기능을 제공하지만, Prometheus Alertmanager보다 유연하지 않아 Prometheus Alertmanager 또는 Grafana Alerta와 함께 사용해야 효과적임 버전 별 정리 아키텍처 장점 단점 최종 평가 V1: Prometheus 단독 빠른 구성 가능, 별도 설정 불필요 고가용성 보장 안됨, 메모리 사용량 과다 SPOF 문제로 비효율적 V2: Prometheus + Thanos Sidecar 고가용성(HA) 확보, 장기 데이터 저장 가능, 메모리 최적화 가능 Thanos 추가 구성 필요, 운영 복잡도 증가 장기 저장 및 확장 가능 V3: Burrow + Prometheus + Thanos CloudWatch 비용 절감, Kafka Consumer 상세 모니터링, 기존 Prometheus 연동 가능 Burrow 설정 필요, Alert 기능 부족 최종 채택 Kafka 모니터링을 효과적으로 수행하기 위해, Burrow + Prometheus + Thanos를 조합하여 Kafka Consumer Lag까지 포함한 종합적인 모니터링 시스템을 구축하는 것이 최적의 해결책이었다.\n구현 Burrow Kafka Consumer Lag Monitoring with Burrow Kafka client의 consumer에서 metrics() 메서드를 사용하여 records-lag-max를 기록할 수 있지만, 가장 뒤처진 파티션의 지연만을 보여주므로 전체 상태 파악이 어렵다. 또한, consumer가 멈추면 lag을 감지할 수 없어 외부 모니터링 시스템이 필요하다. 이를 해결하는 대표적인 솔루션이 LinkedIn의 Burrow이다.\nBurrow: Kafka Consumer Monitoring Reinvented\nConsumer A: lag이 지속적으로 감소 → 정상 Consumer B: lag이 일시적으로 증가했으나 복구됨 → 정상 Consumer C: lag이 일정하게 유지됨 → 정상 Consumer D: lag이 일시적으로 증가했으나 복구됨 → 정상적인 트래픽 처리 Kafka Lag Threshold의 문제점 임계값(threshold) 기반 감지는 오탐 가능성이 높다. 예를 들어, threshold를 250으로 설정하면 실제 정상적으로 동작하는 B, D도 이상 상태로 감지될 수 있다.\n⚠️ Kafka consumer의 MaxLag 값만으로 장애 여부를 판단할 수 없다!\nBurrow는 어떻게 해결하는가? Burrow는 Kafka 내부의 consumer offset을 기록하는 토픽을 읽어 개별 consumer 상태를 독립적으로 평가한다. 특정 consumer에 종속되지 않으며, 모든 consumer를 자동으로 모니터링하여 객관적인 상태 분석이 가능하다.\nBurrow의 동작 방식 Burrow는 sliding window 기법을 활용하여 최근 N개의 offset commit을 분석한다. LinkedIn에서는 10개의 offset commit(약 10분)을 기준으로 다음을 평가한다:\nConsumer가 지속적으로 offset을 커밋하는가? Consumer offset이 증가하고 있는가? Lag이 증가하고 있는가? Lag 증가 패턴이 지속적인가? 이를 기반으로 consumer 상태를 다음과 같이 분류한다:\n✅ OK: 정상 작동 ⚠️ Warning: lag이 증가하는 상태 ❌ Error: consumer가 멈추거나 동작이 중단됨 Burrow는 임계값 없이 패턴 분석을 통해 자동으로 이상 감지하며, HTTP API 및 알림 시스템을 통해 정보를 제공한다.\nBurrow API 예제 GET /v2/kafka/local/consumer/dingyu/status consumer의 현재 상태와 문제가 발생한 topic과 partition 정보를 확인할 수 있다.\n연동 방안 1. 사전 준비 OS: Amazon Linux 2 또는 Ubuntu 20.04 이상 Docker 및 Docker Compose 설치 EC2 보안 그룹에서 다음 포트 허용 Prometheus: 9090 Thanos Sidecar: 10901, 10902 Burrow: 8000 2. 패키지 설치 # Docker 설치 sudo yum install -y docker sudo systemctl enable docker --now # Docker Compose 설치 sudo curl -L \u0026#34;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 3. 폴더 구조 MSK-MONITORING/ │── templates/ # 설정 템플릿 폴더 │ ├── burrow.tmpl.toml # Burrow 설정 템플릿 │ ├── prometheus.tmpl.yaml # Prometheus 설정 템플릿 │ ├── targets.tmpl.json # Prometheus 타겟 설정 템플릿 │── deploy.sh # 배포 스크립트 │── docker-compose.yaml # Docker Compose 설정 파일 │── Makefile # 설정 렌더링 및 빌드 관리 │── README.md # 프로젝트 문서 4. 주요 구성 요소 4.1 Burrow Kafka Consumer 상태를 모니터링하는 도구 burrow.tmpl.toml 파일을 기반으로 환경 변수를 대체하여 설정 SASL/TLS 인증을 사용하여 MSK에 연결 HTTP 서버를 통해 상태 제공 Burrow 관련 트러블슈팅 SASL 인증을 하는 경우, 레퍼런스가 전혀 없어서 무한 삽질을 거듭하였다\nTLS의 경우 인증을 하지 않아 별도로 설정하지 않았으나, skip verify 옵션으로 무조건 필요했다\n이 부분은 sarama client 생성 시, config를 고쳐 가며 디버깅을 거듭했다\nSASL Mechanism은 SCRAM-SHA-512/SCRAM-SHA-256을 지원한다! MSK에서 어떠한 Mechanism으로 설정하였는지 필히 확인하자\n4.2 Prometheus Kafka 및 Burrow 메트릭 수집 prometheus.tmpl.yaml을 기반으로 환경 변수 대체 후 설정 targets.tmpl.json을 통해 JMX 및 Node Exporter 메트릭 수집 4.3 Docker Compose docker-compose.yaml을 사용하여 Burrow, Prometheus, Thanos Sidecar 컨테이너 실행 컨테이너 간 네트워크를 구성하여 원활한 통신 지원 4.4 Makefile make render: 환경 변수를 반영하여 설정 파일을 생성 (generated/ 디렉토리) 4.5 환경 변수 관리 환경 변수는 아래 example 처럼 docker-compose와 같은 디렉토리에 .env 형태로 관리하세요\nPROM_CLUSTER={your-cluster-name} PROMETHEUS_PORT=9090 BURROW_PORT=8000 ZOOKEEPER_HOST_1={zookeeper1_endpoint} ZOOKEEPER_HOST_2={zookeeper2_endpoint} ZOOKEEPER_HOST_3={zookeeper3_endpoint} BROKER_HOST_1={broker1_endpoint} BROKER_HOST_2={broker2_endpoint} BROKER_HOST_3={broker3_endpoint} BURROW_USERNAME={user} BURROW_PASSWORD={password} 5. 설치 및 실행 방법 5.1 프로젝트 클론 git clone https://github.com/dings-things/msk-monitoring-docker-compose.git cd msk-monitoring-docker-compose 5.2 환경 변수 설정 .env 파일을 생성\n5.3 배포 스크립트 실행 chmod +x deploy.sh ./deploy.sh 5.4 개별 실행 (수동 실행) make render docker compose up -d 배포 프로세스 자세한 사용법은 github 참고 !\n실무 환경에서는 gitlab snippets를 사용하여 환경 변수를 snippets API를 통해 불러와 환경 별로 매핑합니다.\n대시보드 구성하기 꼭 구성해야 하는 중요한 지표를 아래와 같이 분류하였다\nTopic/Partition 별 Status Check : 특정 토픽, 파티션의 이상 여부 확인 burrow_kafka_topic_partition_status 지표 활용 Disk Usage : Disk 임계치 초과 시 Alert 설정 (증설) node_filesystem_avail_bytes 지표 활용 (현재 남아있는 공간(avail_bytes) 을 전체 디스크 용량(size_bytes) 과 비교하여 사용된 비율을 계산) CPU Usage : CPU 임계치 초과 시 Alert 설정 (파티션 증설) node_cpu_seconds_total 지표 활용 (user[kafka]사용 CPU, 전체 - idle[유휴] CPU 확인) Consumer Group Status Check : 컨슈머 그룹(애플리케이션) 상태 체크 burrow_kafka_consumer_status 지표 활용 Consumer Group/Topic Lag : 컨슈머 그룹 / 토픽 별 쌓인 Lag 체크 burrow_kafka_consumer_partition_lag 지표 활용 Lag Per Partition : 파티션 별 쌓인 Lag 체크 burrow_kafka_consumer_partition_lag 지표 Table 활용 Current Offset : 현재 컨슈머 그룹이 처리하고 있는 최근 Offset burrow_kafka_consumer_status 지표 활용 최종 구성 REFS Burrow 공식 문서 Prometheus 공식 문서 Prometheus 를 스케일링 하기 위한 Thanos AWS MSK Connect 효과적으로 운영하기 여기어때 MSK 모니터링 구축해볼까요? ","permalink":"https://dingyu.dev/posts/dance-with-burrow/","summary":"아직도 저수준의 Kafka Input/Ouput Bytes로만 모니터링 하신다구요? Burrow와 jmx, node exporter를 통해 토픽 수준의 모니터링을 구성해봅시다","title":"[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos"},{"content":"들어가기에 앞서\u0026hellip; 느슨한 결합을 유지하면서 높은 확장성을 보장하는 EDA에서 역설적이지만 Producer Consumer 간의 강한 결합을 갖게하는 이벤트 스키마 왜 사용하고 어떤 이유로 Schema Registry를 사용할까? 이벤트 스키마의 목적 데이터의 구조를 정의하고, 메시지 형식을 표준화하며, Producer와 Consumer 간의 데이터 일관성을 유지 Producer와 Consumer 간의 호환성 유지 데이터에 대한 검증 백엔드라면 익숙한 REST API를 예시로 들어보자! 각 서비스가 서로 통신하기 위해서는 사전에 정의된 인터페이스로 Client와 Server 간의 일종의 \u0026ldquo;약속\u0026quot;을 맺게 된다\n서로 일관된 형태로 통신하기 위하여 OpenAPI 혹은 문서를 통해서 사용자는 어떤 값을 입력해야 하는지, 그리고 어떤 값을 반환 받게 되는지에 대한 협의를 하게 되는데\u0026hellip;\nAPI가 아닌 이벤트 스트림에서도 동일하다\nProducer가 사전 정의된 이벤트에 대하여 발행하면, Consumer는 사전 정의된 이벤트를 읽어와 비즈니스 로직을 수행한다.\n[예시-1] Producer와 Consumer가 사전에 협의를 통해 스키마를 정의하였다고 가정해보자.\n{ \u0026#34;user_id\u0026#34; : number, \u0026#34;user_action\u0026#34; : \u0026#34;string\u0026#34; } Producer와 Consumer는 사전에 이벤트 스키마를 통해 협의를 했음에도 불구하고 Producer는 action string이 아닌 action code로 이벤트를 발행하였다.\n(효과는 대단했다! Consumer의 분노 게이지가 Max다 🤢)\nERD를 만들지도 않고 DB에 삽입하는 일이 없듯이\u0026hellip; 이벤트 드리븐 아키텍처에서 개발함에 있어 스키마 설계는 선택사항이 아닌 강제사항이라 생각된다.\nEvent Schema 이벤트 스키마가 어째서 필요한지는 어느정도 설명이 되었다 생각된다.\n스키마는 당연히 설정해야 겠지만 포맷에 결정 고민이 된다면 아래 표를 참고해보자!\n형식 장점 단점 JSON (JavaScript Object Notation) 사람이 읽기 쉬운 텍스트 기반 포맷 / 대부분의 프로그래밍 언어에서 널리 지원됨 텍스트 포맷으로 인해 크기가 큼 / 스키마 강제가 없어서 데이터 무결성 문제 발생 가능 Protobuf (Protocol Buffers) Google에서 개발한 빠르고 효율적인 바이너리 포맷 / 스키마 기반으로 데이터 구조를 강제할 수 있음 / JSON보다 빠른 파싱 속도 및 작은 메시지 크기 사람이 읽을 수 없는 바이너리 포맷 / 사전 스키마 정의가 필요함 / JSON에 비해 생태계가 상대적으로 작음 Avro 스키마 기반으로 데이터 구조를 관리할 수 있음 / 작은 메시지 크기 (Compact Binary Format) / 배포된 프로그램을 깨뜨리지 않고 스키마 진화(Schema Evolution) 지원 JSON이나 Protobuf보다 덜 널리 사용됨 / 일부 환경에서는 도구 및 라이브러리 지원이 부족할 수 있음 스트림 또한 네트워크 통신을 거치기 때문에, 결국 중요한 것은 데이터의 사이즈일 것이다.\nAPI 명세를 자주 작성하는 엔지니어라면 단순하게 쉽고 편한 JSON을 사용할 것이다. 다만\u0026hellip; 이 경우 명확하게 JSON을 사용해야 할 필요성이 있는가? 를 고려해보시길 바란다.\n얼죽JSON을 위한 체크리스트 아래 여건을 모두 만족한다면 JSON을 선택하였더라도 매우 합리적인 선택일 것이다!\n데이터의 크기가 작은가? 역/직렬화에 드는 비용을 감수할 것인가? 강타입 유효성 검증이 필요하지 않은가? Schema Registry 사용할 생각이 없는가? 데이터가 점진적으로 더 많이 유입될 여지가 없는가? 디버깅 용이성을 위해서 눈으로 확인이 가능한 모델이 필요한가? Avro / Protobuf의 장점 강타입 유효성 검증을 통해 보다 일관된 데이터를 받을 수 있다 ex. ENUM, float 등과 같이 지정된 타입이 아닐 경우 직렬화 자체가 실패함 역/직렬화에 드는 비용을 최소화 할 수 있다 본래 역/직렬화 성능은 압축률에 반비례한다 (JSON은 압축되지 않음). 단 추가적인 파싱 문제로 JSON은 매우 비효율적임 JSON은 텍스트 기반이므로 추가적인 Parsing이 필요함 Avro/protobuf는 바이너리 기반으로 Parsing이 필요없음 상위/하위 호환성을 지원한다 필드가 추가될 때, 해당 필드에 대한 모델이 반영되어 있지 않더라도 무시하고 정상 동작함 실제 벤치마크 결과에서 JSON 비록 작은 데이터사이즈임에도 불구하고 직렬화와 역직렬화 성능이 2배 이상의 차이를 보였다.\n놀라운 점은 데이터 크기가 커질수록 이 격차는 보다 확연해진다는 점이다.\n데이터 사이즈와 성능의 상관 관계 JSON은 BINARY가 아닌 TEXT의 형태로 저장되기에 Avro나 Protobuf에 비하여 보다 큰 공간을 차지한다.\nKafka Volume의 증가 : JSON 이벤트 사용을 위해 물리적으로 보다 큰 용량을 사용해야 함 Broker에서 이벤트 생산/소비의 성능 저하 : 본질적으로 네트워크 통신에 있어 이동되는 데이터의 크기가 커질수록 성능이 저하될 수 밖에 없음 Produce 단계에서 In Sync Replication에 보다 큰 비용이 발생 Consume 단계에서 이벤트를 가져오는 데에 보다 큰 비용이 발생 Schema Registry 이벤트 스키마를 정리하자면 주요하게 아래 3개를 보장한다\n일관성 성능 향상 호환성 Schema Registry는\u0026hellip; Kafka 메시지의 데이터 구조(스키마)를 중앙에서 관리하고 검증하여 생산자와 소비자가 데이터 호환성을 유지하도록 돕는 서비스이다\n스키마 진화와 호환성 [예시-2] API에서 v1 API를 v2 API로 전환한다 생각해보자. 기존 하위 호환성을 지키되 v1 API 사용자에게 v2로 전환을 부탁하고 \u0026hellip; 몇개월이 지나 v1 API의 유입이 없음을 확인한 뒤에야 v2로 완전 전환이 가능할 것이다.\n이벤트 스트림에서는 어떨까?\nv2 스키마로 업데이트 이후에, 해당 이벤트를 구독중인 Consumer들에게 어떠한 필드가 추가되었는지 알리고.. Consumer는 필요에 따라 추가 구현을 진행하게 될 것이다.\n그럼 Producer가 먼저 업데이트되어야 하는가? Consumer가 먼저 업데이트 되어야 하는가? 닭이 먼저냐 계란이 먼저냐??\n다행히도 스키마 레지스트리를 사용하면 이러한 문제는 해결된다!\n스키마 레지스트리에 스키마를 등록하면, URL은 유지한 채로 Consumer는 최신 스키마 버전을 가져오게 된다. Producer 에서 새로운 스키마 버전으로 이벤트가 발행됨 (v2) Consumer 는 기존 캐싱된 스키마 버전과 다름을 인지하고 새로운 스키마 버전을 조회 새로운 스키마 버전으로 비즈니스 로직 수행 이처럼 하위호환성을 유지하면서 스키마 변경이 자유로워진다\n효율적인 이벤트 관리 무조건 Schema Registry가 좋으냐..? Event Schema는 필수인가..?\n기술선택에 Must는 없다. 상황에 따라 최선의 선택을 하는것은 엔지니어의 역량에 달려있다 생각한다.\nKafka Stream에서의 Schema Event 이해 Schemaless인 JSON과는 달리, Avro와 Protobuf의 경우 Schema를 포함하여 Event와 함께 Produce 된다\nAvro와 Protobuf의 경우 바이너리 포맷이며 스키마 없이 해석할 수 없기 때문에, 데이터를 어떻게 해석해야 하는지 스키마 정보가 요구됨 이벤트 데이터 사이즈 비교 스키마 이벤트의 장점으로 설명하였던 압축된 작은 바이너리 데이터는 스키마 정보를 포함하는 순간 퇴색된다. 이처럼 스키마 정보를 포함하는 순간 압축률이 높다 하더라도 보다 큰 데이터일 수 밖에 없다.\n이러한 단점을 극복하는데 있어 스키마 ID는 이벤트 사이즈를 최소화할 수 있으며 호환성 보장이 가능하다.\n사실 Producer와 Consumer에서 동일한 스키마 파일이 있다면 굳이 스키마 정보를 포함하여 이벤트로 발행하지 않아도 가능하다. 단, Submodule의 단점은 다음과 같다\nProducer와 Consumer가 같은 .proto를 사용해야 하는 전제 조건이 강함 스키마 변경이 동적으로 반영되지 않음 스키마 변경이 있을 경우, Producer와 Consumer를 모두 재배포해야 함 AWS Glue 와 Schema Registry 차이 MSK를 사용하는 경우, 별도 AWS Glue를 사용하여야 스키마 레지스트리를 사용할 수 있다. 이에 대한 차이는 다음과 같다.\n기능 AWS Glue Schema Registry Confluent Schema Registry 스키마 업데이트 방식 새로운 버전으로 추가됨 새로운 버전으로 추가됨 스키마 URL 유지 여부 ✅ 유지됨 (ARN 기반) ✅ 유지됨 (REST API 기반) 자동 최신 버전 사용 ❌ 기본적으로 자동 X (Consumer 설정 필요) ✅ 기본적으로 자동 사용 Kafka 호환성 ✅ AWS MSK와 연동 가능 ✅ Confluent Kafka와 기본 연동 왜 Schema Registry를 사용하냐고 물으신다면? Producer와 Consumer 간 데이터 일관성 유지\nProducer가 보내는 데이터와 Consumer가 기대하는 데이터 형식을 검증 데이터 불일치로 인한 비즈니스 로직 오류 방지 Schema Evolution(스키마 진화) 지원 → 하위/상위 호환성 보장\n새로운 필드 추가 시 기존 Consumer가 깨지지 않도록 유지 가능 기존 필드 삭제나 변경 시에도 안전한 데이터 처리가 가능 스키마 관리의 중앙화 → 변경 및 배포 프로세스 단순화\n스키마를 중앙에서 관리하여 모든 서비스가 동일한 기준을 따름 개별 서비스에서 .proto 파일을 관리하지 않아도 자동으로 최신 버전 적용 가능 Kafka 메시지 크기 최소화 (스키마 ID 활용)\n스키마 정보를 메시지에 직접 포함하지 않고, Schema Registry에서 스키마 ID만 전송 네트워크 비용 절감 + Kafka 저장 공간 절약 Schema Validation(데이터 유효성 검증) 기능 제공\nProducer가 잘못된 데이터(예: 필드 누락, 타입 불일치)를 보내면 Schema Registry에서 즉시 차단 Consumer가 유효한 데이터만 수신하여 안정적인 서비스 운영 가능 실시간 스키마 변경 감지 및 자동 업데이트 가능\nConsumer가 Schema Registry에서 최신 스키마를 조회하여 동적으로 변경된 필드를 활용 가능 서비스 재배포 없이 데이터 구조 변경 가능 Schema Compatibility Mode 설정 가능\n하위 호환성(Backward Compatibility), 상위 호환성(Forward Compatibility) 등의 정책을 설정하여 스키마 변경으로 인한 장애 방지 스키마 조회 및 버전 관리 용이\nREST API 혹은 UI를 통해 기존 스키마 및 변경 이력을 조회할 수 있어 유지보수 편리 특정 시점의 스키마 버전으로 롤백 가능 REFS Confluent Oliveyoung Exploring Data Serialization in Apache Kafka ","permalink":"https://dingyu.dev/posts/schema-registry/","summary":"이벤트 스키마의 하위/상위 호환성 어떻게 지켜질까?","title":"[EDA] Schema Registry"},{"content":"class Me: def __init__(self): self.name = \u0026#34;Jung Woo Lee\u0026#34; self.born_year = 1996 self.MBTI = \u0026#34;ENTP\u0026#34; self.location = \u0026#34;Seoul, Korea\u0026#34; self.school = \u0026#34;Tsinghua University\u0026#34; self.major = \u0026#34;automation\u0026#34; self.interests = [\u0026#34;BE\u0026#34;, \u0026#34;DevOps\u0026#34;, \u0026#34;MLOps\u0026#34;, \u0026#34;Go\u0026#34;, \u0026#34;Kafka\u0026#34;, \u0026#34;TDD\u0026#34;, \u0026#34;Automation\u0026#34;] ","permalink":"https://dingyu.dev/ko/about/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Jung Woo Lee\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eborn_year\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1996\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMBTI\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;ENTP\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elocation\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Seoul, Korea\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eschool\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Tsinghua University\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emajor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;automation\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einterests\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;BE\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;DevOps\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;MLOps\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Go\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Kafka\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;TDD\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Automation\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"About"},{"content":"RPC? Remote Procedure Call의 약자로 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신 기술 입니다.\n→ 즉, 내부적인 커넥션 과정과 데이터가 전달되는 일련의 과정을 추상화하는 Method를 사용하여, 실제로는 외부 통신을 하지만 코드상으로는 함수를 호출하는 것과 동일한 효과\nHTTP API 와 더불어 Client ↔ Server, Server ↔ Server 간 데이터를 주고 받을 때 사용되는 범용적인 통신 방법! 원격 프로시저 호출을 이용하여 프로그래머는 함수가 로컬이나 원격 위치에 있든 동일한 코드를 작성하여 기능을 활용할 수 있습니다. MSA 구조의 서비스에서 다양한 언어와 프레임워크로 개발되는 경우 프로토콜에 맞춰 통신해야 하는 비용이 발생한다.\n그러한 분산 컴퓨팅 환경에서 프로세스(서비스) 간 상호 통신 및 컴퓨팅 자원의 효율적인 사용을 위해서 발전된 기술이다.\n→ 애플리케이션이 점차 쪼개짐에 따라\u0026hellip; 기존 모노 레포에서 함수를 호출하면 그만이던 것이.. 외부 통신을 거쳐야만 데이터 조회가 가능한 형태로 변경됨\u0026hellip; → Server Process Time \u0026laquo; Network Latency : 애플리케이션 코드 내에서의 최적화는 수ns 정도는 줄일 수 있겠지만, 실질적인 병목 구간인 네트워크 통신 비용에 대한 해결책으로 gRPC가 화두가 되기 시작함\nRPC 동작 방식 IDL(Interface Definition Language) 을 사용하여 서버의 호출 규약을 정의한다. 함수명, 인자, 반환값에 대한 데이터 형이 저장된 IDL 파일을 rpcgen 컴파일러를 이용하여 stub 코드를 자동으로 생성한다 (1) 우선 IDL(Interface Definition Language)를 통해 호출에 대한 인터페이스를 정의합니다.\n(2) IDL에 의해 정의된 인터페이스는 client의 stub과 server의 skeleton 생성의 기반이 되며, rcpgen(유틸리티)를 통해 각각의 stub과 skeleton을 생성합니다.\n(3) 클라이언트는 리모트의 프로시저를 사용하기 위해 설계된 스텁의 프로시저를 호출하고, 프로시저 호출에 필요한 인자와 비지니스에 로직에 필요한 메소드를 호출합니다.\n(4) 스텁은 서버가 이해할 수 있는 형태로 데이터의 캐스팅 진행하고, 서버 측 RPC로 호출을 진행합니다.\n(5) 서버는 수신된 호출에 대한 데이터를 처리합니다.\n(6) 서버측 RPC 프로토콜은 처리된 데이터를 캐스팅하여 클라이언트로 응답합니다.\nStub이 뭔가요? Stub은 원격 프로시저 호출(RPC)에서 클라이언트와 서버 간의 통신을 추상화하고 단순화하는 데 사용되는 코드 조각\nGRPC? gRPC는 Protocol Buffer를 IDL (Interface Definition Language) 및 메시지 교환 방식으로 사용합니다. 구조화된 데이터의 직렬화(Serialization), 역직렬화(Deserialization) 에 사용 클라이언트 어플리케이션에서 로컬 객체(method) 인 것처럼 다른 머신(remote) 에 있는 서버 어플리케이션의 메서드를 직접 호출 할 수 있다. 흔히들 (나만 그럴지도..?) rpc 통신을 한다 하면\u0026hellip; HTTP/2 기반의 protocol Buffer를 사용하겠구나~ (grpc 구나) 라고 생각하기 마련이다.\n그치만\u0026hellip; 실제 Stub 내부적인 원격 프로시저 호출의 구현체가 어떠한 프로토콜을 사용하여 구현되어 있는지는 알 수 없다\n즉, rpc != grpc 이며 RPC와 gRPC는 포함관계이다\nHTTP/1.1과 HTTP/2.0 HTTP는 TCP 위에서 동작하며, \u0026ldquo;Connection Oriented\u0026quot;를 목적으로 둔 TCP 답게 \u0026ldquo;연결\u0026quot;을 맺어야 데이터 송수신을 하게된다.\n흔히 알고 있는 HTTP/1.1 통신 흐름은 다음과 같다. TCP 연결 (3 way handshake) 데이터 송수신 TCP 연결 종료 (4 way handshake) 여러번 데이터를 주고 받아야 하는 상황에서 TCP 연결 및 종료에 따른 오버헤드는 무시할 수 없다. (특히나 물리적인 거리가 먼 경우에는\u0026hellip; 어휴 😂)\n다행히도 HTTP/1.1에서는 Keep-Alive가 활성화되어 있어, 하나의 TCP 연결을 여러 HTTP 요청/응답에 재사용할 수 있다.\n주로 REST를 사용하는 Production 애플리케이션에서는 이러한 TCP 연결에 따른 오버헤드를 줄이고자 HTTP Client를 재사용하곤 한다.\n재사용할 수 있으면 큰 문제가 없지 않느냐..?\nKeep-Alive는 여러 요청을 하나의 TCP 연결에서 처리할 수 있지만, HTTP/1.1은 기본적으로 한 번에 하나의 요청만 처리 가능(직렬 처리) 여러 개의 요청을 동시에 처리하려면 여러 개의 TCP 연결을 만들어야 함 → 이로 인해 네트워크 오버헤드 증가 HTTP/1.1의 문제와 HTTP/2.0에서의 개선사항 HTTP/1.1 - Proxy로 인한 Keep-Alive의 치명적 문제 클라이언트가 프록시를 통해 HTTP 요청(Keep-Alive 포함)을 서버로 보냄. 프록시는 서버에 같은 요청을 전달하고, 서버도 Keep-Alive를 유지함. 서버가 응답을 보낸 후, Keep-Alive 상태에서 연결을 유지함. 일정 시간이 지나면, 프록시가 타임아웃을 감지하고 서버와의 연결을 강제 종료함. 클라이언트는 아직 연결이 살아 있다고 생각하고 새로운 요청을 보냄. 하지만 프록시는 이미 서버와의 연결을 닫았으므로 연결 재사용이 불가능하고 \u0026ldquo;Connection Reset\u0026rdquo; 오류 발생. HTTP/2.0 - PING과 GOAWAY를 통한 문제 해결 클라이언트가 Proxy를 통해 서버에 HTTP/2 요청 (GET /resource) 전송 서버가 200 OK (Keep-Alive) 응답 → 연결 유지 서버가 연결 종료 예정 → Proxy에게 GOAWAY 프레임 전송 Proxy가 클라이언트에게 GOAWAY 전달 → 새로운 요청 시 새 연결 사용하도록 유도 Proxy가 서버와의 연결 상태 확인 (PING 프레임 전송) → PING ACK 응답 받으면 연결 유지 서버가 Keep-Alive Timeout으로 연결 종료 → Proxy가 감지 클라이언트가 GET /another-resource 요청 → Proxy는 새로운 서버 연결 맺음 새로운 연결을 통해 요청 전달 및 200 OK 응답 반환 → 정상 처리 완료 물론 해당 이슈는 서버측에서 비정상 종료 시, graceful shutdown 과정에서 GOAWAY를 전달해야 가능하다\nHTTP/1.1 - HOL(Head-of-Line) Blocking 문제 클라이언트가 첫 번째 요청 (/slow-resource)을 보냄. 서버에서 이 요청을 처리하는 데 오랜 시간이 걸림. 클라이언트가 두 번째 요청 (/fast-resource)을 보냄. 하지만 HTTP/1.1에서는 한 개의 TCP 연결에서 요청을 순차적으로 처리해야 함. 따라서 두 번째 요청(fast-resource)은 첫 번째 요청(slow-resource)이 끝날 때까지 대기해야 함. 첫 번째 요청이 완료된 후에야 두 번째 요청 처리 가능. 두 번째 요청은 빠르게 처리할 수 있지만, 첫 번째 요청의 처리 지연으로 인해 응답이 늦어지는 HOL Blocking 발생. HTTP/2.0 - Multiplexing을 통한 문제 해결 클라이언트가 두 개의 요청 (/slow-resource, /fast-resource)을 보냄. HTTP/2에서는 Multiplexing을 통해 단일 TCP 연결에서 두 개의 요청을 동시에 전송. 서버가 먼저 응답이 가능한 요청(/fast-resource)을 처리하고 즉시 응답을 보냄. /slow-resource 처리가 완료된 후 해당 요청에 대한 응답을 별도로 전송. 결과적으로 HOL Blocking 없이 빠른 요청이 지연되지 않고 독립적으로 처리됨. Pros \u0026amp; Cons 구분 장점 (Pros) 단점 (Cons) 성능 HTTP/2 기반으로 멀티플렉싱, 헤더 압축, 스트리밍 지원 → 높은 성능 HTTP/2를 지원하지 않는 클라이언트와의 통신이 어려움 IDL (Interface Definition Language) Protocol Buffers(ProtoBuf)를 사용하여 강력한 타입 안정성과 코드 자동 생성 가능 ProtoBuf는 JSON보다 가독성이 낮고 사람이 직접 읽기 어려움 다양한 통신 방식 지원 Unary, Server Streaming, Client Streaming, Bi-directional Streaming 지원 복잡한 스트리밍 방식은 디버깅이 어려울 수 있음 다양한 언어 지원 Go, Java, Python, C++, Node.js 등 여러 언어에서 사용 가능 일부 언어에서는 gRPC 지원이 완벽하지 않거나 라이브러리 성숙도가 낮음 자동 코드 생성 .proto 파일을 기반으로 클라이언트와 서버 코드 자동 생성 추가적인 빌드 과정 필요 (protoc 컴파일러 사용) 보안 TLS 기반의 강력한 보안 제공 TLS 설정이 복잡할 수 있음 로드 밸런싱 클라이언트 사이드 로드 밸런싱 지원 기본적으로 제공하는 기능이 제한적이며, Envoy 등과 함께 사용하는 것이 일반적 스트리밍 지원 실시간 데이터 처리를 위한 스트리밍 API 제공 스트리밍을 활용한 서비스 구현이 상대적으로 복잡 트랜스포트 방식 Binary 기반 직렬화로 메시지 크기가 작고, 전송 속도가 빠름 RESTful API처럼 사람이 직접 요청을 보내거나 디버깅하기 어려움 브라우저 호환성 gRPC-Web을 통해 브라우저 지원 가능 기존 gRPC는 브라우저에서 직접 사용 불가하여 gRPC-Web 프록시 필요 ","permalink":"https://dingyu.dev/posts/grpc/","summary":"흔히들 (나만 그럴지도..?) rpc 통신을 한다 하면\u0026hellip; HTTP/2 기반의 protocol Buffer를 사용하겠구나~ (grpc 구나) 라고 생각하기 마련이다. rpc는 무엇이고 grpc는 어째서 빠를까? 그리고 왜 사용할까?","title":"[Protocol] RPC... 그리고 GRPC 톺아보기"},{"content":"배경 서비스 별로 다른 프로젝트 구조 프로젝트 마다 코드 파악이 힘듦 e.g.\nSomeAPI ├── .vscode ├── api ├── build ├── config ├── data ├── db ├── externalservice ├── httpsrv ├── httptest ├── mocks ├── log ├── cli ├── repository ├── util ├── .gitignore ├── .gitlab-ci.yml ├── changelog ├── data.go ├── diag_debug.go ├── diag.go ├── go.mod ├── go.sum ├── main.go ├── Makefile ├── release.conf ├── README.md 공통 컨벤션이 없어 공통 모듈/CI를 사용하기 힘듦 모든 프로젝트에서 사용될 수 있도록 고려할 사항이 많아짐 → 개발 생산성 ↓ 온보딩 과정이 힘듦 신규 합류된 팀원이 Go언어에도 익숙치 않은 상태에서 너무 제각각인 스타일으로 인해 혼란이 옴 팀이 Go 언어 생태계로 전환을 완료했고, 이제는 노하우가 생겼다 생각함 장기적인 운영에서 컨벤션 사용으로 유지보수성 ↑ 신규 프로젝트에서 새로운 프로젝트 구조에 대한 고민을 하는 일, 기존 프로젝트에서 리팩토링의 방향성을 잡기 힘듦 개발 생산성 ↓ 프로젝트 구조 제안 적용이 Must인 부분은 * prefix를 가집니다 (그 외, Optional)\n엔터프라이즈 레벨의 프로젝트가 아닌 MSA를 기준으로 작성됩니다 추후 리팩토링을 하더라도 도메인 단위의 MSA로 물리적인 격리가 진행되기 때문\u0026hellip;\n프로젝트 구조 샘플 도메인을 \u0026ldquo;매치 샘플링\u0026quot;이라 하였을 때\n. ├── *docs // 프로젝트 별 문서들 │ ├── *swagger.yaml // API 스웨거 문서 │ ├── sequence.md // 비즈니스 시퀀스 다이어그램 │ └── architecture.md // 시스템 아키텍처 다이어그램 ├── *cmd │ └── *main.go // 프로젝트 진입점, DI 주입 ├── pkg // 비즈니스 로직에 종속적이지 않은 패키지 (외부에서 import 하여도 상관없는 모듈) │ ├── file_parser.go │ └── time_convertor.go └── *internal // 외부에 공개되면 안되는 비즈니스 로직 영역 (도메인 영역) ├── *handler │ ├── *v1 │ │ └── sampling_handler.go // 도메인 핸들러 v1 │ ├── v2 │ │ └── sampling_handler.go // 도메인 핸들러 v2 │ ├── server.go // handler가 많을 경우, handler를 등록할 server를 둡니다 │ ├── health_handler.go // v1, v2 공통 핸들러 │ ├── swagger_handler.go // 프로젝트 테스트 용 openapi 핸들러 (CORS 허용) │ └── auth_middleware.go // 미들웨어들 ├── data │ ├── mysqldb.go // DB client 커넥터 │ ├── redis.go // DB client 커넥터 │ ├── feature_event_producer.go // Kafka event producer - xxx_producer │ ├── match_repository.go // ORM 수행 repository (DB client 주입) - xxx_repository │ └── nass_api.go // 외부 API Data Layer - xxx_api ├── *service │ ├── kda_sampler.go // Data layer 혹은 다른 service를 주입 받아 구현 │ ├── match_sampling_usecase.go // service 가 많을 경우, 오케스트레이션 해주는 유즈케이스 구현 │ └── kda_sampler_test.go // 비즈니스 로직의 유닛테스트 ├── logger.go // 애플리케이션 전역에서 사용될 기능 ├── constants.go // 외부에서 참조 되어야 하는 상수 값 정의 └── *config.go // application 설정 파일 ├── *gitlab-ci.yml ├── *go.mod ├── *go.sum └── *README.md // 프로젝트에 대한 배경, 유즈케이스, 설치 방법 기술 구분 필수 여부 설명 예시 docs ✔ 프로젝트 아키텍처, 시퀀스 다이어그램, 스웨거 문서를 관리 - swagger.yaml- sequence.md cmd ✔ 프로젝트 진입점, 실행 가능한 파일 및 스크립트 관리 - main.go- start.sh pkg 애플리케이션에 종속적이지 않은 유틸리티 기능 관리 - time_convertor.go- file_parser.go internal ✔ 외부에 공개되면 안되는 비즈니스 로직(도메인) 영역애플리케이션 전역에서 사용될 기능 담당 - config.go- logger.go- constants.go internal/handler ✔ API라면 API Handler일 것이고 Consumer라면 Consumer Handler 담당- 버저닝은 *필수, HTTP/gRPC/MQ/Kafka 와의 통신을 담당- 미들웨어는 Optional- handler가 여러개일 경우, server 에서 handler를 등록할 수 있도록 합니다 - blacklist_handler.go- alive_handler.go- log_middleware.go- server.go internal/data 3 Tier Architecture 중, Data Layer 영역영속성을 가진 데이터 CRUD 담당(외부 API 또한 해당됨, Kafka 또한 stream에 저장하는 행위로 간주) - event_producer.go- blacklist_repository.go- member_api.go internal/service ✔ 비즈니스 로직을 수행하는 비즈니스 영역- 각각의 서비스는 단일 책임 원칙에 따라 하나의 책임만 수행- 서비스가 다수일 경우, 이를 오케스트레이션 해주는 xxx_usecase로 구현- 서비스 코드의 단위 테스트는 필수 (일부 의존성에 따른 테스트 불가 시 패스) - fraud_detect_usecase.go- fraud_retriever.go- rule_analyzer.go ./ (root) ✔ 프로젝트 실행 및 운영을 위한 파일 영역- 리드미는 필수로 작성 (유즈케이스와 설치 방법은 항상 기술) - gitlab-ci.yml- README.md 상수 컨벤션 기본적으로 카멜케이스와 파스칼케이스를 원칙으로 사용합니다\n→ 하나의 도메인 파일에서 도메인과 관련된 상수가 다른 패키지에 속해 있는 경우, 수정에도 어렵고 추적에도 귀찮음이 동반 됨을 느꼈습니다\n→ 하나의 책임을 지는 파일 내에서 private 상수로서 관리 된다면 유지보수에도 용이할 것이고 코드 파악에도 용이할 것이라 생각합니다\n복수 패키지에서 다수 의존될 여지가 있는 경우 (Pascal) internal layer의 constants.go 파일에 상수 값들을 정의 합니다\npackage internal const ( LanguageCodeKorean = \u0026#34;ko\u0026#34; LanguageCodeEnglish = \u0026#34;en\u0026#34; LanguageCodeChinese = \u0026#34;zh_CN\u0026#34; LanguageCodeJapanese = \u0026#34;ja\u0026#34; ) 하나의 패키지 내 혹은 하나의 파일에서 사용할 경우 (Camel) 동일 패키지 내에서는 private 변수에 참조할 수 있습니다\npackage handler const ( // resultSuccess : 성공 응답 resultSuccess = \u0026#34;true\u0026#34; // resultFailure : 실패 응답 resultFailure = \u0026#34;false\u0026#34; ) 불가피하게 다른 패키지로부터 참조되어야 하는 경우 상수는 private으로, struct의 Public 함수로 참조 될 수 있게 합니다\npackage handler const ( // samplerEndpoint : 매치 샘플링 엔드포인드 samplerEndpoint = \u0026#34;/v1/:match_id\u0026#34; ) // Endpoint : 핸들러의 엔드포인트를 반환 func (h *SamplerHandler) Endpoint() string { return samplerEndpoint } 데이터 모델 컨벤션 데이터 모델은 가급적 별도 파일이 아닌, 수행되는 파일에서 정의하여 사용합니다\n→ model을 별도로 지정해 둘 경우, 특정 도메인에 대한 수정이 있을 때 참조된 여러 파일을 수정해야 하는 불편함이 존재합니다\n→ 같은 계층 간의 데이터 이동에 대해서는 파라미터로 주고 받고 다른 레이어 간 통신은 *레이어 간 데이터 모델 컨벤션에 따라 데이터 모델을 주고 받습니다\n→ parameter가 두 개 이상일 경우, 데이터 모델로 만들어 관리합니다\n레이어 간 데이터 모델 컨벤션 handler → service\nrequest → serviceDTO\nfunc (h *Handler) CreateMatch(c *gin.Context) { var req matchRequest if err := c.ShouldBindJSON(\u0026amp;req); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // Service 호출 err := h.service.Create(req.ToServiceDTO()) // so on } service → data\nserviceDTO → entity\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { ... // repository 계층에 MatchEntity 삽입 요청 id, err := b.repository.Insert(match.ToEntity()) if err != nil { return 0, err } return id, nil } data → service\nentity → serviceDTO\nfunc (r *MatchRepository) Insert(entity MatchEntity) (int, error) { // 데이터 레이어에서 UserEntity 가져오기 result, err := s.db.Create(\u0026amp;entity) ... return result.ID, nil } 데이터 모델에서의 조건 검사 모델을 주고 받는 경우, 가독성을 위해 조건 검사는 함수로 실시 합니다\n단위 테스트에 용이 하며, 한눈에 비즈니스 로직을 파악하기 쉬워 집니다\n[AS-IS]\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { if strings.HasPrefix(match.Version, \u0026#34;rc\u0026#34;) \u0026amp;\u0026amp; match.detail == \u0026#34;test\u0026#34; { return } // 비즈니스 로직 } [TO-BE]\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { if match.IsTest() { return } // 비즈니스 로직 } 테스트 컨벤션 비즈니스 로직의 테스트는 선택사항이 아닌 필수입니다. 이미 정의된 에러에 대한 테스트케이스는 최대한 상세하고 간결하게 작성합니다.\nDeterministic 비동기 단위 테스트 비동기로 처리하고 결과 값을 확인하지 않거나 time sleep 이후의 로깅을 멈추세요\nDI + Eventually를 통한 flaky test를 방지합니다\n로거 주입 // NewQueue 비즈니스 로직을 수행할 Queue 생성자 func NewQueue( config Config, httpClient *http.Client, logger *zerolog.Logger, ) (queue Queue, err error) { // queue는 Start()를 통해 thread executor가 실행될때에 생성됩니다. queue = Queue{ config: config, client: httpClient, logger: logger, quitChan: make(chan struct{}), } return } 응답 값 테스트 큐 로직 실패 테스트 t.Run(\u0026#34;큐 처리 실패시, 실패 로깅 테스트\u0026#34;, func(t *testing.T) { // given var buffer bytes.Buffer ... 로거 의존성 주입 // when ... 비동기 작업 수행 event1, err := queue.Push([]byte(validJSON1)) assert.NoError(t, err) event2, err := queue.Push([]byte(validJSON2)) assert.NoError(t, err) // then assert.Eventually(t, func() bool { output := buffer.String() return strings.Contains(output, event1.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, event2.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, `\u0026#34;success\u0026#34;:false`) }, 1*time.Second, 10*time.Millisecond) }) 큐 로직 성공 테스트 t.Run(\u0026#34;큐 처리 성공시, 성공 로깅 테스트\u0026#34;, func(t *testing.T) { // given var buffer bytes.Buffer ... 로거 의존성 주입 // when ... 비동기 작업 수행 event1, err := queue.Push([]byte(validJSON1)) assert.NoError(t, err) event2, err := queue.Push([]byte(validJSON2)) assert.NoError(t, err) // then assert.Eventually(t, func() bool { output := buffer.String() return strings.Contains(output, event1.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, event2.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, `\u0026#34;success\u0026#34;:true`) }, 1*time.Second, 10*time.Millisecond) }) ","permalink":"https://dingyu.dev/posts/go-convention/","summary":"효율적인 Go Project Structure Guide","title":"[Go] Go Convention"},{"content":"왜 Loki? 백엔드 애플리케이션에서 로그를 기반으로 사용자 문의에 대한 ES 쿼리를 수행하거나, 운영팀에 시각적으로 리포트가 가능한 Kibana 대시보드를 자주 사용하곤 했다.\n\u0026ldquo;왜 Loki로 전환하느냐?\u0026rdquo; 라고 묻는다면\u0026hellip;\n\u0026ldquo;비용적인 절감을 위해서!\u0026rdquo; 라고 답할 것이다.\n항목 Loki 🟢 Elasticsearch 🔴 데이터 저장 방식 메타데이터만 저장, 원본 로그는 Object Storage 활용 모든 로그를 인덱싱하여 저장 검색 방식 라벨 기반 검색 정교한 텍스트 검색 (Full-text search) 인덱싱 비용 낮음 높음 (인덱싱에 CPU, 메모리 많이 사용) 스토리지 비용 저렴함 (S3, GCS 등 외부 스토리지 활용 가능) 비쌈 (Elasticsearch 전용 노드 필요) 성능 대량 로그 저장 시 성능 우수 빠른 검색 속도 확장성 간단한 구성으로 확장 가능 클러스터 확장이 비교적 복잡 운영 부담 적음 (별도 클러스터 관리 부담 없음) 높음 (클러스터 관리 필요) 사용 사례 단순 로그 저장 및 조회 복잡한 검색 및 데이터 분석 고려사항 체크리스트 별도의 대시보드를 외부에 제공할 필요가 없는가? 이슈 발생 시, 단순 로그 조회 용도만 필요한가? Loki 연동 시 라벨 값이 매우 다양하거나 고유한 값이 많아지면, Loki의 인덱싱 시스템이 비효율적으로 작동\nexample: user_id, timestamp와 같이 고유한 값이 자주 바뀌는 필드를 라벨로 지정하면 인덱스 크기가 급격히 커짐 결과:\n쿼리 성능 저하 메모리 과다 사용 저장 비용 증가 고정된 값 중심으로 라벨 구성하기 낮은 카디널리티 유지하기 위해 라벨 구성\n라벨 값은 가능한 한 고정적이거나 변경 범위가 제한된 값을 사용 example Good 😊: region=\u0026quot;us-east-1\u0026quot;, app=\u0026quot;payment-service\u0026quot; Bad 😥: user_id=\u0026quot;12345\u0026quot;, request_id=\u0026quot;abcd-efgh\u0026quot; 필터링 목적에 맞는 라벨만 사용 라벨 설계 시, 추후 어떠한 로그 필드로 어떠한 대시보드를 구성할 것인지 상세하게 설계한다\n라벨은 실제 검색, 필터링, 분석에 필요한 데이터에만 지정 불필요하거나 디버깅만을 위한 라벨은 피한다 example Good 😊: API 요청에 따른 요청 량에 대한 집계가 필요한 경우(TPS, latency 등), Request 당 한번만 존재하는 로그를 기준으로 설계 → func=\u0026ldquo;LogMiddleware.Log\u0026rdquo; 중 latency 사용 → label을 func로 등록 Bad 😥: latency를 label로 지정 로그 메시지와 메타데이터 분리 Label은 Raw Log를 식별할 수 있는 \u0026ldquo;Tag\u0026quot;와 가까움.. 라벨은 메타데이터로만 활용, 실제 동적인 값은 로그 메시지 본문에 포함\nexample Good 😊: label:func=\u0026ldquo;RestrictionsService\u0026rdquo; line:member_id =\u0026ldquo;12341512321\u0026rdquo;, message=\u0026ldquo;restricted member\u0026rdquo; **Bad 😥: label:member_id=\u0026ldquo;12341512321\u0026rdquo; line:message =\u0026ldquo;restricted member\u0026rdquo;, func=\u0026ldquo;RestrictionsService\u0026rdquo; 라벨 개수 제한 Label 자체를 많이 설정한 경우.. 이 또한 고 카디널리티로 인덱스 효율이 비효율적이다\nLoki 공식 권장사항에 따르면, 라벨 수는 20개 이하로 유지하는 것이 좋음 라벨의 유니크 값 개수 제한 Loki는 라벨당 1,000개 미만의 유니크 값을 권장합니다. 예를 들어, status=\u0026quot;200\u0026quot;, status=\u0026quot;500\u0026quot; 같은 정해진 값은 문제없지만, user_id=\u0026quot;12345\u0026quot;, session_id=\u0026quot;abcd-efgh\u0026quot; 같은 값은 라벨로 사용하면 안 됨.\nexample Good 😊: env=\u0026ldquo;production\u0026rdquo;, service=\u0026ldquo;payments\u0026rdquo;, region=\u0026ldquo;us-east-1\u0026rdquo; Bad 😥: user_id=\u0026ldquo;12345\u0026rdquo;, request_id=\u0026ldquo;xyz-789\u0026rdquo; Chunk 크기와 보관 주기 고려하기 Loki는 로그를 Chunk 단위로 저장하며, 일정 주기마다 Object Storage로 Flushing 됨. Chunk 크기가 너무 작으면 → 성능이 저하되고, 너무 크면 → 검색 속도가 느려질 수 있음.\nchunk_encoding: gzip chunk_target_size: 1MB~2MB (case by case) 대시보드 구성하기 1. Variable 설정하기 Variable의 경우, 전체 로그에서 필터를 적용해줘야 하는 번거로움이 있지만\u0026hellip; 미래에 모니터링을 하고 있을 자신에게 선사하는 작은 선물이다\nApplication 로그의 경우, 주로 raw log를 기반으로 쿼리하기 때문에 빠르게 필터링 할 수 있는 label을 Variable로 두는 것이 좋다\nraw log / error log에서 필터링 된 로그 중 빠른 파악을 위해 text box filter를 두어 2차로 걸러 주는 것이 바람직할 것임!\n2. raw log 구성하기 앱 전역에서 남기는 로그를 쉽게 확인해보기 위해 모든 로그를 한눈에 볼 수 있는 Logs Visualization으로 시작해보자\nexample\n{_type=\u0026#34;loki\u0026#34;} |= `$filter` 3. log level에 따른 error log 구성하기 raw log에서 duplicate를 통해 error인 로그만 남겨보자\n비즈니스 로직에 따라 에러임에도 에러로 처리하지 않는 예외 케이스가 존재한다. 이를 유의하여 log level을 미리 지정하자\nexample\n{level=\u0026#34;error\u0026#34;} 4. TPS 구성하기 극한의 완성도는 속도에서 들어나는 법.. 대시보드 구성시 P50, P99는 매번 챙기는 지표이다\nGauge Visualization으로 quantile_over_time을 사용하여 PXX를 확인해보자. 단 아래와 같은 유의 사항이 있다. (prometheus가 아닌 loki+grafana에 초점을 맞추었으니 양해를 구합니다)\nPrometheus처럼 TSDB(Time-Series Database)에서 효율적으로 백분위수를 계산하는 것이 아님 대량의 로그를 처리할 경우 성능 저하 발생 가능 quantile_over_time 연산이 메모리 집약적이며, 큰 범위에서 실행 시 비용이 높음 example\nquantile_over_time(0.50, {func=\u0026#34;LogMiddleware.Log\u0026#34;} |= `$filter` | json | unwrap latency [$__range]) by (func) 5. Label에 따른 Distribution 구성하기 Piechart는 전반적인 분포도를 조사하기에 알맞다. 단, Label이 지정되어야 하기에 Unique한 Label의 분포일 경우에만 구성하자\nexample\nsum by(method) (count_over_time({func=\u0026#34;LogMiddleware.Log\u0026#34;} |= `$filter` [$__auto])) 6. Table을 통해 Distribution 및 필터링 구성하기 Table은 시각적으로 한눈에 분포를 확인할 수 있으며 아래와 같이 구성할 경우, 클릭을 통해 해당 라벨에 대한 로그를 필터링 할 수 있다\nexample\nsum by(method) (count_over_time({func=\u0026#34;LogMiddleware.Log\u0026#34;} |= `$filter` [$__auto])) 대시보드 완성본 REFS 6 easy ways to improve your log dashboards with Grafana and Grafana Loki ","permalink":"https://dingyu.dev/posts/es-to-loki/","summary":"단순 애플리케이션 모니터링 목적을 두고 보았을 때.. 과연 Elasticsearch 처럼 무거운 서비스를 사용해야할까? Loki로 전환하면서 겪은 시행착오를 소개합니다","title":"[LGTM] Elasticsearch to Loki 전환기"},{"content":" REFS Rules Based Stream Processing with Apache Flink\u0026rsquo;s Broadcast Pattern Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System Build a dynamic rules engine with Amazon Managed Service for Apahce Flink 리서치 배경 Window Time 동안 필터링 조건에 따른 횟수 기반의 탐지 정책을 구축하는 방안 케이스 스터디가 필요함 하나의 Job 코드에서 모든 정책에 대한 처리 하는 방안에 대한 리서치가 필요 정책 별 인스턴스 할당은 가상화 된 컨테이너를 활용하더라도 리소스 낭비가 심함 정책은 관리자에 의해 수정될 수 있으며, 정책 변경에 따른 재배포를 최소화해야 함 사전 지식 동적 파티셔닝 Kafka는 Event Key를 기반으로 해싱 후, 모듈러 연산을 통해 파티셔닝 됨\nKafka Streams, Flink에서 Event의 Key가 아닌 값으로 group by (keyBy) 할 경우, 해당 Key를 기준으로 리셔플이 발생\n(리셔플 발생 시, 네트워크를 통해 Task Manager 간의 데이터 재구성이 진행되며 심각한 오버헤드가 될 수 있음) 이를 적절히 해결하기 위해, 동일한 키를 가진 스트림 트랜잭션이 **같은 작업자(subtask)**에서 처리될 수 있도록 구성해야 함\nex. ) Group By Target이 \u0026ldquo;ID\u0026rdquo; or \u0026ldquo;IP\u0026rdquo; 으로 source에서 미리 두개의 topic으로 발행하는 것도 방법이 됨\n용어 정의 구성 요소 설명 주요 역할 특징 JobManager Flink의 중앙 관리 노드로, 작업(Job)의 생명 주기를 관리합니다. - 작업 계획 수립 및 분배- ExecutionGraph 생성- Checkpoint 관리 및 장애 복구- 리소스(TaskManager 슬롯) 할당 - 클러스터당 하나의 JobManager 실행- 모든 작업의 상태와 진행 상황을 모니터링- Checkpoint와 Savepoint를 통해 상태를 저장 및 복구 TaskManager Flink의 작업을 실행하는 워커 노드입니다. - SubTask 실행- 네트워크 통신 및 데이터 전송- 상태(State)와 메모리 관리 - 병렬 처리 단위를 실행하는 물리적 노드- 클러스터 내 여러 TaskManager 존재- 각 TaskManager는 여러 슬롯(Slot)을 가질 수 있으며, 슬롯마다 SubTask 실행 SubTask Flink 작업의 병렬 실행 단위로, TaskManager 내에서 실행됩니다. - 파티셔닝된 데이터를 처리- 연산자(Operator)의 로직 실행- 독립적인 상태(State) 관리 - keyBy를 통해 파티셔닝된 데이터만 처리- 병렬도(parallelism)에 따라 생성- SubTask 간에는 데이터가 공유되지 않으며 독립적으로 작동 Broadcast 작은 크기의 데이터 스트림을 모든 SubTask에 복제하여 전달하는 메커니즘입니다. - 규칙(Rule) 데이터 전파- 설정 정보 동기화- 컨트롤 메시지 공유 - Broadcast 데이터를 모든 SubTask에 복사- 일반 데이터 스트림과 결합 가능- 네트워크 부하가 발생할 수 있으므로 작은 크기의 데이터에 적합 구현 방안 rule DB의 CDC를 기반으로 액션 이벤트 + 활성화된 정책 이벤트를 병합하여 이벤트 발행 액션 이벤트가 1이고 활성화된 이벤트가 N개라면 총 N개의 병합(액션+정책 정보 포함) 이벤트 발행 DynamicKeyFunction을 토대로 source stream에서 group by에 따라 이벤트를 파티셔닝 새로운 keyBy() 조건에 따른 리셔플을 동적으로 처리 → Job 코드 수정 X, 재배포 X 기존 keyBy() 조건인 경우 기존 TaskSlot에서 처리 DynamicEvaluationFunction에서는 소스로부터 데이터를 읽어와 이벤트가 정책에 부합하는 지 확인, 정책에 부합한다면 restrict event로 발행 Broadcast State REFS : A Practical guid to broadcast state in Flink\nBroadcast State 는 하나의 데이터 스트림을 다른 데이터 스트림의 모든 작업(Task)에 동일한 상태(State)로 전파하여 공유할 수 있도록 설계된 기능\n주로 동일한 설정값이나 기준 데이터를 실시간 업데이트하여 다른 데이터와 조합해 처리해야 하는 애플리케이션에서 사용 됨\nBroadcast State의 동작 구조 두 개의 스트림이 필요: Broadcast Stream: 이 스트림의 이벤트는 모든 작업(Task)의 병렬 인스턴스에 **공유 상태(State)**로 전파됨 일반 Stream: 이 스트림의 이벤트는 각 작업의 병렬 인스턴스로 개별적으로 전달됨 이벤트 처리 방식: Broadcast Stream의 이벤트는 상태로 유지되어 모든 병렬 작업에서 참조 가능 일반 Stream의 이벤트는 개별 작업에서 Broadcast Stream의 상태와 함께 처리 적합한 사용 사례 Low Throughput vs High Throughput 스트림 결합:\nBroadcast Stream은 상대적으로 낮은 속도(low throughput)로 동작하며, 이를 일반 스트림(high throughput)과 결합해 효율적으로 처리 소스 액션 이벤트 스트림과 알림 정책을 스트림 기반으로 전환하여, 동적으로 결합하여 사용할 수 있도록 함 동적 처리 로직 업데이트:\nBroadcast Stream을 사용해 처리 로직 또는 기준 데이터를 실시간으로 업데이트 정책 변경 시, Broadcast stream으로 정책 정보 전달, 실시간으로 변경된 정책으로 Evaluate Data Stream : Source Event (결제 이벤트)\nBroadcast Stream : 정책 Event (Retention Time은 무제한)\n원본 이벤트 (액션 이벤트)에 정책 Event를 병합하여 처리 Operator Task는 Broadcast Stream 기반으로 하는 Broadcast State(K/V Store) 를 바탕으로 정책 Evaluate Dynamic Data Paritioning REFS : Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System\nProduction System에서 runtime에 Job을 재배포할 필요 없이 Rule을 더하거나 지울 수 있도록 시스템을 구현한다\nKeyBy와 Partitioning KeyBy 메서드: Flink의 keyBy 메서드를 사용하면 스트림의 이벤트에 **키(Key)**를 지정 가능 같은 키를 가진 이벤트는 같은 파티션으로 할당되며, 다음 Operator의 같은 Task에서 처리됨 Key 지정의 일반적인 패턴: 대부분의 스트리밍 애플리케이션에서는 키를 정적인 필드로 고정 e.g. 유저 로그인(login stream)에서 memberID를 키로 사용해 윈도우 기반 집계를 수행 Horizontal Scalability: 정적 키를 사용하면 수평적 확장성(horizontal scalability)을 제공하여 높은 처리량을 지원 구분 정적 키 (Static Key) 동적 키 (Dynamic Key) 정의 런타임 전에 미리 고정된 필드로 데이터를 그룹화 런타임 시점에 비즈니스 로직에 따라 동적으로 키를 설정 설정 고정된 필드 기반의 keyBy (예: Transaction::getAccountId). JSON이나 Rule 엔진과 같은 외부 설정으로 키를 구성(예: groupingKeyNames 필드에서 동적으로 결정) 유연성 비즈니스 로직 변경에 대응하기 어려움 비즈니스 요구사항 변화에 따라 키 설정을 변경 가능 구현 난이도 단순하고 구현하기 쉬움 상대적으로 복잡하며, 런타임 시 Rule 파싱 및 키 설정 로직 추가 필요 성능 최적화에 유리하며, 실행 시 오버헤드가 적음 키 계산 로직 및 유연성으로 인해 약간의 추가 성능 오버헤드 발생 적용 사례 - Account ID 기반 그룹화- 동일 IP 기반 집계- 사용자별 활동 추적 - 다양한 필드 기반 그룹화 (예: 송신자, 수신자)- 조건에 따라 동적으로 그룹화- Rule 기반 실시간 처리 장점 - 구현 및 유지보수가 용이- 성능 최적화에 유리- 단순한 집계 작업에 적합 - 복잡한 비즈니스 로직을 처리 가능- 유연하고 확장성이 높음- 다양한 Use Case에 적합 단점 - 복잡한 요구사항을 처리하기 어려움- 비즈니스 변화 시 재배포 필요 - 구현이 복잡하고 런타임 오버헤드 발생- 실수로 인해 키 설정 오류 발생 가능 셔플이 발생하지 않도록, 정책에 따라 생성된 SubTask가 동일한 KeyedStream을 사용할 수 있도록 한다 Static 하게 지정된 Key가 아닌 정책에 따라 동적으로 KeyedStream을 생성하거나 재사용하도록 구성하는 방안\n성능이나 코드파악에서는 하드코딩된 명시적인 Key가 관리하기엔 용이할 수 있다. 하지만, 지속가능한 아키텍처를 구현하기 위해서 어느정도의 TradeOff를 감수하고 동적 키 파티셔닝을 구현하는 것임\n*T : Transaction (결제 이벤트를 의미)\nT1_Rule1, T1_Rule2, T1_Rule3 는 Flink SubTask를 의미\n각각은 groupingKey (keyBy)에 따라 셔플링되어 각 네트워크를 통해 SubTask로 전달\n다른 정책, 동일 KeyBy 정책 Evaluate 조건은 다를지라도 Group By하는 Key가 같을 경우, 동일 SubTask 내에서 정책 평가를 진행\n동일 SubTask에 여러 정책을 Evaluate 할 경우, SubTask 내부에서 순차적으로 정책 평가를 진행\n병렬도를 늘리고 싶다면 소스이벤트의 다른 필드를 키로 하여 파티션을 나눌수 있겠지만 그만큼 셔플링으로 인한 오버헤드가 발생됨\n정책을 동적으로 만들 수 있는 파라미터 정의\n필드명 설명 예시 RuleID 정책 고유 ID 78, 889 Aggregation Field 집계 결과가 저장되는 필드 명 id_count, hpid_count Grouping Fields 집계할 필드 ID, IP Aggregation Function 집계 연산 sum, count, avg Window Duration 집계 기간 10m, 10s, 90d Limit 임계치 3, 5 Limit Operator 임계치 연산자 gt, lt, equal Filter 필터링 조건 { \u0026ldquo;filter_option\u0026rdquo;: \u0026ldquo;option_value\u0026rdquo;} e.x \u0026ldquo;정책 2: 로그인 단계에서 3분 이내에 동일 ID의 서로 다른 IP가 4개 초과인 경우 알림\u0026rdquo;\n{ \u0026#34;ruleId\u0026#34;: 2, \u0026#34;ruleState\u0026#34;: \u0026#34;ACTIVE\u0026#34;, \u0026#34;groupingKeyNames\u0026#34;: [\u0026#34;id\u0026#34;], \u0026#34;aggregateFieldName\u0026#34;: \u0026#34;ip\u0026#34;, \u0026#34;aggregatorFunctionType\u0026#34;: \u0026#34;UNIQUE_COUNT\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;action\u0026#34;: \u0026#34;login\u0026#34; }. \u0026#34;limitOperatorType\u0026#34;: \u0026#34;gt\u0026#34;, \u0026#34;limit\u0026#34;: 4, \u0026#34;windowMinutes\u0026#34;: \u0026#34;3m\u0026#34; } Rules BroadCasting REFS : Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic\n앞서 설명한 **DynamicKeyFunction()**은 데이터를 동적으로 파티셔닝하여 셔플링으로 인한 오버헤드를 최소화 DynamicEvaluationFunction() 은 정책에 따른 평가를 수행하는 데이터를 의미\n컴파일 되기 전에 미리 Rules 를 List로 읽어와 실행하는 것은 가능하다\n하지만 컴파일 된 후, 정책 변경 시에 결코 동적으로 정책에 따른 SubTask Operator를 동작 시킬 수 없다\n이를 해결하기 위해 Rules Broadcasting을 구현 Source Topic으로 부터 액션 이벤트를 받아오고, Rule Source를 Broadcast로 병합하여 정책 평가\n만약! 정책 DB가 Soft Delete 이라면 CDC의 disabled 컬럼을 통해 rule_id operator를 드롭하도록 한다 신규 추가된 정책은 새롭게 operator task로 생성한다\nBroadcasting Flow 항목 설명 Payment Event Source 병렬적으로 Kafka 파티션에서 이벤트를 컨슘. Dynamic Key Function DynamicKeyFunction()을 통해 병렬 Task로 파티셔닝. 지정된 키에 따라 복합키 또는 단일키를 해싱하여 네트워크로 데이터 전송 Dynamic Evaluation Function - 필터링 조건에 따라 Data Window를 상태 저장소(State Backend)에 저장- 임계치를 초과하면 Sinking 처리 Restriction Topic 제재(Restriction) Topic으로 제재 정보를 포함하여 발행 *병렬도는 부하 테스트를 통해 Consumer Lag을 최소화하는 병렬도 산정\nRule DB의 CDC는 Broadcast Channel을 통해 main processing data flow에 병합 됨 Broadcast는 각 메시지를 모든 병렬 인스턴스로 뿌림 (key나 source 파티션에 관계없이 모두 전달됨) FDS 시스템에서의 개략적 설계 방안 processBroadcastElement: Broadcast source stream의 이벤트 발생 시 트리거 됨 CDC 로 기존 정책 remove + 새로운 정책 insert processElement: Source stream의 이벤트 발생 시 트리거 됨 현재 활성화된 정책들을 불러와 활성화된 조건 마다 Rule 조건 + Payment 이벤트를 병합한 이벤트를 발행 정책 별 group by 조건에 따라 파티셔닝 됨 (keyBy) Broadcast Stream 에서 읽어온 데이터는 Broadcast State (K/V map)에 상태를 저장한다\nBroadcast Stream에 새로운 메시지가 도착하면 processBroadcastElement() 가 호출된다\n해당 class를 상속하는 DynamicKeyFunction을 구현하면 runtime에 분산 키를 수정할 수 있다\nCustom Window Processing REFS : Advanced Flink Application Patterns Vol.3: Custom Window Processing\nFlink에서는 다양한 유즈케이스에 맞춘 Window API를 제공함\n종류 설명 사용 예시 Tumbling Window - 고정된 간격으로 데이터를 그룹화- 각 윈도우는 겹치지 않고 연속적으로 이어짐 - timeWindow(Time.minutes(1))- 1분마다 평균, 합계 등의 집계 처리 Sliding Window - 고정된 크기의 윈도우가 겹치며 이동.- 슬라이드 간격(slide)에 따라 중복된 데이터를 처리할 수 있음 - timeWindow(Time.minutes(1), Time.seconds(30))- 1분 윈도우, 30초 간격으로 이동하며 집계 처리. Session Window - 데이터가 **활동 간격(session gap)**에 따라 윈도우가 시작되고 종료됨.- 활동 간 데이터가 없는 경우 윈도우가 닫히고 결과 출력. - sessionWindow(Time.minutes(5))- 유저별 활동 세션 분석. 이 중, 고려해볼 Window는 Tumbling과 Sliding Window\nWindow API 사용 시 제약 사항 유형 Tumbling Window Sliding Window 정책 예시 Time Window동안 동일 이벤트가 6번 발생하면 제재한다 Time Window동안 동일 이벤트가 4번 발생하면 제재한다 가정 제약사항 Tumbling Window는 고정된 간격으로 겹치지 않게 이어지기 때문에 탐지할 수 없음 슬라이드 간격에 따라 중복된 데이터가 처리됨, Sliding 간격을 촘촘히 하더라도 정확한 탐지가 불가능 Tumbling Window 예외 케이스 예시 Sliding Window 예외 케이스 예시 가장 큰 제약 사항 Flink API의 sliding window example을 보면, slide S인 sliding window를 쓰면, S/2 만큼의 evaluation delay가 생기게 된다\n윈도우 API의 트리거는 윈도우의 종료 시점에 실행되며, 종료 시점까지는 Delay가 필연적으로 발생한다\n→ Fraud Detection Delay 동안 어뷰저의 Negative action을 방치하므로 회사의 손실을 야기시킨다\nCustom Window Function Implementation DynamicEvaluationFunction()에 대한 구현 Consume Event: Source로 부터 이벤트를 가져옴 DynamicKeyFunction에 따라, 정책 정보 + 액션 이벤트가 함께 이벤트에 포함됨 Add Event: 이벤트를 집계하기 위해 상태 저장소에 현재 이벤트 저장 Get Rule: Broadcast State로 부터 현재 활성화된 정책 불러오기 만약 정책이 존재하지 않는다면 비활성화된 정책임 (처리할 필요 X return) Rule Condition Check: 현재 이벤트가 필터링 조건에 부합하는지 체크 부합하지 않는다면 return Get Window States: 이벤트 시간 기준으로 정책에 등록된 duration 동안 정책을 만족하는 이벤트 집계 Produce Restrict Topic: 집계된 결과가 정책을 만족하면 다음 Enforcement Topic으로 발행 Cleanup: Retention 기간이 만료된 이벤트 제거 Window State에 저장될 이벤트에 대한 고찰 이벤트는 source가 되는 이벤트의 발행 시점 timestamp를 갖게 된다 파티셔닝은 group by 조건에 따라 발생되기에 동일한 timestamp를 가진 이벤트가 여러개가 발생될 수 있다 중복 적재가 되더라도 무관한 자료구조인 Set을 활용하는 것이 바람직. Key는 timestamp\nMapState\u0026lt;Long, Set\u0026lt;PaymentEvent\u0026gt;\u0026gt; windowState; 상태 저장소는 Key Value Store이기 때문에 List Type을 사용할 수 없다\n필연적으로 모든 Map의 timestamp를 순회하면서 만족하는 값을 찾아야 하는데\u0026hellip;\n이 부분에 대한 리서치는 조금 더 필요할 듯 event 전체를 순회하는게 아니라 timestamp만 순회하여 메모리는 크게 이슈가 되지 않을듯 (다만 loop 동안 CPU가 괜찮을까..?)\nEvent Retention에 대한 고찰 보관 기간 즉, Event의 TTL을 어떻게 잡을 것인가 ?\nDynamicEvaluationFunction() 에서는 같은 key scope를 가지는 결제 이벤트를 받을 수 있지만, 다른 Rule에 의해 evaluate되고, 다른 길이의 time window를 가질 수 있다\n그렇기에 Rule Stream (Broadcast Stream)에서 이벤트를 컨슈밍하는 시점에서 가장 긴 Duration을 업데이트할 수 있도록 한다\nex. UpdateWidestWindow\n@Override public void processBroadcastElement(Rule rule, Context ctx, Collector\u0026lt;Alert\u0026gt; out) { ... updateWidestWindowRule(rule, boradcastState); } private void updatWidestWindowRule(Rule rule, BoradcastState\u0026lt;Integer, Rule\u0026gt; broadcastState) { Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY); if (widestWindowRule == null) { broadcastState.put(WIDEST_WRULE_KEY, rule); return; } if (widestWindowRule.getWindowMillis() \u0026lt; rule.getWindowMillis()) { broacastState.put(WIDEST_RULE_KEY, rule); } } 즉 Dynamic Evaluation에서는 가장 Duration이 긴 정책을 기반으로 Event의 TTL을 지정한다\n","permalink":"https://dingyu.dev/posts/flink-dynamic-job/","summary":"정책이 바뀔 때마다 Job Code를 재배포해야만 할까..? 동적으로 Flink Job을 수행하는 법 뽀샤보기","title":"[EDA] Flink Dynamic Job Case Study"},{"content":" MSA 에서 Go App의 조건들 설정 읽기, Graceful shutdown\u0026hellip; 테스트 가능한 코드 API 명세 로깅 프로파일링, 에러 모니터링, 메트릭, API 트레이스, \u0026hellip; 위의 조건들을 만족하는 미니멀리즘 Go의 예시를 나열합니다\nTiny main abstraction 별도의 환경 변수 파일이 아닌, os 환경 변수를 통해 관리하는 예시\n모든 os ARGS를 flag set으로 설정하면 낭비가 심한게 아닌가? Graceful shutdown 테스트 가능한 코드 서버가 뜨기까지 기다리기 위해 long polling 한 뒤에 test 진행 → 클린하진 않다 생각함\n해당 연사자의 메인 포커스는 바닐라 Go 이기에 httptest 패키지 또한 사용하지 않은 것으로 추측\nHealth Check ldflags 옵션을 통해 버전을 지정, 이 부분은 release 단계에서 tag 기반으로 설정하면 좋을 것 같음\nUptime은 Server가 시작된 시간을 남기는 것이 좋다 생각함. (얼마나 서버가 실행중이었는지는 굳이?) Doc is Must 고퍼 가라사대 \u0026ldquo;GoDoc은 권장이 아닌 필수 사항이다\u0026rdquo; godoc은 아니고 openapi 에 대한 API 명세 설명이었다\ngo:embed는 Go 코드 내에서 파일을 임베드할 때 컴파일 시점에 해당 파일의 내용을 바이너리 내에 포함시키는 기능입니다.따라서 go build를 수행할 때, 임베드할 파일이 필요하며, 이 파일이 존재하지 않으면 빌드에 실패합니다. swagger용 API endpoint를 열어두어 임베딩 된 openapi를 노출시킨다\nAPI 수정을 하면 필연적으로 swagger 수정도 필요함.. 유지가 가능할지 의문이 듦 (swaggo를 사용하는게 더 직관적이지 않나)\nLogging is a Must 로그머스트 😊 slog를 활용하여 JSON 로그를 채택하고 있다 (모던 애플리케이션에서는 필수인듯)\nStdout으로 충분하다. 12 factor app에서도 소개 되었듯 로그는 스트림으로서 관리하자! FileIO에 드는 리소스도 절감!\n센트리, 예거, ES 여러개의 output을 두어 로그 기반의 후처리는 fluentbit에게 위임한다\n센트리 : 에러 트래킹 예거 : API 트레이싱 ES : elasticsearch 적재 → 키바나 연동하여 로그 확인 Decorate HTTP 상태코드와 Bytes 트래킹 (기존 ResponseWriter를 임베딩하여 확장)\n후기 앞선 프로젝트 구조와 정반대의 성향임을 느꼈다. 클린 아키텍처에 집착하지 않고 Go 만의 색을 입힌 미니멀한 프로젝트 구성에 납득됨 어느정도의 타협은 필요하다. 바닐라 Go는 컨셉이라 느껴졌고 상용화된 프레임웍을 사용하더라도 깔끔하고 간결한 코드를 짤 수 있다. 오히려 코드의 량은 줄어들듯 Fluentbit 도입이 되었으면 좋겠다. 다양한 필터 처리에 따른 Output으로 애플리케이션에서 log에 대한 결합도를 확실히 낮출 수 있다 생각한다. 전사적으로 예거, opentelemetry와 같이 트레이싱을 도입하는 게 좋을 것 같다. 이는 CTO가 있다면 다소 강압적으로라도 전사적으로 도입이 되어야 한다 생각 ++ 실제 프로덕션 코드에 적용하기 // HealthHandler : 서버 상태 확인 핸들러 type HealthHandler struct { version string startTime time.Time } // NewHealthHandler : 서버 상태 확인 핸들러 생성자 func NewHealthHandler(version string) HealthHandler { return HealthHandler{ version: version, startTime: time.Now(), } } // Check : 서버 상태 및 빌드 정보 확인 func (h HealthHandler) Check(ctx *gin.Context) { type responseBody struct { Version string `json:\u0026#34;version\u0026#34;` Uptime string `json:\u0026#34;up_time\u0026#34;` LastCommitHash string `json:\u0026#34;last_commit_hash\u0026#34;` LastCommitTime time.Time `json:\u0026#34;last_commit_time\u0026#34;` DirtyBuild bool `json:\u0026#34;dirty_build\u0026#34;` } var ( lastCommitHash string lastCommitTime time.Time dirtyBuild bool ) { buildInfo, _ := debug.ReadBuildInfo() for _, kv := range buildInfo.Settings { if kv.Value == \u0026#34;\u0026#34; { continue } switch kv.Key { case \u0026#34;vcs.revision\u0026#34;: lastCommitHash = kv.Value case \u0026#34;vcs.time\u0026#34;: lastCommitTime, _ = time.Parse(time.RFC3339, kv.Value) case \u0026#34;vcs.modified\u0026#34;: dirtyBuild = kv.Value == \u0026#34;true\u0026#34; } } } up := time.Now() ctx.JSON(http.StatusOK, responseBody{ Version: h.version, Uptime: up.Sub(h.startTime).String(), LastCommitHash: lastCommitHash, LastCommitTime: lastCommitTime, DirtyBuild: dirtyBuild, }) } ","permalink":"https://dingyu.dev/posts/gopher-con-2024-minimalistic-go/","summary":"불필요한 프레임워크는 이제 그만\u0026hellip; 튜닝의 끝은 순정일세~ 바닐라 Go를 통해 미니멀리스틱 App 개발하는 법","title":"[Go] Gophercon 2024 - Building Minimalistic Backend Microservice in Go"},{"content":" 작은 프로젝트 트래픽이 적다 → 사용자 풀이 확보되지 않음 기능이 단순하다 → 신규 서비스로 초기 유저 상태가 정의되지 않음 빠른 개발이 필요하다 → 신규 기능이지만 실험적으로 소수의 유저를 통해 가설 검증이 필요한 상태 간단한 CLI 인 경우 간단한 API 서버를 만드는 경우 단순하게 접근, 기본 라이브러리를 활용하여 API를 연동하여 작게 붙여나가는 방식\n기능 단위의 프로젝트 코드 패턴 Handler Struct (Class)을 활용한 DI 방식 Method 단위로 필요한 파라미터의 경우 → func input 파라미터 활용\nHTTP Handlerfunc에 DI를 주입하는 방식 내부에서 클로저를 사용하여 service DI를 참조할 수 있음\n간결하고 클로저 내부에 필요한 의존성만 포함할 수 있어서 테스트에 용이한 구조\n항목 장점 선택 기준 Handler - 복잡한 상태를 관리하기 쉬움- 의존성과 상태가 구조체 필드로 명시되어 명확함- 확장성 측면에서 관련 메서드를 쉽게 추가할 수 있음- 다른 인터페이스를 쉽게 구현할 수 있음- 복잡한 로직을 구조화할 수 있음 복잡한 비즈니스 로직, 많은 의존성, 상태 관리가 필요한 경우 HandlerFunc - 간단한 핸들러를 빠르게 작성 가능- 의존성 주입이 쉽고 클로저를 활용할 수 있음- 함수형 프로그래밍 가능, 함수 조합과 고차 함수 활용 용이- 빠른 프로토타이핑- 의존성 모킹이 쉬워 테스트 코드 작성이 용이 간단한 핸들러, 빠른 개발이 필요한 작은 App 혹은 마이크로서비스 엔터프라이즈 서비스를 위한 코드 패턴 Layered Architecture 적용 Presenter = Domain Model ↔ API Model Handler = API Model 서빙 HTTP/gRPC 요청 처리와 응답 생성에만 집중 프레젠테이션 계층(Handler)과 애플리케이션 계층(Usecase)이 명확히 구분됨 Usecase = 비즈니스 로직 수행 Service 또는 Repository를 의존성으로 받아 느슨한 결합 유지 → 말만 다르지 서비스인듯? 순수한 도메인 객체를 사용 → API Model 이나 Repository 모델을 사용하지 않음 (Service) = 비즈니스 로직 수행 Usecase의 복잡성이 증가하면 구분 → 여러 서비스에 의존적인 도메인 서비스가 있는 경우 서비스들을 분리 Usecase는 흐름 제어와 조정에 집중, Service는 구체적인 비즈니스 로직 구현에 집중 → xxxExecutor 패턴과 동일 Repository = Domain Model의 CRUD 담당 데이터 접근 로직만을 담당 상위 계층(Usecase 등)이 구체적인 저장 방식을 알 필요가 없음 도메인 모델을 반환, Repository가 도메인 계층에 의존하게 되어 의존성 역전 원칙을 따름 (Recorder) = DB Model 핸들링 주로 DB의 형태가 다양한 경우 (NoSQL, RDBMS\u0026hellip; etc) 각 DB에 의존적인 로직을 구현 다른 DB 마이그레이션 시, recorder DI를 갈아끼우는 방식 채택 각 레이어에서의 테스트 코드 Mocking 라이브러리 counterfeiter를 사용\n특징 go mockery counterfeiter 목 생성 자동 목 생성이 간편하며 매개변수 설정이 용이 페이크 객체를 포함하여 좀 더 복잡한 시뮬레이션 가능 설정 용이성 단순하고 직관적인 설정 가능 복잡한 테스트 시나리오에 적합 테스트 유지보수 간단한 인터페이스에 적합 페이크 객체로 장기적인 테스트 유지보수 용이 적합한 상황 단순하고 독립적인 모듈 테스트 복잡한 구조와 다양한 응답이 필요한 테스트 모킹된 fakes 들은 fake가 속한 레이어에 포함 하더랍니다\n후기 Go 생태계에서 구조적으로 다양한 시도들이 있었지만 이렇다 할 만한 구조는 찾지 못하였는데 충분히 참고할 여지가 있는 구조인 것 같다 레이어드 아키텍처를 구현하기 위해 불필요한 데이터 type 변환이 발생하지 않을까? (ex. Presentation, Business, Data 각각 하나씩이라 해도 API 하나에 데이터 struct 3개를 사용해야함) service와 usecase를 나누는 기준은 service가 두개 이상이냐?에 따라 갈리는 듯 APM을 도입한다 했었는데 비용적인 측면은? → 모든 곳에서 APM을 적용하진 않는다, 비즈니스 크리티컬한 로직에 APM을 삽입하고 있다 ","permalink":"https://dingyu.dev/posts/gopher-con-2024-go-project-guide/","summary":"Spring과 같이 규격화 되어 있지 않은 Go 언어에서 프로젝트를 구성하는 방법.. 피쳐 단위 개발 그리고 엔터프라이즈 App까지 설계에 대한 개략적인 사례를 소개함","title":"[Go] Gophercon 2024 - 고언어 프로젝트 가이드 A-Z"},{"content":"쿠버네티스 API 쿠버네티스 플랫폼과 상호작용할 수 있는 인터페이스 사용자, 관리자, 애플리케이션이 클러스터 및 리소스를 관리하는 목적으로 사용가능 리소스 목록을 얻거나 생성하는 일련의 작업 수행 가능 애플리케이션 배포 및 상태 모니터링 기능 제공 HTTP API 형태로 제공되어 다양한 언어 및 도구 지원 https://\u0026lt;APISERVER\u0026gt;/\u0026lt;GROUP\u0026gt;/\u0026lt;VERSION\u0026gt;/\u0026lt;RESOURCE\u0026gt;/\u0026lt;NAME\u0026gt;\nAPI SERVER : API 서버 주소 GROUP : 리소스 그룹 /api : 쿠버네티스 코어 API 그룹 기본적이고 필수적인 리소스 : Pod, Service 등 /apis/* : 쿠버네티스 확장 API 그룹 애플리케이션 배포 및 확장 기능에 관계된 리소스 VERSION : v1 (안정 버전), v1beta, v1alpha1 RESOURCE : 접근하려는 리소스 종류 (/pods, /services) NAMESPACE : 리소스가 속한 네임스페이스 이름 네임스페이스 범위 리소스를 네임스페이스 조건을 빼고 조회하면 모든 네임스페이스 검색 NAME : 접근하려는 리소스 이름 지정 client-go 라이브러리 쿠버네티스 API 호출을 추상화해 사용하기 편하게 제공\n쿠버네티스 코어 그룹과 확장 그룹 모두 접근 가능\n기본 리소스 외 사용자 정의 리소스 접근 및 사용 가능 클러스터 내부/외부에서 초기화 기능 지원\n리소스 변경 사항을 캐싱하는 Informers등 다양한 기능 지원 Pods(\u0026quot;\u0026quot;)로 조회할 경우, 모든 네임스페이스 조회 가능 (단, 접근 권한을 가진 네임스페이스 한정) Deployment 리소스를 동시에 변경하는 경우 가장 먼저 도착한 변경 사항은 적용되고 나머지는 실패 → First Updater Wins! MVCC와 유사하다고 생각됨. version 충돌을 검사하여 충돌 방지 (lost update 발생되지 않음) 서로 다른 서버에서 동시에 이미지 변경 시도 → 한 요청이 성공하면 다른 요청은 Conflict 에러와 함께 실패\n낙관적 동시성 Step 1 Step 2 Step 3 변경 요청을 전송하면 리소스 버전을 이용해 충돌 감지 저장된 리소스 버전과 동일한 버전을 가진 변경 사항을 적용 리소스 버전이 다른 수정 사항은 충돌 실패 MVCC와 유사하게 버전 충돌로 인한 에러의 경우 Retry 설정을 통해 해결\nretry.RetryOnConflict() 함수를 이용해 간단하게 사용 가능!\n쿠버네티스 컨트롤러와 오퍼레이터 컨트롤러\n쿠버네티스 기본 리소스를 주로 관리하는 목적 Pod, Deployment, Service 등의 리소스 관리 오퍼레이터\n사용자 정의 리소스를 통해 복잡한 상태 관리 가능 애플리케이션 배포 및 관리 자동화를 위해 사용 kubebuilder 프레임워크 쿠버네티스 컨트롤러 혹은 오퍼레이터를 개발하기 위한 Go 프레임워크 사용자 리소스 관리 스크립트 및 컨트롤러 기본 코드 제공 오퍼레이터를 통해 관리하려는 대상에 집중 가능 client-go 라이브러리를 이용해도 됨 → 하지만 매우 복잡한 작업이 필요 Process : 애플리케이션 설정 및 초기화 Manager : API 서버와 통신, 이벤트 캐시, 메트릭 노출, \u0026hellip; Webhook : 리소스 초기화, 데이터 검증을 진행할 웹 훅 설정 Controller : 리소스 이벤트를 필터링해 Reconciler 호출 Reconciler : 사용자 리소스를 관리하는 실질적인 로직 구현 SPEC : 리소스 특징 및 원하는 상태 지정 Status : 리소스 현재 상태 표현 컨트롤러 옵션 설정 리소스가 변경될 때 호출되는 Reconcile() 함수 관련 설정\n변경 감지 리소스, 필터, 성능 옵션 등 다양한 설정 변경 가능 Spec 속성이 변경될 때만 Reconcile() 함수가 호출되도록 Generation 필드를 사용하는 이벤트 필터 설정\nReconcile() 함수가 동시에 몇 개까지 실행될 수 있는지 컨트롤러 옵션을 이용해 설정\nReconcile() 함수가 호출되는 상황 처음 오퍼레이터가 실행되는 경우 모든 리소스를 순회하면서 Reconcile() 함수 호출 리소스가 변경되는 경우 일반적으로 리소스 필드가 변경되면 호출 Spec 속성이 변경될 때만 호출되도록 설정 가능 후기 일반적인 케이스에서 CPU 와 메모리를 통한 오토스케일링이 기본적으로 설정되어 있다. 하지만 애플리케이션의 특성에 따라 이를 커스텀하게 변경하는 것도 고려해보면 좋을 것 같다. 예를 들어 큐에서 하나의 일을 순차적으로 처리하는 서버일 경우, Queue Size Limit을 검사하여 오토스케일링이 가능할 듯 하다 동시로 배포를 요구하는 상황은 없겠지만 Conflict로 인한 실패를 커스텀 컨트롤러에서는 방지할 수 있을 것이다. 런덱을 매번 생성해달라 할 필요 없이, daemon set으로 오퍼레이터를 띄워, 자동화를 거칠 수 있지 않을까? (위험 부담이 있긴 할 것같다) ","permalink":"https://dingyu.dev/posts/gopher-con-2024-kubernetes-programing/","summary":"go 기반으로 k8s API를 사용하는 법\u0026hellip; 오퍼레이터로 배포하는 애플리케이션","title":"[Go] Gophercon 2024 - 쿠버네티스 플랫폼 프로그래밍"},{"content":"\npprof 적용은 pprof로 GC 튜닝하기를 참고 해주세요\n배경 비즈니스 요구사항에 따른 서비스를 수행하는 서비스 서버를 **\u0026ldquo;서비스 서버\u0026rdquo;**라 칭합니다\n[AS-IS] 서비스 서버에서는 매번 단 건의 HTTP Request로 서버내에서 발생한 이벤트를 발행하고 있었습니다 비동기로 HTTP 요청을 수행하고는 있었지만, HTTP 요청 수에 비례하여 Batch Loader 응답지연 시간이 리니어하게 증가하고 있었습니다. 문제 과도한 네트워크 요청 : 이벤트가 발생할 때마다 HTTP 요청을 보내므로, 이벤트 발생 빈도가 높아질수록 네트워크 트래픽이 과도하게 증가 레이턴시 증가 : 요청이 많아지면 큐잉이 발생하여 응답 시간 지연 확장성 부재 : 다수의 서비스에서 제각각의 구현 방식으로 Batch Loader에 적재중. HTTP 요청이 아닌 이벤트 스트리밍 기반으로 확장하였을 때, 불필요하게 반복적인 수정 작업을 다수의 서버에서 진행하게 됨 [TO-BE] 문제 해결 과도한 네트워크 요청 해결 : 서비스 서버 내에서 이벤트에 대한 큐를 두어, 최대 버퍼 limit을 초과 하거나 Batch 주기에 도달하는 경우, buffer를 Batch Loader로 이벤트 발행. 오버헤드인 HTTP Request 를 최소화 레이턴시 증가 해결 : 서버에서 지정해둔 Interval Duration에 따라 buffer를 모아 요청하기에 큐잉으로 인한 레이턴시 증가는 해결됨. 확장성 증가 : 서비스 서버에서 사용할 공통 라이브러리를 Repository로 구축하여, Batch Loader 서버의 변경 또는 확장에 따른 서비스 서버들의 반복적인 수정 작업을 최소화. Batch Loader 서버와는 느슨한 결합을 갖도록 함 해결 방안 Batch Loader 서버와는 느슨한 결합을 가지도록 공통 라이브러리를 구축하는 의사 결정 완료 공통 라이브러리에서 이벤트 버퍼를 모아 요청을 하는 모듈을 **\u0026ldquo;Batch Processor\u0026rdquo;**라 칭합니다.\n요구사항 IO Bound Task를 최소화 goroutine 생명주기를 제어 가능해야 함 1안 : Worker Pool 방안 여러개의 worker들이 각각의 Interval Duration 동안 내부적인 버퍼를 채워 동기적으로 API로 요청하는 방안\nPros deep copy가 발생되지 않는다 성능 개선을 위해 Worker Pool을 튜닝할 수 있다 Cons Interval Duration 주기로 Worse Case Worker Pool 수 만큼 HTTP Request 발생 서비스 서버는 Worker Pool의 Magic Number를 찾기 위해 테스트를 진행해야함 2안 : 하나의 Worker + Async HTTP Request Pros Interval Duration 동안 한번만 HTTP Request 발생 Worker Pool Magic Number를 찾기 위한 테스트가 불필요 Cons deep copy로 인한 CPU 부하 가능성 (byte array size 만큼 순회하면서 값 할당) deep copy로 인한 Memory 부하 가능성 (byte array를 copy하면서 추가적인 힙 할당) GC 동작 방식에 따라, 복사된 buffer memory로 인한 GC Trigger -\u0026gt; Stop the World 로 인한 서비스 서버의 지연 가능성 고려 두가지 비교군 중, 공통 라이브러리를 구성하는 것에 있어 사용성이 보장되어야 하기에, 2안이 적합한 방안이라고 생각되었습니다.\n하지만 deep copy로 인한 CPU / memory 상의 오버헤드가 어느정도이고, 영향도가 없을지 검증이 필요했습니다.\n프로파일링 프로파일링 목표 분당 처리량: 1분간 2000 RPS 요청 처리 가능 수 메모리 사용량: deepCopy()로 인한 메모리 부하 확인 GC 발생 오버헤드: 메모리 복사 과정에서의 GC 확인 deep copy 코드\nfunc deepCopy[T any](src []T) []T { if src == nil { return nil } dst := make([]T, len(src)) copy(dst, src) return dst } 테스트 방법 10, 100개의 Worker Pool + Sync IO 방안과 하나의 Worker + Async IO 방안의 테스트를 진행합니다.\n각 비교군은 CPU Profile을 활성화하여 docker image를 빌드합니다.\n분당 처리량 : 1분간 2000 RPS의 요청을 몇개까지 처리 가능한가? API 호출 이후 호출된 Event의 개수 로깅 메모리 : deepCopy()로 인한 메모리 부하가 얼마나 생기는 지 확인 메모리 copy 과정에서 GC 발생으로 인한 오버헤드 확인 heap Profile을 통한 관측 curl {endpoint}/debug/pprof/heap\\?seconds\\=30 --output {output_path} 처리된 개수는 어떻게 세나요? API send() 메서드 중 로깅을 통해 확인\nfunc (q *BatchProcessor) send(payload []byte, traceIDs []string) { ... response, err := q.client.Do(request) ... q.logger.Info().Int(\u0026#34;count\u0026#34;, len(traceIDs)).Send() } count를 파싱하여 stop 이전에 처리된 개수를 확인 합니다\n[e.g.] logfile 예시\nlog file ( sum = \u0026hellip; + 1020 + 1000 ) ... 2024-10-14T05:11:06Z INF count=1020 2024-10-14T05:11:07Z INF count=1000 2024-10-14T05:11:07Z INF stopping BatchProcessor, waiting for remaining events to be sent func=BatchProcessor.Stop 2024-10-14T05:11:07Z INF count=288 CPU Profile selectgo : select 구문 중 여러 채널에서 데이터를 동시에 기다리면서 그 중 하나가 준비되면 해당 작업을 수행하는 기능\n채널 1: queue 에서 Pop()하여 stack buffer에 적재, buffer maxlimit을 초과하는 경우 API 전송 및 buffer Flush 채널 2: time.Ticker 일정 시간 마다 내부 버퍼 스택으로 API 전송 및 Flush 채널 3: 종료 시그널을 받아, 남아있는 버퍼 스택을 API 전송 및 고루틴 종료 Worker Pool (100) + Sync IO runWithSync() 분석\n각 worker들은 공유 자원인 queue 채널을 소비하며, 워커의 수가 많아질 수록 내부적인 lock과 acquireSudog(채널 수신 대기)에 드는 비용이 발생 runtime 스케쥴러에 의해, 동시성 처리에 드는 비용이 예상외의 오버헤드 selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 85% Worker Pool (10) + Sync IO runWithSync() 분석\nsellock 비율이 100 worker pool에 비해 현저히 감소하는 것을 확인 selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 66% 하나의 Worker + Async IO run() 분석\ndeepCopy(그림 중 runtime.memmove)로 인한 오버헤드는 10ms selectgo 중, 오버헤드인 runtime.recv (외부 API 호출 시, goroutine 준비 작업)+ deep copy의 비율은 50% Heap Profile run() / runWithSync() 함수가 실행되는 동안 수행되는 DeepCopy에 초점을 맞추어 프로파일링\nWorker Pool deepCopy() 로 인한 오버헤드 없음\n100 workers 중 8.2MB 중 HTTP Request가 7.7MB 소모 하나의 Worker + Async IO 총 12.21MB의 run 과정 중 내부 버퍼를 쓰는 작업인 Write를 제외한 오버헤드를 산정\nworker run / Request 비율 100 worker pool 중, 8.2MB:7.7MB 12.21MB 인 경우 11.4MB가 HTTP Request에 사용 deepCopy에 드는 오버헤드는 150kB (1.22%) 매우 미미한 수준 테스트 결과 분류 분당 처리량 CPU 오버헤드 메모리 오버헤드 10 worker 83,663 66% 0% 100 worker 84,042 85% 0% 1 worker + async 119,720 50% 1.22% 정리 Worker Pool을 사용할 경우, Queue의 동시성 처리를 위해 사용되는 오버헤드가 상당하다 Worker Number를 늘리더라도 동시성 처리 오버헤드가 상승되기에 number of worker 와 처리량은 리니어하게 상승하진 않는다 IO Bound Task를 수행할 경우, Worker Pool 보다는 비동기로 처리하는 것이 성능상의 이점이 크다 CPU Bound Task의 경우, runtime에 의해 goroutine 이 수행되기 까지 대기 시간이 걸리기에 worker pool을 사용하는 것이 좋다 순서가 보장되어야 하는 경우에는 IO Bound Task 일지라도 Worker Pool을 사용하는 것이 좋다 ","permalink":"https://dingyu.dev/posts/worker-pool-async/","summary":"여러개의 워커가 동시에 일을 나눠 받고 처리하는 것이 좋을까? 아니면 비동기로 매 작업을 수행하는 것이 좋을까? 긴가 민가해서 알아보았다","title":"[Go] Worker Pool과 비동기 작업의 성능 프로파일링"},{"content":" 소스 코드 : https://github.com/dings-things/coffee_pal\n목적 일을 하는 것에서 그치는 것이 아닌, 일을 잘 하고 싶은 조직에서 좋은 문화를 구성하는 것은 일의 생산성이나 품질에도 여러 이점을 가져온다\n필자가 개발하고자 하는 \u0026ldquo;CoffeePal\u0026quot;은 문제에 막혀 길을 잃어버린 사람이나 소소한 스몰 토크로 일에도 능률을 키울 수 있는 그러한 앱을 만들 고자 커피 친구라는 의미에서 커피팔을 기획하게 되었다\n개발에 앞서\u0026hellip; 먼저 사내 커뮤니케이션 툴인 Slack에서 상호작용을 통해, 쉽고 빠르게 커피 친구를 매칭해줘야 하는 요구사항이 있다\n이에 앞서 간단하게 Slack Workflow를 통하여, 전반적인 흐름을 파악해 본다\nTrigger Point 생성 테스트 용이기 때문에, Trigger는 :커피: 이모지로 반응하였을 때 워크플로가 실행 되도록 한다\n활성화 하기 반응한 메시지를 전송한 사용자에게 메시지를 보내어, 커피팔 매칭을 시작할 지 여부를 확인한다\n양식에서 정보 수집 개인화된 서비스를 위해 MBTI, 생년월일을 입력 받는다. 해당 데이터의 기입은 Optional 하게 만든다\n대상, 일시, 주제를 지정한다 커피팔 대상과 커피 일정, 그리고 전반적인 주제를 사전에 정의한다.\n커피팔 대상에게 초대 메시지 보내기 앞서 지정한 데이터를 통해 커피팔에게 간략하게 초대 메시지를 보낸다\n개인적으로 Slack 워크플로를 처음 사용해 보았는데, UI가 깔끔하고 사용성이 괜찮음을 느꼈다\n다만, 사용자와 \u0026ldquo;상호작용\u0026quot;이라기 보다는, 일방적인 소통에 가깝기 때문에 slack app으로 확장 해보도록 한다\n먹고 싶지 않은 음식을 억지로 먹여주는 느낌\u0026hellip; 이랄까요?\n요구사항 미리 저장된 데이터를 기반으로 사용자 기반의 매칭을 할 수 있어야 한다\n개인정보 입력 시, 매칭 시스템 Trigger App을 사용한 상호작용을 위해 컴퓨팅 리소스를 확보한다\n사내 서버 방화벽 관리 어려움 소켓 통신을 통한 빠른 응답 AWS Lambda 프리티어 기준 무료 서버리스 AWS API GW와 연계 가능 프리티어 종료 후, 유지 비용 고려 사용자에게 한눈에 봐도 알 수 있는 UI 제공\nSlack Block kit 활용 구축하기 Lambda로 구축하기 Slack APP 생성 Lambda 설정 Socket Mode 설정 Slack APP 생성 1. App 생성하기 slack API에서 App 생성하기 Slack APP 생성 2. From scratch를 클릭 Slack APP 생성 3. 앱 workspace와 이름 지정하기 Slack APP 생성 4. 유저 상호작용을 위한 봇 설정 Slack APP 생성 5. 이벤트 활성화 Lambda 설정 1. Lambda 페이지에서 함수 생성하기 Lambda 설정 2. 함수 설정, 런타임 및 아키텍처 설정 Lambda 설정 3. API Gateway 설정 API Gateway는 HTTP 요청을 Lambda 함수로 라우팅 할 수 있는 매우 유용한 트리거입니다. Slack Events API와 Lambda를 연동하기 위해서는 API Gateway를 통한 설정이 필요합니다.\n라고 생각하던 와중\u0026hellip; 서버가 이미 있다면 굳이 람다로 구현을 해야하는가? 이미 있는 서버를 안쓰는 것이 더 낭비가 아닌가? 🤔 고민에 빠졌습니다\n서버는 남는 개발 서버를 활용하여 처리를 하고 소켓 모드로 일괄 처리하는 방안을 생각하게 되었습니다\nSocket Mode 설정 소켓 모드란? 소켓 모드를 켜면 이러한 페이로드를 공개 HTTP 앤드포인트인 요청 URL로 보내는 대신 WebSocket 연결을 통해 앱의 상호 작용과 이벤트를 라우팅합니다. 앤드 포인트를 사용하지 않음으로서 여러 요청에 대한 보안적인 위협을 피할 수 있습니다. 또한 여러 Event에 대해 일일이 구독을 하지 않아도 됩니다\n1. 애플리케이션 전역 토큰 생성 전역 토큰에 권한을 부여 → 서버 내에서 권한을 사용하여 슬랙 제어 2. 토큰의 Scope 지정 channels:read : 채널의 사용자 정보 취득 chat:write : 채널에서 쓰기 권한 chat:write.public : 채널에 invite 되어 있지 않아도 쓰기 권한 groups:read : private 채널 정보 취득 groups:write : private 채널에 쓰기 권한 im:write : DM 발송 권한 mpim:write : group DM 발송 권한 reminders:write : 리마인더 설정 권한 개발 Slack Bolt Slack 애플리케이션을 개발하기 위한 프레임워크 주로 Node.js, Python, JavaScript와 같은 언어로 작성되었으며, Slack 플랫폼과 통합된 애플리케이션을 쉽게 만들 수 있도록 도와줍니다.\n굳이\u0026hellip;? 싶지만\u0026hellip;\n안쓰면 불필요한 작업이 너무 많아집니다. 이는 곧 낮은 생산 속도, 유지 보수도 힘들어지죠\n쓰지 않을 때 from slack_sdk import WebClient from slack_sdk.errors import SlackApiError import os import json import base64 import urllib.parse def lambda_handler(event, context): bot_token = os.getenv(\u0026#39;BOT_KEY\u0026#39;) # 토큰으로 인증 client = WebClient(token=bot_token) # Base64 인코딩 여부 확인 및 디코딩 if event.get(\u0026#39;isBase64Encoded\u0026#39;, False): try: # Base64 인코딩된 본문을 디코딩하여 문자열로 변환 decoded_body = base64.b64decode(event[\u0026#39;body\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;) event_body = urllib.parse.unquote_plus(decoded_body)[8:] except Exception as e: print(f\u0026#34;Error decoding base64 body: {e}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps({\u0026#39;message\u0026#39;: \u0026#39;Invalid base64 encoded body\u0026#39;}) } ele: event_body = event[\u0026#39;body\u0026#39;] print(event_body) # 디코딩된 본문을 JSON으로 파싱 try: event_data = json.loads(event_body) except json.JSONDecodeError: print(\u0026#34;JSONDecodeError occurred. The body may not be in valid JSON format.\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps({\u0026#39;message\u0026#39;: \u0026#39;Invalid request body\u0026#39;}) } # Event 타입 확인 event_type = event_data.get(\u0026#39;event\u0026#39;, {}).get(\u0026#39;type\u0026#39;) # Event 타입에 따라 분기로 처리 쓸 때 app = App(token=settings.SLACK_BOT_TOKEN) logger = logging.getLogger(__name__) # app_home_opened 이벤트 핸들러 등록 @app.event(\u0026#34;app_home_opened\u0026#34;) def handle_app_home_opened( event: Union[ str, Pattern, Dict[str, Optional[Union[str, Sequence[Optional[Union[str, Pattern]]]]]], ], client: WebClient = None, ) -\u0026gt; SlackResponse: ... # 버튼 액션 핸들러 등록 @app.action(\u0026#34;suggest_coffee_chat_button\u0026#34;) def handle_random_coffee_chat_button( ack, body, client: WebClient = None ) -\u0026gt; SlackResponse: ... 특정 이벤트 / 액션 / 뷰 를 디버깅 할 때에 Bolt를 활용하면 인증, event, action에 따른 분기 처리, 미들웨어 설정 등등\u0026hellip;\n서비스 로직을 수행하기전 거쳐야 했던 중복되는 과정들을 생략하고 서비스 로직에 집중할 수 있습니다.\n유지보수 ↑ 가독성 ↑ Bolt에서 제공되는 기능 중 크게 5가지를 사용하게 됩니다.\nmiddleware 앱 전반의 로깅 및 인증 관리 action 버튼 클릭, Select 메뉴 등의 상호작용 시 발생 view 모달과 같은 복잡한 인터페이스를 생성 및 관리 event Slack 워크스페이스 내에서 발생하는 다양한 이벤트. 가령 채널에 참가 / 사용자의 메시지 전송 등등 Block Kit 슬랙 앱 개발의 꽃은 역시 Block Kit이라 말할 수 있습니다. 각 화살표는 Block을 나타내며 type에 따라 구분되는데 이를 Stacking 하여 하나의 View를 형성합니다.\nex.\nHOME_OPENED = { \u0026#34;type\u0026#34;: \u0026#34;home\u0026#34;, \u0026#34;blocks\u0026#34;: [ ... ], } HOME 구성 요소 Section 섹션을 활용하여 직관적인 UI로 사용자 경험을 최적화 합니다\n가로 섹션 세로 섹션 Input Slack API는 Restful API 답게 Stateless (무상태성)을 띕니다. 각 요청이 독립적이며, 서버가 클라이언트의 이전 요청에 대한 정보를 유지하지 않는것이죠\nInput 없이는 유저의 이전 View에서의 상태를 알 수 없기 때문에 상호작용이 불가합니다. 랜덤 커피챗을 예로 들어 보겠습니다 서버가 만약 순간적인 단절이 생겼을 때에도 다시 요청 시, 이전 Input 값을 토대로 무상태성 요청을 보낼 수 있어\n안정성이 보장됩니다\n개선 사항 Slack DataStore를 이용한 유저의 상태 값 저장 TTL을 지정하여 예약된 커피챗 일정의 조회 / 수정 / 삭제 기능 인사정보를 조회하여 나만의 맞춤형 커피팔 선정 인사 API 권한을 얻어 직급 / 나이 / 직군 별 맞춤형 커피팔을 추첨하는 기능 UI 개선 딱 봐도 이거네~ 누구나 알기 쉽게 사용자 편의성을 고려한 View 구성 CI/CD 및 인프라 구성 허락을 구한다면.. 별도 인프라로 full time 사용가능한 앱 구성 CI CD 파이프라인으로 누구나 기여하여 새로운 기능을 추가하도록 오픈소스화!! 마치며 개발자로 살아오며 “우분투\u0026rdquo; 정신에 깊게 공감하고 있었습니다\n\u0026lsquo;우리가 함께 있기에 내가 있다(I am because you are)\u0026rsquo;\n우리가 함께할 수 있는 환경을 구성하는 것도 중요하다 생각됩니다. 모든 이가 소통에 두려움을 느끼지 않고 \u0026ldquo;함께\u0026quot;가 되었으면 하는 마음에\n커피팔 을 만들게 되었습니다 기술적인 어려움에 부딪히거나, 보다 긴밀한 협업을 위해 아이스 브레이킹이 필요하시다면 여러분도 슬랙봇을 만들어 보세요 :)\n","permalink":"https://dingyu.dev/posts/coffee-pal/","summary":"나 개발잔데 옆에 사람이랑 슬랙으로 대화한다.. 우리 이제 친해져요","title":"[DX] 사내 커피 챗 슬랙 봇 개발기"},{"content":"pprof 적용 import \u0026#34;github.com/gin-contrib/pprof\u0026#34; // init server var ( router *gin.Engine ) { router = gin.New() // pprof 라우터 등록 pprof.Register(router, APIPrefix+\u0026#34;/debug/pprof\u0026#34;) } Script echo \u0026#34;User API v1.2.3\u0026#34; # 프로파일링 curl https://{endpoint}/debug/pprof/trace\\?seconds\\=10 --output v1.2.3-trace.out \u0026amp; curl https://{endpoint}/debug/pprof/heap\\?seconds\\=10 --output v1.2.3-heap.prof \u0026amp; curl https://{endpoint}/debug/pprof/profile\\?seconds\\=10 --output v1.2.3-cpu.prof \u0026amp; # 부하를 준 상태에서 GET 요청 수행 bombardier -t 1s -l -c 30 -d 10s\\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -m GET https://{endpoint}/v1/users/51387659 wait # go tool 활성화 -\u0026gt; port에서 각 프로파일 실행 go tool trace -http 127.0.0.1:9094 v1.2.3-trace.out \u0026amp; go tool pprof -http 127.0.0.1:9095 v1.2.3-heap.prof \u0026amp; go tool pprof -http 127.0.0.1:9096 v1.2.3-cpu.prof \u0026amp; bash의 \u0026amp;는 비동기로 다른 작업이 수행됨 PPROF의 기본 프로파일링 방법\npprof 라우터가 등록된 애플리케이션을 실행시킨다 기존 부하가 없는 경우라면.. 테스트하고자 하는 API Endpoint의 부하테스트 진행 curl 요청을 통해 필요한 프로파일링을 시작 ※ LB의 Timeout이 있는 경우, 해당 Timeout보다 작게 산정하여야 프로파일 데이터를 받을 수 있습니다\nHEAP 프로파일링 inuse_objects: 현재 사용 중인 객체의 수 inuse_space: 현재 사용 중인 메모리 양 alloc_objects: 프로그램이 시작된 후 할당된 총 객체 수 alloc_space: 프로그램이 시작된 후 할당된 총 메모리 양 Inuse Alloc 지표 확인 시 주의사항 e.g. Inuse와 Alloc의 할당된 메모리가 같은 케이스 Inuse가 1GB / Alloc이 1GB인 객체는, 처음 한번 할당된 이후 계속 사용 되고 있다는 뜻 → GC 개입 없음을 의미 → CPU 효율적\ne.g. Inuse보다 Alloc이 많이 할당된 케이스 Inuse가 1GB / Alloc이 1TB인 객체는, Heap 메모리를 객체에 1024번 할당했다는 뜻 → GC 가 1024번 발생됨 → GC로 인한 CPU 사용 → GC가 동작하는 동안 프로그램이 동작을 멈추는 Stop the World 현상\n튜닝 포인트 찾기 Flame Graph 최적화가 가능한 영역 (e.g. 개발자가 작성한 코드)와 최적화가 불가능한 영역 (e.g. 프레임워크 내부적으로 처리되는 로직 ServeHTTP)를 구분하여 최적화가 가능한 영역을 확인한다 가로축의 길이가 길어지는 비중만큼, 해당 함수가 프로그램 동작 과정에서 GC개입이 필요한 객체들을 많이 생성하고 있는 것을 알 수 있음\n주요 병목 지점이라 생각했던 Redis는 7.9%인 방면 Context에 Value를 Set하는 함수(13.9%)가 보다 많은 Heap이 할당됨을 알 수 있음 Set은 Context에 지정된 Key가 없는 경우, 새롭게 make(map[string]any)로 할당함. capacity를 지정하지 않기 때문에.. map에 대한 메모리 할당이 진행됨\n하나의 Request 단위로 로그를 그룹화 하기 위한 키이자만 이에 드는 오버헤드가 크다면 사용하지 않는 방안도 있음\nGraph 그래프에서는 네모의 크기가 곧 할당된 메모리의 크기입니다. 주요 팁은 크기가 큰 네모를 찾고 할당 비율(%)가 높은 것을 우선순위로 확인하는 방법입니다. 단적인 예로 어째서 zerolog가 메모리를 이렇게 차지하게 되었는지 살펴봅니다\nzerolog는 main에서 할당된 Logger 객체를 사용하기에 Allocation은 당연히 Zero라고 생각했습니다. (zerolog의 모토 자체가 zero alloc이기에\u0026hellip;)\n코드리뷰 과정에서 중복된 필드의 With 작성으로 가독성이 저해된다는 피드백을 받고.. 이를 해결하기 위해 Context Logger를 생성하여 사용하도록 수정한 히스토리가 있었습니다. 아래는 문제의 Func입니다\n// Handle : CheckerHandler의 핸들러 func (h *BlacklistHandler) Handle(ctx *gin.Context) { // validation check var ( requestParams BlockCashoutGetRequestParams snValue string ) { ... } var ( logEntry zerolog.Logger = h.logger.With(). Str(\u0026#34;trace_id\u0026#34;, ctx.GetString(RequestIDContextKey)).Logger() // func 실행때 마다 New됨 ) // fetch blacklist \u0026amp; validate { ... if err != nil { // redis nil인 경우에만 false로 처리 if errors.Is(err, redis.Nil) { ctx.JSON(http.StatusOK, NewNotBlacklistResponse()) logEntry.Info().Msg(\u0026#34;not found in blacklist\u0026#34;) return } ctx.JSON( http.StatusInternalServerError, NewInternalServerErrorResponse(ctx.GetString(RequestIDContextKey)), ) return } ... if err != nil { // 시간 포맷이 틀린 경우 에러 로깅 logEntry.Error(). Err(err). Msg(\u0026#34;failed to parse blacklist expire time\u0026#34;) ctx.JSON(http.StatusOK, NewBlacklistResponse()) return } ... // response ctx.JSON(http.StatusOK, NewBlacklistResponse()) } return } 주입받은 Zerologger는 Inuse == Alloc이 같아 GC로 인한 부하가 없지만서도\u0026hellip; 내부적으로 NewLogger()를 수행하는 것과 동일한 효과로 인해, 매번 메모리가 할당되고 있었던 것이죠\n이러한 문제를 최적화하기 위해서는 가독성에 대한 TradeOff를 감수하거나 다른 로거를 사용하는 것도 방법이 될 수 있습니다.\n다른 Logger의 With는 Interface를 인자로 받기때문에 메모리 Alloc이 더 심해질수도 있습니다\n이에 대한 벤치마킹을 충분히 진행하여야 할것임\nGC 튜닝 가장 핵심은 과도한 GC 실행으로 인해 애플리케이션이 동작을 멈추는 Stop The World 현상을 개선하는 것이겠죠 아래는 이에 대한 여러가지 튜닝 방안입니다\nGOMEMLIMIT 사용하기 GOGC는 현시점의 Heap 크기와 직전 시점의 Heap 크기에 대한 증가율을 바탕으로 GC를 수행할지를 결정합니다. GC가 동작하는 Default 비율 값은 100으로, 기존 대비 Heap이 100% 증가, 즉 2배가 되면 GC를 수행합니다. 이 값을 낮추면 GC가 더 자주 수행되고, 이 값을 높일수록 GC가 덜 수행되게 됩니다.\nGolang 프로그램에 따른 수행 기준 값 선정하기 GC 값이 작은 경우\nGC가 너무 빈번하게 수행될 수 있습니다. 특히 프로그램이 재시작되어 아직 메모리 소비량이 작은 경우, 약간의 Heap 메모리 할당에도 허겁지겁 GC가 수행됩니다. 예시로 1GB의 Heap 메모리 크기가 2GB가 되어도 100% 증가이지만, 기준 값이 10MB인 경우, 겨우 20MB가 되어도 이 역시 100% 증가이기 때문입니다.\nGC 값이 큰 경우 OutOfMemory(이하 OOM) 발생 가능성이 커집니다. 기존 Heap 사용량이 40GB이고 GOGC가 50이라면, 1.5배 상승한 60GB가 되어야 GC가 수행되기 때문입니다.\nGOMEMLIMIT은 프로그램이 사용할 수 있는 메모리 사용량 한계선을 정하는 설정입니다. 이 방식에서는 설정한 GOMEMLIMIT의 값만큼 메모리 사용량이 올라가는 경우에만 GC가 수행됩니다.\n따라서 프로그램이 사용할 수 있는 최대 메모리 한계선을 미리 산정한 후, 그 값보다 작은 값을 GOMEMLIMIT으로 설정하면 손쉽게 GC를 튜닝할 수 있습니다. 한계선보다 작은 값을 설정하는 이유는 GOMEMLIMIT은 SoftLimit으로 프로그램이 설정된 GOMEMLIMIT 보다 조금 더 많은 메모리를 사용할 수 있기 때문입니다. 이로써 GC가 항상 최대한 늦게 동작할 수 있는 환경이 갖추어지며, GC Cycle이 최대로 길어지게 되어 STW가 최소화됩니다.\n바람직한? 프로세스\n기본 GOGC를 적용한 뒤, 메모리 수치 확인 PEAK 기준의 80%정도로 산정 (경험적인 수치) 프로파일링 / 모니터링하여 GC Cycle 확인 Production 코드의 벤치마크 해보기 가장 쉬운 방법은 작업한 코드의 벤치마크를 통해 확인해보는 방법입니다 bench의 -benchmem 을 통해 메모리 Alloc을 확인하고 Production 환경에서의 영향도를 확인해봅니다\ngo test -bench=. -benchmem ex. StructuredLogger 벤치마크 중 StructuredLogger는 팀에서 규격화되지 않은 필드들이 Elasticsearch에 적재되므로서 동일한 데이터 필드임에도 불구하고 데이터 사일로가 발생되는 것을 막기 위해 별도로 개발한 코드입니다.\n[주요 목적]\n로거의 변경이 필요하더라도 로거의 타입만을 바꾸어도 코드 수정이 불필요하도록 Wrapper구현 일관되지 않은 필드로 인하여 애플리케이션 내부에서 동일 필드임에도 불구하고, type 및 필드 명의 불일치가 잦음 [관련 벤치마크 테스트]\ngo test -bench=. -benchmem BenchmarkStructuredZeroLoggerMessage-12 596910 1724 ns/op 1000 B/op 30 allocs/op BenchmarkStructuredZeroLoggerMessageWithFields-12 285715 3926 ns/op 1633 B/op 60 allocs/op BenchmarkStructuredZeroLoggerMessageWithFieldsWithContext-12 222223 5346 ns/op 3418 B/op 68 allocs/op BenchmarkStandardZeroLoggerMessage-12 11927823 90.17 ns/op 0 B/op 0 allocs/op BenchmarkStandardZeroLoggerMessageWithDeterminedFields-12 5649648 217.6 ns/op 0 B/op 0 allocs/op BenchmarkStandardZeroLoggerWithFields-12 300001 3894 ns/op 1553 B/op 59 allocs/op 동일한 ZeroLogger를 사용하더라도 WithFields로 마샬링하는 과정에서 반복된 Memory Allocation이 발생합니다\n유즈케이스를 살피고 포인터 변수를 사용하자 일반적으로 생각하는 상식 상, value를 넘기기 보다 pointer 메모리 주소만 넘기기 때문에 CPU에 효율적이라고 생각합니다. 하지만 Golang에서는 CallByPointer보다 CallByValue가 효율적인 경우가 자주 발생합니다!\n포인터로 선언되는 순간, 해당 오브젝트는 무조건 Heap 영역에 할당되기 때문\nREF : https://articles.wesionary.team/use-case-of-pointers-in-go-w-practical-example-heap-stack-pointer-receiver-60b8950473da\n그렇다면 언제 Pointer를 사용해야 하는가? 큰 구조체의 경우: 큰 구조체는 복사 비용이 크므로, 포인터로 전달하여 메모리 사용을 줄이는 것이 더 효율적입니다. 변경 가능성: 포인터로 전달하면 원본 데이터를 변경할 수 있습니다. 즉, 메서드에서 구조체의 값을 수정하고 싶다면 포인터를 사용해야 합니다. 일관성 유지: API에서 일관성을 유지하기 위해 포인터를 사용하는 것이 좋습니다. 한 메서드에서 포인터를 사용한다면 다른 메서드도 일관성을 위해 포인터를 사용하는 것이 바람직합니다. null 값을 다룰 때: 예를 들어, int와 같은 필드가 실제로 값이 없음을 나타내야 할 때는 포인터를 사용하여 \u0026ldquo;진정한 부재\u0026quot;를 나타낼 수 있습니다. 기본 값이 0인 경우와 구분하기 위함입니다. Capacity를 상수로 지정하여 Slice 생성하기 Capacity가 지정되지 않은 Slice를 Dynamic Slice라고 칭해보겠습니다. Dynamic Slice의 경우, 값을 Append 할 때마다, 새로운 메모리를 할당받고 새로운 데이터를 적재 후, 기존 객체는 버리는 realloc이 발생합니다\nGolang에서는 Data Type을 고려해서 크기가 64KB이하인 객체의 경우 Stack 메모리에 선언하는 기능이 있기 때문에\u0026hellip; Capacity를 지정한 Slice 또는 Map을 Stack 메모리에 저장하여 성능을 개선시킬 수 있죠!\n고 컴파일\nMaxStackVarSize: 명시적으로 선언된 변수(var x T 또는 x := ...)의 경우 최대 10MB까지 Stack에 할당될 수 있으며, 그 이상의 크기는 Heap에 할당됩니다. MaxImplicitStackVarSize: 암묵적으로 생성된 변수 (new(T), \u0026amp;T{}, make([]T, n) 등)의 경우 최대 64KB까지 Stack에 할당됩니다. 이보다 큰 경우는 Heap에 할당됩니다. MaxSmallArraySize: 256바이트 이하의 작은 배열은 직접 Stack에 할당 및 초기화되며, 그 이상의 배열은 Heap에 할당된 후 복사됩니다. ","permalink":"https://dingyu.dev/posts/go-pprof-gc/","summary":"티끌모아 태산이라도 들어보았나? 병목 구간을 확인하여 최적화 하거나\u0026hellip; Memory Alloc을 최소화하여 GC의 부담을 덜어줌이 더해져 성능 최적화된 애플리케이션을 만든다!","title":"[Go] pprof로 GC 튜닝하기"},{"content":"배경 개발자가 직접 로그 모니터링을 통하여 장애 대응 아래와 같은 이유로 로그 모니터링에도 제약 사항이 존재 Field Type의 불일치로 인한 Elasticsearch field mapping Error 발생 → 로그 이벤트의 DROP 시스템 로그로 기록되는 경우, 스택 트레이스를 위하여 별도로 SE에게 시스템 로그를 요구하는 공수가 필요 목표 Go를 사용하는 프로젝트에서 공통적으로 표준이 될 수 있는 센트리 구조 확립 센트리에 대한 기능 명세 / 가이드라인 제공 센트리 적용 이후, 빠른 장애 대응을 통한 안정적인 서비스 구축 본 글은 센트리 계정이 있으며, 센트리 프로젝트를 이미 생성하였다 가정하고 진행됩니다.\nSentry에 대하여 Capture Exception 에러 추적(Capture Exception): 애플리케이션에서 발생하는 예외와 에러를 자동으로 감지하고 기록합니다. 센트리는 스택 트레이스(stack trace)와 함께 에러 발생 시점의 환경 정보를 제공하여, 에러의 원인을 쉽게 파악할 수 있도록 도와줍니다.\nTransaction 성능 모니터링(Transactions): 애플리케이션의 성능을 모니터링하며, 웹 요청이나 API 호출 등의 트랜잭션을 추적합니다. 각 트랜잭션의 응답 시간, 성공 및 실패 비율과 같은 세부 정보를 제공하여 성능 병목 현상을 식별하고 개선할 수 있도록 도와줍니다.\nTrace 트레이싱(Trace): 애플리케이션의 트랜잭션을 세부적으로 추적하여, 서비스 간 호출, 데이터베이스 쿼리 등의 작업에 걸리는 시간을 분석합니다. 이를 통해 애플리케이션 전체의 성능을 이해하고, 문제가 되는 부분을 파악할 수 있습니다.\nAlert 이슈 관리 및 알림: 센트리는 에러와 성능 문제를 이슈로 관리하며, 발생 시 지정된 이메일이나 슬랙(Slack) 등의 통지 채널을 통해 알림을 보냅니다. 개발자는 이슈를 할당받고, 처리 상태를 업데이트하며, 문제 해결을 위해 협업할 수 있습니다.\nRelease Tracking 릴리즈 추적(Release Tracking): 애플리케이션의 버전을 추적하여, 새로운 릴리즈가 에러 비율에 미치는 영향을 분석할 수 있습니다. 이를 통해 최근 배포된 변경사항이 문제를 일으키고 있는지 파악할 수 있습니다.\nSentry Alerts 센트리 알람을 통해 협업 툴과 연동하여 개발자가 쉽게 대응할 수 있도록 합니다.\n설정 STEP BY STEP 대시보드 - Alert - Create Alert 트리거 설정\nIssues : 에러의 stacktrace를 기반으로 이슈가 생성되는데, 에러의 유형 별로 센트리 알람 트리거 에러 유형 별로 처리가 필요할 때 사용 ex. API를 기준으로 HTTP status 코드를 기반으로 설정 ex. Service의 유형 기반으로 설정 Number of Errors : 에러의 횟수 기반으로 센트리 알람 트리거 동일한 유형의 에러이며, 횟수 기반 처리가 필요할 때 사용 Users Experiencing Errors : 정의된 User 기반 임계치 설정으로 센트리 알람 트리거 특정 Page 내에서 사용자 경험 최적화 또는 이슈 발생을 확인이 필요할 때 사용 ex. 100 명의 유저가 로그인 페이지에서 에러가 발생 세부 조건 설정\nWHEN : 알람이 트리거 되는 시점 정의\nany (아래 조건 중 하나라도 만족할 경우) / all (모든 조건을 만족하는 경우) 선택 이슈의 상태 / 이슈의 횟수를 기준으로 선정 IF : 이벤트의 세부 조건\n태그 기반 / 발생 빈도 기반 / 카테고리 기반 THEN : 액션 선정\n메일 / 슬랙 / 팀즈 등으로 액션 지정 개발하기 Client Options Dsn: _Data Source Name_의 약자로, Sentry 프로젝트를 식별하는 고유한 문자열입니다. 이 값을 설정함으로써 에러와 이벤트가 보고될 정확한 Sentry 프로젝트를 지정할 수 있습니다. [Projects - Settings - Client Keys] Environment: 애플리케이션의 실행 환경(예: production, staging, development)을 지정합니다. 이 정보는 에러 필터링과 분석 시 중요한 차원으로 사용됩니다. 각 실행 환경 별로 필터링하여 알림 설정을 하거나, 모니터링 가능 Issue Filtering Release: 애플리케이션의 릴리즈 버전을 지정합니다. 이 값을 통해 에러가 발생한 애플리케이션의 구체적인 버전을 추적하고, 릴리즈 간 에러 비율을 비교할 수 있습니다. SampleRate: 0에서 1 사이의 값을 설정하여, 보고될 이벤트의 샘플링 비율을 결정합니다. 예를 들어, 0.1로 설정하면 10%의 이벤트만이 실제로 보고됩니다. 이는 대량의 트래픽이 발생하는 애플리케이션에서 유용하게 사용될 수 있습니다. API 트래픽 량이 많을 수록 0에 가깝게 지정 네트워크 트래픽 감소 / 성능 최적화 / 비용 절감을 위해 적절히 지정 TracesSampleRate: 성능 모니터링에 사용되며, SampleRate와 비슷하게 트랜잭션 데이터의 샘플링 비율을 결정합니다. 이를 통해 성능 데이터의 양을 조절할 수 있습니다. BeforeSend: 보고되기 전에 이벤트를 수정하거나 필터링할 수 있는 콜백 함수를 설정합니다. 예를 들어, 특정 조건을 만족하는 이벤트만을 보고하거나, 민감한 정보를 제거하는 데 사용될 수 있습니다. AttachStacktrace: 자동으로 스택 트레이스를 이벤트에 첨부할지 여부를 결정합니다. 이 옵션을 활성화하면 에러가 아닌 로그 메시지에도 스택 트레이스 정보가 포함됩니다. ServerName: 이벤트가 보고될 때 서버 이름을 명시적으로 설정할 수 있습니다. 이 정보는 에러 분석 시 서버 구분에 도움을 줄 수 있습니다. Integrations: Sentry와 함께 사용할 추가적인 통합 기능들을 설정합니다. Sentry는 다양한 플랫폼과 프레임워크에 대한 통합을 제공하여, 보다 쉽게 에러 추적 및 성능 모니터링을 구현할 수 있도록 돕습니다. Transport는 Sentry 서버로 이벤트를 전송하는 메커니즘을 정의합니다. 이 옵션을 사용하여 개발자는 기본 HTTP 전송 방식 대신 커스텀 전송 방식을 구현할 수 있습니다 timeout 값은 네트워크 지연이나 서버 응답 시간의 변동성을 고려하여 설정되어야 합니다 Initialize Go-Sentry SDK 사용 시, 최초 초기화 당시에 HTTP Client의 TCP 커넥션을 자동으로 처리 합니다.\nApplicaiton 의 main.go 에서 최초로 Init() 설정하는 것이 Best Practice로 소개됩니다.\nerr := sentry.Init( sentry.ClientOptions{ Dsn: si.conf.Sentry.DSN, SampleRate: si.conf.Sentry.SampleRate, EnableTracing: si.conf.Sentry.EnableTrace, Debug: si.conf.Sentry.Debug, TracesSampleRate: si.conf.Sentry.TracesSampleRate, Environment: si.conf.Sentry.Environment, AttachStacktrace: true, Transport: \u0026amp;sentry.HTTPSyncTransport{ Timeout: si.conf.Sentry.Timeout, }, }, ) Capture Exception 발생한 예외(에러)와 관련된 스택 트레이스를 자동으로 캡처하고 추적합니다.\n// 현재 컨텍스트와 연관된 Hub 생성 또는 가져오기 hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } // 에러 캡처 hub.CaptureException(err) Go Error 사용에 따른 스택 트레이스 차이점 정확한 에러의 발생처를 알기 위해서는 pkg/errors 라이브러리를 사용하자!\nerrors 패키지: 기본적으로 스택 트레이스 정보를 제공하지 않습니다. 에러는 단순히 메시지를 포함하는 값이며, 디버깅을 위한 추가적인 컨텍스트나 위치 정보는 포함되어 있지 않습니다.\ngithub.com/pkg/errors 패키지: 에러에 자동으로 스택 트레이스를 포함합니다. 이를 통해 에러가 어디서 발생했는지, 에러의 원인을 추적하는 데 필요한 상세한 호출 스택 정보를 얻을 수 있습니다.\ntest. errors 패키지와 pkg/errors 에 따른 스택 트레이스\npackage main import ( \u0026#34;context\u0026#34; stdErr \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; sentry \u0026#34;github.com/getsentry/sentry-go\u0026#34; pkgErr \u0026#34;github.com/pkg/errors\u0026#34; ) var ( PkgErr1 = pkgErr.New(\u0026#34;pkg error 1\u0026#34;) PkgErr2 = pkgErr.New(\u0026#34;pkg error 2\u0026#34;) StdErr1 = stdErr.New(\u0026#34;standard error1\u0026#34;) StdErr2 = stdErr.New(\u0026#34;standard error2\u0026#34;) ) func main() { err := sentry.Init( sentry.ClientOptions{ Dsn: \u0026#34;\u0026#34;, Debug: true, AttachStacktrace: true, }, ) if err != nil { // sentry 초기화 실패 시, panic 시스템 os exit panic(err) } ctx := context.Background() hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } err = errPkgNested() go hub.CaptureException(err) fmt.Println(\u0026#34;Standard error nested\u0026#34;) time.Sleep(5 * time.Second) } func errStdNested() error { return stdErr.Join(PkgErr1, PkgErr2) } func errPkgNested() error { return pkgErr.Wrap(PkgErr1, PkgErr2.Error()) } Scope() Sentry에서 Scope는 특정 에러 또는 이벤트에 추가적인 컨텍스트 정보를 제공하는 메커니즘입니다. 에러의 재현을 위해서 요청 파라미터 등을 Scope에 저장하여 애플리케이션의 고도화가 가능합니다.\nSentry 클라이언트를 통해 생성되는 허브는 Context 단위로 싱글턴 패턴을 유지하며, go context.Context 와 함께 메타데이터를 저장하여, 추적에 용이하도록 돕습니다.\nfunc (rm *sentryScopeMiddleware) Register(originalHandler http.Handler) http.Handler { if !rm.initializer.Enabled() { // sentry가 비활성화 되어 있는 경우, 센트리 활성화 rm.initializer.Init() } return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { hub := sentry.GetHubFromContext(r.Context()) if hub == nil { hub = sentry.CurrentHub().Clone() r = r.WithContext(sentry.SetHubOnContext(r.Context(), hub)) } hub.Scope().SetRequest(r) }) } Sentry Advancement SentryInitializer 하나의 애플리케이션에서 싱글턴을 유지하기 위해 설정을 통한 초기화 여부를 확인하는 클래스\npackage core import ( \u0026#34;sync\u0026#34; \u0026#34;github.com/getsentry/sentry-go\u0026#34; ) type ( // SentryInitializer : Sentry 설정 초기화를 담당하는 구현체 SentryInitializer struct { conf *Config enabled bool mutex sync.RWMutex // enabled 필드에 대한 읽기/쓰기 동기화를 위한 RWMutex } ) // NewSentryInitializer : SentryInitializer 생성자 func NewSentryInitializer(conf *Config) SentryInitializer { return SentryInitializer{ conf: conf, } } // Init : SentryInitializer 초기화 // // - sentry 패키지 변수를 통해 싱글턴 처리하므로 최초 설정만 요구됨 func (si *SentryInitializer) Init() error { si.mutex.Lock() // enabled lock for writing defer si.mutex.Unlock() err := sentry.Init( sentry.ClientOptions{ Dsn: si.conf.Sentry.DSN, SampleRate: si.conf.Sentry.SampleRate, EnableTracing: si.conf.Sentry.EnableTrace, Debug: si.conf.Sentry.Debug, TracesSampleRate: si.conf.Sentry.TracesSampleRate, Environment: si.conf.Sentry.Environment, AttachStacktrace: true, Transport: \u0026amp;sentry.HTTPSyncTransport{ Timeout: si.conf.Sentry.Timeout, }, }, ) if err != nil { // sentry 초기화 실패 시, panic 시스템 os exit panic(err) } // 활성화 상태로 변경 si.enabled = true return nil } // Enabled : Sentry 활성화 여부 // // - Init()이 호출된 경우, 활성화 상태로 변경 func (si *SentryInitializer) Enabled() bool { si.mutex.RLock() // read lock defer si.mutex.RUnlock() return si.enabled } 동시성 문제로 **Enabled()**의 동기화를 위해 락으로 관리\nErrorCapturer SentryInitializer를 임베딩하여, 센트리를 통한 센트리 허브에서 에러를 캡쳐링하는 클래스 package core import ( \u0026#34;context\u0026#34; \u0026#34;github.com/getsentry/sentry-go\u0026#34; ) type ( // ErrorCapturer : 에러 캡처 인터페이스 ErrorCapturer interface { CaptureError(ctx context.Context, err error) } sentryErrorCapturer struct { SentryInitializer } ) // NewSentryErrorCapturer : SentryErrorCapturer 생성자 func NewSentryErrorCapturer(initializer SentryInitializer) ErrorCapturer { return \u0026amp;sentryErrorCapturer{ initializer: initializer, } } // CaptureError : Sentry로 에러 캡처 func (sec *sentryErrorCapturer) CaptureError(ctx context.Context, err error) { // 에러가 없는 경우, 무시 if err == nil { return } if !sec.SentryInitializer.Enabled() { // sentry 초기화를 통해 활성화 sec.SentryInitializer.Init() } // 현재 컨텍스트와 연관된 Hub 생성 또는 가져오기 hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } // 에러 캡처 hub.CaptureException(err) } RecoverMiddleware 핸들러에서 Panic 발생 시, Recover(), 요청을 허브의 메타데이터로 저장하는 클래스 // Register panic() 발생 시 스택 스레이스를 로깅하며 센트리를 통해 남기는 메서드 // // - http handler에 내부적으로 등록 // - API 고루틴 내부적으로 defer()를 통하여 panic 상황에서도 로깅이 가능하도록 한다 // // Parameters: // - originalHandler: 원래의 http handler func (rm *sentryRecoverMiddleware) Register(originalHandler http.Handler) http.Handler { if !rm.initializer.Enabled() { // sentry가 비활성화 되어 있는 경우, 센트리 활성화 rm.initializer.Init() } return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { hub := sentry.GetHubFromContext(r.Context()) if hub == nil { hub = sentry.CurrentHub().Clone() r = r.WithContext(sentry.SetHubOnContext(r.Context(), hub)) } hub.Scope().SetRequest(r) defer func() { if err := recover(); err != nil { hub.RecoverWithContext(r.Context(), err) stackList := strings.Split(string(debug.Stack()), \u0026#34;\\n\u0026#34;) rm.Logger.Error(). Any(\u0026#34;error\u0026#34;, err). Any(\u0026#34;stack_list\u0026#34;, stackList).Send() resp := dto.ACSErrorResponse{ Code: http.StatusInternalServerError, ErrMessage: \u0026#34;서버에서 예기치 못한 에러가 발생하였습니다\u0026#34;, Success: false, } jsonResp := resp.ToJSON() w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) w.WriteHeader(http.StatusInternalServerError) _, err = w.Write(jsonResp) if err != nil { rm.Logger.Error(). Any(\u0026#34;error\u0026#34;, err).Send() } return } }() originalHandler.ServeHTTP(w, r) }) } 비용적인 문제가 있지만 APM과 Error Capture측면에서는 관리적인 편의성을 제공해주는 Sentry!\n","permalink":"https://dingyu.dev/posts/sentry/","summary":"APM과 에러 스테이스가 가능한 툴이 있다?","title":"[Third-Party] Sentry 연동"},{"content":"배경 k8s 환경 Deploy 후, 부하테스트 과정에서 간헐적으로 502 / 504 에러 발생 확인 Pod들이 교체 되면서 기존 요청에 대한 응답을 반환하지 못한 채 종료 됨 → 504 Gateway Timeout 신규 Pod이 올라가고 대체되는 Pod이 Terminate 됨 → 502 Bad Gateway 롤링업데이트가 진행되지만 Readiness Probe 설정 없이는 순단이 발생할 여지가 있음을 확인\n설정 부하테스트 툴 설치 bombardier : 쉽고 간편한 go cli 부하테스트 툴 vegeta : 스크립트 작성으로 보다 유연한 요청 가능, status code 를 상세히 응답하는 툴\n각 툴의 자세한 설치 과정은 생략 합니다.\nReadniess Probe Pod이 서비스 트래픽을 처리할 준비가 되었는지를 판단하는 데 사용되는 메커니즘\n특정 컨테이너가 시작된 후에도 일부 작업이 완료될 때까지 외부 트래픽을 처리할 준비가 되지 않았을 수 있기 때문에 이를 확인하는 역할을 함\n트래픽 라우팅 제어: Readiness Probe가 성공적으로 완료될 때까지 Kubernetes는 해당 Pod으로 트래픽을 라우팅하지 않습니다. 이는 Pod이 준비되지 않은 상태에서 요청을 처리하지 않도록 보장합니다. 준비가 완료된 후에만 트래픽이 Pod으로 라우팅되기 때문에, Pod이 올바르게 설정되고 필요한 리소스를 확보한 상태에서만 요청을 처리하게 됩니다. Pod의 상태 확인: Readiness Probe는 특정 조건이 충족될 때까지 Kubernetes에 Pod이 트래픽을 받을 준비가 되지 않았다고 알리며, 준비가 완료된 후에는 트래픽을 받을 준비가 되었음을 알립니다. Pod이 준비되지 않은 경우, Kubernetes는 Pod을 서비스의 엔드포인트에서 제거합니다. 502가 발생하는 원인 중 하나이다\nReadiness Probe를 지정하지 않은 경우, 컨테이너가 올라가는 시점에서 트래픽이 들어오게 된다.\n이때에, Pod 내부의 서버 초기화가 완전히 되지 않은 시점에서 요청이 온 경우 → 502 Bad Gateway를 응답한다\ndeployment.yml 수정 사항 ... readinessProbe: httpGet: port: 8080 path: /alive scheme: HTTP initialDelaySeconds: 30 periodSeconds: 30 ... Healthcheck 응답용 Endpoint를 생성해두고 응답 상태코드가 200으로 돌아오면 요청을 받는 형식으로 설정\n테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4205.76 1250.10 16927.12 Latency 47.81ms 10.16ms 2.07s Latency Distribution 50% 45.08ms 75% 49.77ms 90% 57.60ms 95% 64.29ms 99% 81.95ms HTTP codes: 1xx - 0, 2xx - 0, 3xx - 0, 4xx - 753060, 5xx - 12 others - 0 Throughput: 3.24MB/s 여전히 5XX 에러는 존재한다.\nlifecycle \u0026amp; preStop lifecycle 설정이란? 컨테이너의 생명주기 동안 특정 시점에 실행될 작업을 정의할 수 있는 Kubernetes의 구성 옵션 (AOP와 유사\u0026hellip;하다는 생각)\npostStart: 컨테이너가 시작된 직후에 실행됩니다. 컨테이너가 시작된 후 추가적인 초기화 작업을 수행하는 데 사용 preStop: 컨테이너가 종료되기 직전에 실행됩니다. 종료 전에 필요한 작업을 수행하도록 설정 가능 preStop preStop 훅은 컨테이너가 종료될 때 실행되는 스크립트나 명령어를 지정. 이 훅은 컨테이너가 종료되기 전에 반드시 수행해야 하는 작업이 있을 때 매우 유용\n트래픽 분리: Pod이 종료되기 전에 해당 Pod을 서비스 트래픽에서 안전하게 분리하기 위해 사용됩니다. 정리 작업: 종료 전에 리소스 정리, 연결 종료, 파일 저장 등의 작업을 수행할 수 있습니다. 대기 시간 설정: 컨테이너가 실제로 종료되기 전에 일정 시간 동안 대기하도록 설정하여, 클라이언트와의 연결이 완전히 종료되도록 할 수 있습니다. 앞서 설정한 Readiness Probe 설정 이후에도, lifecycle 설정을 하지 않는다면 간헐적인 502 에러가 발생될 수 있다\n파드는 종료될 때 SIGTERM, SIGKILL 처리와 서비스 제외 처리가 비동기로 처리됨\n서비스가 분리되기 전에 Pod이 클라이언트 요청에 정상적으로 응답할 수 없을 수 있다.\n즉, 서비스 분리 → 잔류하는 요청 처리 → pod 종료 를 통해 Graceful Shutdown이 가능하도록 설정한다\ndeployment.yml 수정 사항 ... lifecycle: preStop: exec: command: - /bin/sh - -c - sleep 40 # 서비스 분리가 발생한 후 40초 동안 대기 ... 컨테이너 종료 요청: Kubernetes가 Pod을 종료하기로 결정하면, 컨테이너에 SIGTERM 신호 preStop 훅 실행: SIGTERM 신호가 전송된 후, sleep 40 실행, 컨테이너가 40초 동안 대기 유예 기간 시작 (terminationGracePeriodSeconds): preStop 훅이 실행되면서, 동시에 terminationGracePeriodSeconds에 정의된 유예 기간이 시작 이 기간 동안 Kubernetes는 컨테이너가 정상적으로 종료되기를 대기 컨테이너 종료: preStop 훅이 완료되고, 유예 기간이 끝나면 Kubernetes는 컨테이너를 종료 테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4205.05 1355.65 20756.97 Latency 47.92ms 8.71ms 2.07s Latency Distribution 50% 45.47ms 75% 49.26ms 90% 57.32ms 95% 64.39ms 99% 80.67ms HTTP codes: 1xx - 0, 2xx - 751239, 3xx - 0, 4xx - 0, 5xx - 3 others - 0 Throughput: 2.82MB/s 여전히 5XX 에러는 존재한다.\nterminationGracePeriodSeconds Pod 종료 시나리오:\nKubernetes가 Pod을 종료하기로 결정하면, 먼저 Pod 내의 컨테이너에 SIGTERM 신호를 보냄 SIGTERM 신호를 받은 애플리케이션은 현재 처리 중인 요청을 완료하고, 필요한 정리 작업을 수행 가능 유예 기간 설정:\nterminationGracePeriodSeconds는 이 유예 기간을 정의. 이 기간 동안 Kubernetes는 컨테이너가 정상적으로 종료될 시간을 대기 기본값은 30초입니다. 이 시간이 지나면 Kubernetes는 컨테이너가 여전히 실행 중인 경우 강제로 종료(SIGKILL) SIGKILL 신호:\nterminationGracePeriodSeconds 기간이 만료되었을 때도 컨테이너가 종료되지 않았다면, Kubernetes는 SIGKILL 신호를 줌, 애플리케이션이 강제 종료됨 일정 lifecycle.preStop 설정을 통해, 40초의 유예시간을 두어 애플리케이션에 잔류하는 요청을 응답할 시간을 주었음.\n하지만 terminationGracePeriodSeconds 는 기본 30초로 설정되기에 30초가 지나도록 Pod이 실행중인 경우 SIGKILL을 전송하여 파드를 강제 종료시킴\ndeployment.yml 수정 사항 ... terminationGracePeriodSeconds: 50 ... INGRESS와 연결된 ALB 속성을 꼭 확인하자! terminationGracePeriodSeconds가 ALB 타임아웃보다 긴 경우, 특정 시나리오에서 504 Gateway Timeout 오류가 발생할 수 있음\n예상 발생 시나리오 : 요청 중간에 종료 발생 → ALB 타임아웃 도달 → 응답 전 Pod 종료\n이를 예방하기 위해, lifecycle.preStop (40s) \u0026lt; terminationGracePeriodSeconds (50s) \u0026lt; ALB Timeout (60s) 로 지정\n테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4293.51 1286.80 12924.64 Latency 46.74ms 8.94ms 547.25ms Latency Distribution 50% 44.48ms 75% 46.87ms 90% 54.16ms 95% 66.82ms 99% 81.69ms HTTP codes: 1xx - 0, 2xx - 770240, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 2.89MB/s REF 카카오 테크 k8s 무중단 배포 Pod 라이프사이클 ","permalink":"https://dingyu.dev/posts/k8s-zero-downtime/","summary":"간헐적으로 발생하는 502와 504.. 왜 발생하고 어떻게 예방할까","title":"[Infra] 쿠버네틱스 무중단 배포 설정하기"},{"content":"AWS Architected Best Practice Well-Architected 팀에서 구축하고 있는 시스템이나 애플리케이션을 살펴볼 때 다음 질문에 답할 수 있을까? 설계를 하였지만, 제대로 설계한지 모를 때 필요한 지식\n설계에 대한 기준? 핵심 요소 이점 일반 설계 원칙 비용 성능 RPS를 토대로 CPU/memory 설정 운영 우수성 보안 안정성 성능 효율성 비용 최적화 지속 가능성 설계 원칙 보다 신속한 구축 및 배포 위험 감소 또는 완화 서버에서 22번 포트를 OPEN하는 방법이 안전한 방법일까요? bash 스크립트나 인터넷에서 잘 알려진 22번 포트를 여는게 맞을까? AWS 세션 매니저를 통해 22번 포트를 열지 않고도 서버에 접근할 수 있다 SCALE UP / SCALE OUT SCALE UP: 수직적인 확장, CPU / memory 등의 하드웨어 강화 (UP/DOWN) SCALE OUT: 수평적인 확장, 동일한 스펙으로 서버의 대수를 늘림 (IN/OUT) EC2에서 모범사례 인프라의 관점 용량 먼저 산정 -\u0026gt; 비용으로 이어짐 보안 이벤트에 대한 응답 자동화: 이벤트 기반 알림 또는 조건 기반 알림에 대해 모니터링하고 자동으로 대응 운영 우수성 핵심 요소: 조직이 비즈니스 목표를 지원하는 방법을 다룸 워크로드를 효과적으로 실행하고, 운영에 대한 인사이트를 얻고, 프로세스 및 절차를 지속적으로 개선하여 비즈니스 가치를 제공하는 조직의 능력이 포함됨 설계 원칙 많이 산정: 낭비 (피크 트래픽 기준 트래픽으로 스펙 산정) 적게 산정: 부하 프로덕션 규모로 시스템을 테스트 환경 별로 동일한 스펙으로 테스트해야 안정성 테스트 가능 클라우드 환경이기에 사용 후 없애면 됨 (Blue / Green 배포) 자동화를 통해 더 간편해진 아키텍처 실험 혁신적인 아키텍처 허용 MSA \u0026lt;-\u0026gt; 모놀리스 PoC를 통해 보다 효과적인 방법으로 마이그레이션 (고이지 말자) 데이터를 사용하여 아키텍처를 구동 사람의 감이 아닌 데이터를 통해 구동 실전 테스트를 통한 개선 장애 상황에 대해 미리 대처하지 않으면 복구에 많은 비용이 들 수 있음 인력에 대한 리소스 또한 워크로드에 포함됨 코드형 운영 수행 코드를 통해 인프라를 관리\n되돌릴 수 있는 소규모 변경을 빈번하게 수행 MR과 마찬가지 Code Pipeline을 통해 CI/CD 워크플로우를 구성 가능 카나리 배포: 여러 대 중 일부 서버에만 배포를 진행한 후 테스트 및 모니터링을 통해 나머지 서버에 동일하게 배포 진행 운영 절차 빈번하게 재정의 SSH를 열겠다는 것: 22포트를 여는 것 Well known 포트를 OPEN 하므로 해커들의 공격 발생 가능 AWS 세션 매니저를 통해 브라우저 기반의 관리를 할 수 있음 SSH로 접근하는 것과 동일하게 프롬프트 작업을 수행 가능 장애 예측 및 대응 장애를 수용하는 아키텍처 구성 health check를 통해 트래픽 전송 전 체크 health check가 실패하면 트래픽 격리 -\u0026gt; 장애 전파를 막음 e.g. Any Company 사례 [문제점] A 가용 영역이 다운되면 모든 서비스가 다운된다 -\u0026gt; 가용 영역을 나누어야 함 EC2 위에 데이터베이스를 설치한다는 것은 관리 요소에 부담이 갈 수 있다 -\u0026gt; 이중화 및 별도 인스턴스로 구성 (고가용성 확보)\n[모범 사례 리뷰]\n대부분의 운영 작업이 수동으로 수행됨 제품 카탈로그 애플리케이션에 고가용성 아키텍처가 필요 보안이 최우선 순위 데이터베이스 이중화 Active / StandBy 형태로 구성 데이터가 동기식으로 동기화됨 RPO: 얼마나 자주 백업하는가? RPO가 제로일 수 있음 안정성 핵심 요소 인프라 또는 서비스 장애로부터 복구하고, 수요에 맞춰 컴퓨팅 리소스를 동적으로 확보 잘못된 구성이나 일시적인 네트워크 문제로 인한 중단을 완화하는 시스템의 능력 포함 장애로부터 자동 복구 Rolling, 카나리, Blue Green 배포 설정 방법: 최소:최대:목표 설정 후 AutoScaling 가능 수평적 확장 여러 가용 영역에서의 수평적 확장 Elastic Load Balancer에서 요청이 많으면 자동으로 용량 추가 (오토스케일링) 보안 보안에서는 클라우드 기술을 사용하여 데이터 시스템 및 자산을 보호하고 보안 태세를 개선하는 방법을 고려해야 함\n다양한 팀이 하나의 Account 사용 기능별 AWS 계정 모든 계층에 보안 적용 강력한 자격 증명 기반 구현 Git 커밋처럼 ChangeLog와 유사하게, 언제 어떻게 바뀌었는지 추적 가능 전송 중 및 저장 시 데이터 보호 암호화: Amazon Macie AWS KMS를 사용하여 공통 자원의 키 관리, 팀별 요구사항에 맞는 키 관리는 AWS CloudHSM 비용 최적화 지속적인 모니터링으로 최저 가격으로 비즈니스 가치를 제공하는 시스템을 운영하도록 장려 비용 및 사용량을 사용한 만큼 지불하는 아키텍처 구성 개발/테스트 환경의 최소화 효율적인 비용 관리 워크로드가 변경됨에 따라 가치를 측정 서버리스 아키텍처로 전환 비용 추적을 위해 태그 사용 권장: 어디서 사용량이나 비용이 증가했는지 추적 가능 ","permalink":"https://dingyu.dev/posts/aws-well-architected/","summary":"AWS는 아는 만큼 보인다. 돈먹는 하마이지만 사용하기에 따라 편리한 효자가 될 수 있는 AWS! 인프라 설계의 모범사례를 알아보자","title":"[Infra] AWS Well Architected"},{"content":"목적 일반적인 Transaction이 필요한 RDB의 경우, 자체적으로 격리 수준을 설정하거나 Rollback과 Commit을 통해 트랜잭션을 구현한다.\n하지만 Redis는 어떠한가? Redis에서 데이터의 일관성과 원자성을 보장받기 위해 주어진 옵션은 그렇게 명확하지 않다.\n하나의 Transaction을 격리 시켜야 하며, All or Nothing 원자성을 Redis에서 지켜야 할 때에 도움이 되고자 기록합니다.\n선택지 Redis TxPipeline Lua Script Redis TxPipeline Redis에서 여러 Command를 일괄적으로 처리하기 위해 떠올리게 되는 것은 Pipeline일 것이다\nPipeline은 연결된 Redis Client로 여러 개의 커맨드를 한번에 보내고 여러개의 응답을 한번에 받는 것을 가능하도록 한다\n다만 일반적인 파이프라인이 트랜잭션이 보장된다고 할 수 없다. 즉, 파이프라인 실행 도중 해당 데이터에 대하여 다른 커맨드로 인해 변경될 수 있으며 데이터의 일관성에 문제가 발생할 수 있다\nEdge Case 네트워크 지연: Redis Pipeline을 사용하면 여러 개의 커맨드를 한 번에 보내고, 한 번에 여러 개의 응답을 받는 것이 가능합니다. 그러나 네트워크 지연으로 인해 커맨드가 서버에 도착하는 순서와 응답이 도착하는 순서가 일치하지 않을 수 있습니다. 따라서 응답이 먼저 도착하는 경우에도, 실제로는 나중에 실행한 커맨드의 결과일 수 있습니다. 다중 스레드 환경: Redis 서버는 다중 스레드로 동작하며, 여러 클라이언트가 동시에 요청을 보낼 수 있습니다. 따라서 여러 클라이언트가 동시에 Pipeline을 사용할 경우, 커맨드의 실행 순서가 보장되지 않을 수 있습니다. Redis 서버 설정: Redis 서버의 설정에 따라 일관성이 달라질 수 있습니다. 예를 들어, Redis 서버가 \u0026ldquo;slaveof\u0026rdquo; 설정을 사용하여 데이터를 레플리케이션하는 경우, 일관성이 보장되지 않을 수 있습니다. 이를 해결하는 것이 TxPipeline이다\nPros 트랜잭션 보장: TxPipeline을 사용하면 일괄 처리된 커맨드는 하나의 트랜잭션으로 간주되어, 실행 중 다른 커맨드가 중간에 끼어들지 않습니다. 이로써 데이터의 일관성을 보장합니다. 성능 향상: 여러 개의 커맨드를 한 번에 보내므로 네트워크 오버헤드를 줄일 수 있어 성능이 향상될 수 있습니다. 원자성 보장: TxPipeline 내에서 실행되는 모든 커맨드는 성공하거나 실패되며, 롤백은 지원하지 않습니다. Cons 메모리 사용: 모든 커맨드와 결과가 메모리에 저장되므로, 큰 트랜잭션을 처리할 때 메모리 사용량이 증가할 수 있습니다. 복잡성: TxPipeline은 다른 파이프라인과 혼합해서 사용할 때 주의가 필요하며, 트랜잭션의 범위를 신중하게 관리해야 합니다. 테스트 WATCH를 통해 특정 키의 변경을 감시하고, 이를 통해 트랜잭션의 일관성을 보장할 수 있습니다. 만약 WATCH 중에 감시된 키가 다른 클라이언트에 의해 변경되면, 해당 트랜잭션은 실패\nex. TxPipeline 도중 에러 발생 시나리오\nMULTI SET key1 value1 SET key2 value2 SET key3 value3 EXEC 시나리오 : SET key2 value2 커맨드가 실패\nCASE 1 : 메모리 부족 \u0026#34;OOM command not allowed when used memory \u0026gt; \u0026#39;maxmemory\u0026#39;\u0026#34; CASE 2 : 잘못된 데이터 형식 \u0026#34;WRONGTYPE Operation against a key holding the wrong kind of value\u0026#34; 일반적으로 일어날 수 있는 경우가 드무며, 가장 예상 가능한 시나리오는 Redis Client Connection이 끊어진 케이스가 될것이다. 만약 Client Connection이 끊어진 경우, 실패한 키에 대하여 롤백을 수동으로 진행한다 하여도 롤백 자체가 수행되지 않기 때문에 완벽한 해답은 되지 않는다\n즉, TxPipeline은 일관성은 보장 되지만 완벽한 원자성은 보장되지 않는다\nLua Script Lua 스크립트 내에서 여러 Redis 커맨드를 실행하고, 이를 원자적으로 실행할 수 있다\nEdge Case 스크립트 전송 중 네트워크 지연이나 중단: 클라이언트가 Lua 스크립트를 Redis 서버로 전송하는 과정에서 네트워크 지연이나 중단이 발생하면, 스크립트는 서버에 제대로 도달하지 못하고 실행되지 않을 수 있습니다. 실행 결과 수신 중 네트워크 문제: 스크립트가 성공적으로 실행된 후, 그 결과를 클라이언트가 수신하는 과정에서 네트워크 지연이나 중단이 발생할 수 있습니다. 이 경우, 스크립트는 Redis 서버에서 정상적으로 실행되었지만, 클라이언트는 실행 결과를 받지 못할 수 있습니다. Pros: 경량 및 빠른 실행: Lua는 경량 스크립팅 언어로, 실행 시스템 자원을 적게 소모하며 빠르게 실행됩니다. 이러한 특징은 임베디드 시스템이나 게임 엔진 등 리소스가 제한된 환경에서 유용합니다. 내장 스크립트 언어: Lua는 많은 애플리케이션과 게임 엔진에서 내장 스크립트 언어로 사용됩니다. 이는 애플리케이션의 확장성을 높이고 사용자 정의 스크립트를 통해 기능을 확장하기에 용이합니다. 흔히 이전에 Statement로 관리 되던 DB 명령 방식 ORM이 등장한 배경을 생각해보았을 때, 커맨드(query)를 코드로 관리할 수 없기 때문에 Lua를 사용함에 회의적인 개인적 생각 가독성과 간결성: Lua는 간결하고 가독성이 높은 문법을 가지고 있어 쉽게 이해하고 작성할 수 있습니다. lua Script를 위해 문법을 수정해야 하기 때문에 러닝 커브가 동반될 수 있음 Cons: 작은 생태계: 다른 언어에 비해 Lua의 생태계는 상대적으로 작습니다. 따라서 다양한 라이브러리 및 모듈을 찾기 어려울 수 있습니다. 제한된 자료형: Lua는 몇 가지 기본 자료형만을 지원하며, 정수와 부동 소수점 수의 구분이 없어서 정확한 숫자 처리가 어려울 수 있습니다. 엄격한 문법: Lua는 문법 검사가 엄격하며, 초보자에게는 초기 학습 곡선이 높을 수 있습니다. 쓰레드 처리 어려움: Lua는 기본적으로 싱글 스레드 환경에서 동작하며, 멀티 스레드 처리가 어려울 수 있습니다. 테스트 결국 Lua 또한 트랜잭션에 대한 롤백은 지원하지 않습니다.\n기본적으로 삽입 요청 시, Validation을 체크하는 것을 고려할 때에 일어날 수 있는 최악의 시나리오는 네트워크의 단절이며 해당 방법은 어떠한 방법으로도 복구 될 수 없습니다.\nRedis Pipeline에 저장된 커맨드가 원자적으로 한번에 실행 될 수 없기 때문입니다\n테스트 시나리오\nkey1 ~ key5 까지 세팅하는 도중 에러 발생 시, 롤백 테스트\n실행 코드 (go)\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; ) var ctx = context.Background() func main() { rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, // Redis 서버 주소 }) luaScript := ` for i = 1, #KEYS do if KEYS[i] == \u0026#39;key3\u0026#39; then error(\u0026#39;key3 설정 시 에러 발생\u0026#39;) else redis.call(\u0026#39;SET\u0026#39;, KEYS[i], ARGV[i]) end end ` keys := []string{\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;key3\u0026#34;, \u0026#34;key4\u0026#34;, \u0026#34;key5\u0026#34;} values := []interface{}{\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;value3\u0026#34;, \u0026#34;value4\u0026#34;, \u0026#34;value5\u0026#34;} err := rdb.Eval(ctx, luaScript, keys, values...).Err() if err != nil { fmt.Printf(\u0026#34;Lua 스크립트 실행 중 오류 발생: %v\\n\u0026#34;, err) return } fmt.Println(\u0026#34;Lua 스크립트 실행 완료\u0026#34;) } [결과] 종합 Pros \u0026amp; Cons TxPipeline Lua Script 특징 - Redis Pipeline과 동일한 코드로 수행 가능 - 데이터 무결성 보장 - 낙관적 락 (Watch 중인 키에 변경이 일어나면 트랜잭션 실패) - Lua 언어를 통해 스크립트를 작성해야 함 - 데이터 무결성 보장 - 스크립트 전체가 하나의 단위로 실행 트랜잭션 롤백 여부 불가능 불가능 단점 - Lua에 비해 성능이 안 좋음 (Pipeline과는 비슷) - 스크립트를 관리하는 것 또한 리소스가 소모됨 - 러닝 커브 두 가지 선택지 모두, 트랜잭션 실패 시 롤백을 제공하지 않지만 데이터의 무결성은 보장됨. Value 삽입 전에 유효성 검증을 하기 때문에 데이터 삽입으로 인한 에러 발생 가능성은 적음. 최악의 경우: Redis Connection이 끊어진 경우, Redis 트랜잭션 실패 시 삭제하여 롤백을 구현해야 함. 그러나 커넥션이 끊어진 상태라면 삭제 요청 또한 실패할 가능성이 높음. Redis Sentinel을 사용할 경우, 가용성에 대한 엣지 케이스를 고려해야 하는가? 벤치마크 Redis에 1,000개 Key 세팅 기준\n항목 테스트 횟수 평균 실행 시간 (ms) Lua 스크립트 1424 0.83 TxPipeline 460 2.56 Pipeline 506 2.34 성능차이가 크리티컬 하지 않으며, 무결성은 보장되는 것이 좋기 때문에 TxPipeline 또는 Lua 스크립트를 사용하는 것 권장 ","permalink":"https://dingyu.dev/posts/redis-transaction/","summary":"Redis는 락이 없는데 어떻게 트랜잭션을 보장하죠?","title":"[DB] Redis Transaction"},{"content":"FastAPI Convention에 관하여 FastAPI란? FastAPI의 장점 의존성 주입 자동 문서화 비동기 동작 Pydantic Model 클라우드 서비스가 들어오면서 자연스럽게 MSA 라는 아키텍처 구조가 각광 받았고, 그로 인해 서버의 생태계에 변동이 일어나고 있다. 이제는 Serverless (무상태성)을 띈 Restful API 를 통하여 가벼운 통신 방식을 사용하는 아키텍처가 대세를 이루게 되었는데 이렇게 작게 나뉘어진 서비스에 특화된 것이 FastAPI 이다.\n의존성 (A는 반드시 B가 실행되어야 되는 흐름? A \u0026amp; B 는 의존관계 ) 주입에 핵심적인 Depends 함수로 인하여 인증/ DB 연결 등에서 결합도를 낮추어 유연성을 확보할 수 있게 된다 자동 문서화 문서화는 개발자에게 있어 하기 싫은 방학 숙제와 같다. 다른 프레임워크들과 달리 dependency 를 추가 하지 않아도 리독과 openAPI 자동으로 생성된다. 개발자에게 생산성 증대의 이점을 가져온다. 비동기 동작 Node 처럼 비동기가 기본이 아닌 파이썬은 동기로 동작하지만 GIL(Global Interpreter Lock)으로 인해 쓰레드의 사용도 권장되지 않았기 때문에 동시성 처리를 위한 모듈이 없는 경우가 많다. 하지만 중요한것은 FastAPI 는 이를 지원한다는 점 Pydantic FastAPI 는 Pydantic 을 매우 사랑한다. 간단하게 직렬화, 타입검사 경로 변수 읽기 등등 장점이 수두룩 한데 이는 나중에 더 자세히 다루겠다. 특징 가장 큰 것이 사실상의 표준(de facto standard) 가 없다는 것이다. 여타 프레임워크들과 다르게 역사도 길지 않고 FastAPI의 모토가 자유롭고 경량의 프레임워크를 지향하기에 어쩔수 없게도 코딩 스탠다드가 존재하지 않는다. 좋게 말하면 자유도 높인 프레임워크이지만 어떻게 보면 근본이 없다 보일 수 있을 것이다.\n목적 기존 클래스화 되지 않고 정해진 구조없이 짜여진 코드로 인하여 협업하는 데에 있어 각자의 코딩 색이 너무 진하여 같은 팀이지만 구조화 되지 않은 프로젝트라고 느껴졌다.\n이에 우리만의 Convention을 지정하여 직관적이고 유지보수에 용이한 구조를 만드는 것을 목표로 한다.\nClass Based Convention 현재 문제점 Utility에 의존한 잡다한 Feature methods 너무 많은 책임을 짊어진 클래스 (낮은 응집도) 직관적이지 않은 구조 하나의 비즈니스 레이어가 분산되어 있어 코드 가독성이 떨어짐 Dataclass, Pydantic Model 등 모델에 사용되는 Convention이 지정되어 있지 않음 요구 사항 프로젝트 구조는 일관적, 직관적 클래스는 단 한개의 책임을 가진다 비즈니스 레이어 별로 패키지를 구성한다 요구 사항에 따른 Convention 1. 프로젝트 구조는 일관적, 직관적 [FastAPI에서 제시하는 project structure]\n. ├── app # \u0026#34;app\u0026#34; is a Python package │ ├── __init__.py # this file makes \u0026#34;app\u0026#34; a │ ├── main.py # \u0026#34;main\u0026#34; module, e.g. import app.main │ ├── dependencies.py # \u0026#34;dependencies\u0026#34; module │ └── routers # \u0026#34;routers\u0026#34; is a \u0026#34;Python subpackage\u0026#34; │ │ ├── __init__.py # makes \u0026#34;routers\u0026#34; a \u0026#34;Python subpackage\u0026#34; │ │ ├── items.py # \u0026#34;items\u0026#34; submodule │ │ └── users.py # \u0026#34;users\u0026#34; submodule │ └── internal # \u0026#34;internal\u0026#34; is a \u0026#34;Python subpackage\u0026#34; │ ├── __init__.py # makes \u0026#34;internal\u0026#34; a \u0026#34;Python subpackage\u0026#34; │ └── admin.py # \u0026#34;admin\u0026#34; submodule [제안 하고자 하는 project structure]\nfastapi-project ├── app │ ├── worker (비즈니스 레이어) │ │ ├── enums.py # enums │ │ ├── models.py # pydantic models │ │ ├── dependencies.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ └── utils.py │ ├── configs │ │ ├── config.py # global config (including .env) │ │ └── log_config.py │ ├── models.py # global models │ ├── utils.py # global utils │ ├── exceptions.py # global exceptions │ ├── database.py # db connection related stuff │ └── main.py ├── aws │ ├── client.py # client model for external service │ ├── models.p │ ├── constants.py │ ├── exceptions.py │ └── utils.py ├── tests/ │ ├── domain │ └── aws ├── templates/ │ └── index.html ├── requirements │ ├── dev.txt │ ├── stg.txt │ └── prod.txt ├── .env └── .gitignore 모든 도메인 디렉토리의 root는 app이다\nmain.py에서는 그대로 FastAPI app을 초기화하고 프로젝트의 root 역할을 한다 (보편적으로 src/ 느낌) controller : 각 모듈의 엔드포인트를 가진다 enums : Enum 모델들 models : pydantic 모델들 entities : 엔티티 모델들 service : 모듈 별 비즈니스 로직 담당 dependencies : 유효성 검사 constant : 모듈 내에서 사용되는 상수값 config : 모듈 내의 설정사항 exceptions: 커스텀 예외들! 같은 관심을 갖는 메서드가 두개 이상일 경우 따로 패키지로 분류한다\n외부 패키지의 경우 app에 종속적이지 않기 때문에 app 외부에서 관리한다.\n2. 클래스는 단 한개의 책임을 가진다 저자는 응집도를 잘못 이해하고 있었다. 여러개의 연관된 관심을 가진 메서드들을 묶어 하나의 클래스로 만들고 이게 높은 응집도지 ㅋㅋ 하는 어리석음을 반복하고 있었다.\n객체지향 설계원칙인 SOLID중 이는 SRP (Single Responsibility) 단일 책임 원칙에 해당된다.\n흔히 말하는 GOD 클래스들은 다음과 같다. XXXService, XXXClient, XXXHandler, XXXWorker\n필자 또한 그러하였고 서비스안에 조금이라도 관심이 같다고 판단하면 무수히 많은 피쳐들을 남발하여 추가하였다. 이는 코드 가독성과 유지보수의 이점을 버리는 지름길이라 생각한다.\n가령 아래와 같은 피쳐를 만들어야 한다.\nex. 회원 로그를 txt 파일로 작성하는 피쳐를 만드시오\n[Service]\nclass UserService: def write_log_file(self, user_id:str) -\u0026gt; None [단일책임]\nclass UserLogWriter: def __init__(self, user:User) self.user = user def write(self) -\u0026gt; None 하나의 예시에 불과하지만 서비스들로 구성한 피쳐들이 쌓이면 가독성적이나 특히 유닛테스트에서 큰 골치를 겪을 것이다.\n또한 분산된 메서드들을 조합하는 방식에서 최대한 Pythonic하고 OOP를 따르기 위해 FastAPI의 라우터 또한 손을 보게 되었다.\n굳이 싶긴 하겠지만 시간이 된다면 클래스화하여 컨테이너로 관리하고 싶었고 상속을 통해 보일러플레이트 코드를 최소화하고자 모두 클래스로!! 바꾸게 되었다\nex. [BaseController] [HelloController] 3. 비즈니스 레이어 별로 패키지를 구성한다 간단히 말하자면 User를 도메인으로 가지면서 이에 대한 간단한 CRUD를 가진 애플리케이션을 구성한다고 하였을 경우. 아래와 같이 구성할 수 있다.\nfastapi-project ├── app │ ├── user_manager (비즈니스 레이어) │ │ ├── user_getter.py │ │ ├── user_updater.py │ │ ├── user_creator.py │ │ ├── enums.py # enums │ │ ├── models.py # pydantic models │ │ ├── entities.py # pydantic models │ │ ├── user_database.py │ │ ├── dependencies.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ └── utils.py 가령 DB로 부터 User 엔티티를 얻고자 한다면 UserGetter.get() 과 같이 직관적이게 해당 메서드가 무엇을 리턴하는지 유추할 수 있다.\nFacade Pattern을 적용하여 이들을 조합하는 하나의 Manager 레벨이 증가한다고 하더라도 이는 동일하게 적용 될 수 있다.\nmodels의 클래스 이름이 같을 수 있지 않소? 네, 물론입니다. 특히나 엔티티와 DTO의 네이밍은 겹칠 수 밖에 없죠 그렇기에 naming space를 사용하여 구분 합니다 ex.\nimport app.user_manager.entities as entity import app.user_manager.models as dto user_dto = dto.User user_entity = entity.User 구현보다 중요한 것이 설계이다. 구현 레벨의 설계도 중요하며 이러한 명확한 Convention이 있어야 통일된 Class Diagram과 Sequence Diagram, Module Diagram을 적립 할 수 있을 것이다\n해당 컨벤션이 정답이라고 결코 말할 수 없다. 그냥 이러한 컨벤션을 사용할 수도 있겠구나~ 라고 생각하면 좋을 것 같다\n","permalink":"https://dingyu.dev/posts/fastapi-convention/","summary":"클래스 기반의 FastAPI Structure Guide","title":"[Python] FastAPI Convention"},{"content":"시작에 앞서서 목적 ? 스크래핑을 이용한 데이터 수집에서 로그인하는 과정을 자동화하는 절차는 모든 웹에서 공통적으로 수행해야 하는 과제중 하나이다. 포털 사이트중 일부는 구글 Recaptcha 를 도입하여 Selenium을 통한 접근을 막게 되는데 이를 우회하기 위해 시작하게 되었다. 일반적으로 Selenium 을 사용하게 될때에 쓰이는 Chrome Driver 에 대한 이해를 심화하기 위한 과제 현재는 구글 Extension 을 활용하여 진행하지만 외부에서 배포하고 있는 유료 recaptcha solver 는 사람이 직접 캡챠를 푸는 방식을 채택하는 것이 대부분인데 그 이유를 파악하고자 하는 목적이 있다 기본 설정 1. 크롬 드라이버 설정 사용하고 있는 크롬 브라우저의 버전을 확인한다 : 크롬브라우저 설정 - Chrome 정보 해당 버전과 동일한 버전의 chrome driver를 설치한다 : https://chromedriver.chromium.org/downloads -\u0026gt; supports Chrom version {사용하고 있는 버전} 다운로드 또는 dependency 추가 / Nuget Package 추가 Code를 통하여 Chrome Version과 동일한 버전의 크롬 드라이버를 설치하여 자동화하는 과정은 추후 고도화하는 과정에서 추가할 예정에 있습니다\n2. Buster : Recaptcha Solver 다운로드 구글의 Recaptcha에서 음성을 인식하여 자동으로 타이핑 이후 우회하게 해주는 확장 프로그램입니다\n구글에 buster recaptcha 검색 이후 확장프로그램 다운로드를 진행합니다 추가 설정으로 Speech service 를 선택할 수 있습니다. Wit.ai 가 default 이며 무료로 사용할 수 있으며 Google Speech-to-Text 또한 선택할 수 있는데 논외로 한 기사에서 보았는데 97%의 recaptcha 통과율을 보이는 Speech service 라고 합니다. 다만 Recaptcha 자체가 구글에서 제공하는 것이다 보니 같은 구글의 speech 파일으로 AI의 학습 데이터셋을 활용했을 가능성이 높을것이며 해당 서비스는 유료 이기 때문에 pass 하겠습니다\nWit.ai를 통한 리캡챠 시도시 최대 8회까지 새로고침하여 리캡챠를 시도하였을 때 통과하는 수준을 보였습니다. 이것은 이후에 문제가 되는데 다음에 설명하겠습니다.\n3. Extension 설정 Python, JAVA, C# 을 막론하고 Selenium에서 제공하는 ChromeDriver() 클래스에서는 option으로 addExtension()이라는 메서드를 제공합니다\naddExtension(String extensionPath) : \u0026ldquo;.crx\u0026rdquo; 파일의 크롬 확장 프로그램의 압축 파일의 경로를 인스턴스로 옵션값을 설정하게 됩니다\n크롬 브라우저에서 도구 더보기 - 확장 프로그램 을 통하여 chrome://extentions 에 접근\n개발자 모드를 활성화 시키고 활용하고자 하는 extension의 아이디를 기억합니다 이후 확장 프로그램 압축 클릭 - extension 파일의 경로에 위치 시킵니다 (아래의 경우 1.3.1_0 을 폴더로 선택) 일반적으로 경로는 Users-{사용자 Desktop}-AppData-Local-Google-Default-Extensions에 위치합니다 (위에서 ID값을 기억한 이후 해당 ID값을 가지는 폴더를 선택하여 압축합니다) ! AppData 가 보이지 않는다면 사용자Desktop에서 \\AppData를 입력하여 접근합니다 !\n브라우저를 통한 리캡챠를 갖는 웹의 분석 코드로 작성하기에 앞서 스크래핑에 있어 가장 중요한 웹페이지의 분석 단계입니다 먼저 얻고자 하는 result(리캡챠 통과) 를 설정하고 과정을 시뮬레이션하여 바뀌게 되는 패킷의 이동이나 웹 브라우저의 변화를 감지합니다\nTest 하게 되는 url 은 https://patrickhlauke.github.io/recaptcha/ 이며 해당 url에는 항시 리캡챠가 적용되어있기 때문에 이를 토대로 분석해줍니다\nFiddler 를 통한 패킷의 변화 만약 로그인 시도시에 recaptcha가 존재한다면 HttpResponse 로 ex:needRecaptcha 와 같은 response를 로그인 페이지를 GET하게 될때에 얻을 수 있을 것입니다. 만약 needRecaptcha가 true 라면 이 일련의 과정을 거쳐야 한다고 판단할 수 있는 것이죠! needRecaptcha가 true라는 가정하에 로그인 POST 시에 Required 파라미터로 Recaptcha 토큰 값 또한 body에 넣어야 로그인이 진행됩니다. 이때문에 Recaptcha Api를 제공하는 곳에서는 이 토큰값을 반환하여 돈을 얻게 되는 것이죠. 브라우저의 변화 첫번째로 봐야 할 것은 위에 상단에 위치하는 recaptcha 입니다\ndata-sitekey 라는 속성을 갖는데 이는 웹마다 다른 고유값을 가집니다 (식별키) 실제로 recaptcha solve api를 제공하는 곳에선 이 data-sitekey 를 통하여 리캡챠를 사람이 푼뒤 토큰값을 반환하는 것으로 알고 있습니다 해당 div 에는 iframe이 존재하는데 Selenium 의 SwitchTO().Frame 을 통하여 접근할 수 있습니다 분석한 결과를 토대로 핵심만 말하자면 이 iframe 에서는 Recaptcha 가 체크되었는지, 즉 통과되었는지 여부를 알 수 있습니다 aria-checked = false 에서 true 로 바뀌는 시점이 리캡챠가 풀리는 시점입니다. 현재 Selenium을 통한 스크래핑 과정중에 있기때문에 현실에서는 눈으로 캡챠가 풀렸는지 확인할 수 있지만 Selenium을 통하였을때 통과되는 분기점을 찾는것은 매우 중요합니다. 저는 이 aria-checked 라는 attribute 값의 변화를 분기점으로 두고 스크래핑하였습니다 또한 리캡챠가 완료되었을때 token 값이 담기는 iframe 이기 때문에 핵심이라고 할 수 있습니다 두번째는 title=\u0026ldquo;recaptcha challenge expires in two minutes\u0026rdquo; 를 갖는 iframe 입니다\n만약 리캡챠를 푸는것이 초기라면 그림이나 음성을 통한 수행과정 없이도 바로 체크를 얻을 수 있을것입니다. 하지만 반복적인 리캡챠 수행이 이루어지게 되었을때 그림, 음성 수행과정을 수행하는 iframe 이 이곳입니다 buster 확장프로그램 버튼이 위치하는 iframe이기도 합니다 앞서 설명했듯 Wit.Ai 를 통한 Speech-to-Text 는 완벽하지 않습니다. 평균적으로 5회 정도하였을때 성공하는 정도를 보였습니다. 결국 성공할 때 까지 refresh 버튼을 통하여 Speech 를 초기화한뒤 buster button을 계속 눌러줘야 합니다 (성공할때까지)\n! 구글은 이러한 정형화된 Action 을 파악하여 일정 횟수를 초과하면 해당 ip 에서는 아에 리캡챠를 수행하지 못하도록 막아버립니다. 이러한 이유때문에 이 프로젝트가 실험적인 요소로 남을 수 밖에 없는 것입니다 !\nTo Code (C# Base) 위의 분석을 토대로 전체적인 Flow 를 구상합니다\n로그인 페이지에 접근 -\u0026gt; response에서 needRecaptcha 가 true ? -\u0026gt; Selenium을 통한 브라우저 조종 ( recaptcha checkbox 가 체크될때 까지 buster button 과 reload를 눌러 리캡챠를 통과 시킴 ) -\u0026gt; recaptcha token 을 포함하는 POST 메서드를 통하여 로그인 통과\n유닛테스트 (MS Test)를 기반으로 프로젝트를 생성하겠습니다\nNuget Package 를 통하여 Selenium.WebDriver 를 다운로드하여 프로젝트 패키지에 넣어줍니다\n크롬 드라이버 생성\nNuget 을 통하여 ChromeDriver를 생성하였다면\nChromeOptions _options = new ChromeOptions(); _options.AddExtension(@\u0026#34;...\\...\\path_to_.crx\u0026#34;); ChromeDriver _driver = new ChromeDriver(_options); chromedriver.exe를 직접 설치하였다면 (chormedriver.exe 가 아닌 포함 된 폴더로 지정)\nChromeOptions _options = new ChromeOptions(); _options.AddExtension(@\u0026#34;...\\...\\path_to_.crx\u0026#34;); ChromeDriver _driver = new ChromeDriver(@\u0026#34;...\\...\\path_to_chromedriver_folder\u0026#34;,_options); Extra ) Profile 을 통한 설정으로 크롬드라이버 생성시 만약 다른 사용자가 만들어놓은 Profile에 접근 할 수 없어 보안상 문제가 없다고 한다면 통용되는 방법입니다\n크롬에서 프로필 사진 클릭 계정 없이 계속 신규 프로필 생성 새로 만든 프로필의 경로 Users-{사용자 Desktop}-AppData-Local-Google-Profile{만든순서} 에 위치합니다\n새로 만든 프로필에서 buster extension을 다운로드\nChromeDriverOption 설정을 통하여 드라이버 생성\nChromeOptions _options = new ChromeOptions(); _options.AddArgument(\u0026#34;--user-data-dir=\u0026#34; + @\u0026#34;path_to_profile\u0026#34;); _options.AddArgument(\u0026#34;--profile-directory=ProfileNumber\u0026#34;); ChromeDriver _driver = new ChromeDriver(_options); **! 주의 사항 ! **: 해당 프로필의 브라우저가 열려있을때 Selenium 으로 해당 프로필 정보로 드라이버 생성시 Error 가 발생합니다\n우선 리캡챠 체크 여부를 판별하는 메서드와 해당 WebElement 가 존재하는지 여부를 판별하는 메서드를 따로 생성하여 관리 하였습니다 public static bool IsChecked(ChromeDriver driver) { bool check = driver.FindElement(By.Id(\u0026#34;recaptcha-anchor\u0026#34;)).GetAttribute(\u0026#34;aria-checked\u0026#34;).Equals(\u0026#34;true\u0026#34;) ? true : false; return check; } public static bool IsExistByCss(ChromeDriver driver, string cssQuery) { try { driver.FindElement(By.CssSelector(cssQuery)); } catch (Exception e) { return false; } return true; } 세션시간 초과로 캡챠가 도중에 풀렸을 수도 있기때문에 미리 캡챠 div가 있는지 판별 if (IsExistByCss(_driver, \u0026#34;iframe[title=\\\u0026#34;reCAPTCHA\\\u0026#34;]\u0026#34;)) recaptcha 가 존재한다면 앞서 설명한 두개의 iframe Element를 저장해줍니다 IWebElement first = _driver.FindElement(By.CssSelector(\u0026#34;iframe[title=\\\u0026#34;reCAPTCHA\\\u0026#34;]\u0026#34;)); var x = _driver.PageSource; IWebElement second = _driver.FindElement(By.CssSelector(\u0026#34;iframe[title=\\\u0026#34;reCAPTCHA 보안문자 2분 후 만료\\\u0026#34;]\u0026#34;)); 첫번째 iframe 으로 전환후 리캡챠 체크박스를 클릭합니다 ( 이상하게 Element.Click()이 통하지 않아 executeScript를 사용하니 적용이 되었습니다 ) _driver.SwitchTo().Frame(first); var checkBox = _driver.FindElement(By.ClassName(\u0026#34;recaptcha-checkbox\u0026#34;)); _driver.ExecuteScript(\u0026#34;arguments[0].click()\u0026#34;, checkBox); // IFrame 에 접근시 JS를 통하지 않고 바로 Click() 수행시 동작하지 않는 문제 체크박스 클릭이후 체크여부를 판별합니다 if (!IsChecked(_driver)) 첫번째 iframe -\u0026gt; 두번째 iframe 으로 접근합니다 ( iframe 간에는 바로 Switch가 불가능하며 본래 html로 복귀 이후 이동하여야 합니다 ) 이후 buster button을 클릭합니다 _driver.SwitchTo().DefaultContent(); // 본래 html 로 복귀 _driver.SwitchTo().Frame(second); _driver.Manage().Timeouts().ImplicitWait = TimeSpan.FromSeconds(200); var busterHolder = _driver.FindElement(By.ClassName(\u0026#34;help-button-holder\u0026#34;)); busterHolder.Click(); 만약 리캡챠가 풀리지 않았다면 풀릴때까지 10회 반복합니다 ( 이미지 버튼을 클릭하여 Speech reload 이후 buster button click) if (!IsChecked(_driver)) { _driver.SwitchTo().DefaultContent(); // 본래 html 로 복귀 _driver.SwitchTo().Frame(second); _driver.FindElement(By.ClassName(\u0026#34;rc-button-image\u0026#34;)).Click(); _driver.FindElement(By.ClassName(\u0026#34;help-button-holder\u0026#34;)).Click(); } else { isChecked=true; break; } 마지막으로 체크가 되었다면 토큰값을 반환합니다 if (isChecked) { _driver.SwitchTo().DefaultContent(); _driver.SwitchTo().Frame(second); _token = _driver.FindElement(By.Id(\u0026#34;recaptcha-token\u0026#34;)).GetAttribute(\u0026#34;value\u0026#34;); return _token; } 개선사항 위의 프로젝트를 진행하면서 구글의 똑똑함을 다시한번 느꼈습니다. 만약 과금을 하더라도 Google speech-to-text 를 이용하였다면 높은 성공율으로 트래픽이 다소 많더라도 리캡챠를 풀 수 있었겠지만 그렇지 않았기에 결국 자동화된 프로그램으로 인식되어 Recaptcha가 밴 될수도 있다는 것을 알게 되었죠..\nGoogle 의 Recaptcha v3 같은 경우에는 커서의 움직임이나 행동패턴을 통하여도 구분한다고 하는데 이 프로젝트를 고도화 한다 하여도 v3에는 아마 꼬리가 잡히지 않을까 합니다.\n그래서 많은 ReCaptcha Solver API 가 실제 사람들을 고용하여 수동으로 풀고 토큰값을 반환하는게 아닐까 그런 생각도 들고 말이죠.\n핵심적으로 위의 프로젝트에서 개선되어야 할점을 꼬집어 보자면 API로서의 역할을 하기에는 불완전 요소가 많다는 점입니다\nChrome 브라우저 버전과 Chrome driver 버전의 일치를 manually 하여야 한다는 점 트래픽이 많고 리캡챠의 실패가 잦아 질수록 구글에서의 리캡챠 밴이 될 확률이 높다는 점 리캡챠가 풀리는 2분내에 로그인까지 완료가 되지 않을 수도 있다는 점 이러한 점들이 있겠네요.\n","permalink":"https://dingyu.dev/posts/crawling-selenium-solver/","summary":"누구도 날 막지 못해! 크롤링을 하는데 Recaptcha에 막히셨다구요? Buster를 사용해보셨나요?","title":"[Crawler] Recaptcha Solver"}]
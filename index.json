[{"content":"배경 서비스 별로 다른 프로젝트 구조 프로젝트 마다 코드 파악이 힘듦 e.g.\nSomeAPI ├── .vscode ├── api ├── build ├── config ├── data ├── db ├── externalservice ├── httpsrv ├── httptest ├── mocks ├── log ├── cli ├── repository ├── util ├── .gitignore ├── .gitlab-ci.yml ├── changelog ├── data.go ├── diag_debug.go ├── diag.go ├── go.mod ├── go.sum ├── main.go ├── Makefile ├── release.conf ├── README.md 공통 컨벤션이 없어 공통 모듈/CI를 사용하기 힘듦 모든 프로젝트에서 사용될 수 있도록 고려할 사항이 많아짐 → 개발 생산성 ↓ 온보딩 과정이 힘듦 신규 합류된 팀원이 Go언어에도 익숙치 않은 상태에서 너무 제각각인 스타일으로 인해 혼란이 옴 팀이 Go 언어 생태계로 전환을 완료했고, 이제는 노하우가 생겼다 생각함 장기적인 운영에서 컨벤션 사용으로 유지보수성 ↑ 신규 프로젝트에서 새로운 프로젝트 구조에 대한 고민을 하는 일, 기존 프로젝트에서 리팩토링의 방향성을 잡기 힘듦 개발 생산성 ↓ 프로젝트 구조 제안 적용이 Must인 부분은 * prefix를 가집니다 (그 외, Optional)\n엔터프라이즈 레벨의 프로젝트가 아닌 MSA를 기준으로 작성됩니다 추후 리팩토링을 하더라도 도메인 단위의 MSA로 물리적인 격리가 진행되기 때문\u0026hellip;\n프로젝트 구조 샘플 도메인을 \u0026ldquo;매치 샘플링\u0026quot;이라 하였을 때\n. ├── *docs // 프로젝트 별 문서들 │ ├── *swagger.yaml // API 스웨거 문서 │ ├── sequence.md // 비즈니스 시퀀스 다이어그램 │ └── architecture.md // 시스템 아키텍처 다이어그램 ├── *cmd │ └── *main.go // 프로젝트 진입점, DI 주입 ├── pkg // 비즈니스 로직에 종속적이지 않은 패키지 (외부에서 import 하여도 상관없는 모듈) │ ├── file_parser.go │ └── time_convertor.go └── *internal // 외부에 공개되면 안되는 비즈니스 로직 영역 (도메인 영역) ├── *handler │ ├── *v1 │ │ └── sampling_handler.go // 도메인 핸들러 v1 │ ├── v2 │ │ └── sampling_handler.go // 도메인 핸들러 v2 │ ├── server.go // handler가 많을 경우, handler를 등록할 server를 둡니다 │ ├── health_handler.go // v1, v2 공통 핸들러 │ ├── swagger_handler.go // 프로젝트 테스트 용 openapi 핸들러 (CORS 허용) │ └── auth_middleware.go // 미들웨어들 ├── data │ ├── mysqldb.go // DB client 커넥터 │ ├── redis.go // DB client 커넥터 │ ├── feature_event_producer.go // Kafka event producer - xxx_producer │ ├── match_repository.go // ORM 수행 repository (DB client 주입) - xxx_repository │ └── nass_api.go // 외부 API Data Layer - xxx_api ├── *service │ ├── kda_sampler.go // Data layer 혹은 다른 service를 주입 받아 구현 │ ├── match_sampling_usecase.go // service 가 많을 경우, 오케스트레이션 해주는 유즈케이스 구현 │ └── kda_sampler_test.go // 비즈니스 로직의 유닛테스트 ├── logger.go // 애플리케이션 전역에서 사용될 기능 ├── constants.go // 외부에서 참조 되어야 하는 상수 값 정의 └── *config.go // application 설정 파일 ├── *gitlab-ci.yml ├── *go.mod ├── *go.sum └── *README.md // 프로젝트에 대한 배경, 유즈케이스, 설치 방법 기술 구분 필수 여부 설명 예시 docs ✔ 프로젝트 아키텍처, 시퀀스 다이어그램, 스웨거 문서를 관리 - swagger.yaml- sequence.md cmd ✔ 프로젝트 진입점, 실행 가능한 파일 및 스크립트 관리 - main.go- start.sh pkg 애플리케이션에 종속적이지 않은 유틸리티 기능 관리 - time_convertor.go- file_parser.go internal ✔ 외부에 공개되면 안되는 비즈니스 로직(도메인) 영역애플리케이션 전역에서 사용될 기능 담당 - config.go- logger.go- constants.go internal/handler ✔ API라면 API Handler일 것이고 Consumer라면 Consumer Handler 담당- 버저닝은 *필수, HTTP/gRPC/MQ/Kafka 와의 통신을 담당- 미들웨어는 Optional- handler가 여러개일 경우, server 에서 handler를 등록할 수 있도록 합니다 - blacklist_handler.go- alive_handler.go- log_middleware.go- server.go internal/data 3 Tier Architecture 중, Data Layer 영역영속성을 가진 데이터 CRUD 담당(외부 API 또한 해당됨, Kafka 또한 stream에 저장하는 행위로 간주) - event_producer.go- blacklist_repository.go- member_api.go internal/service ✔ 비즈니스 로직을 수행하는 비즈니스 영역- 각각의 서비스는 단일 책임 원칙에 따라 하나의 책임만 수행- 서비스가 다수일 경우, 이를 오케스트레이션 해주는 xxx_usecase로 구현- 서비스 코드의 단위 테스트는 필수 (일부 의존성에 따른 테스트 불가 시 패스) - fraud_detect_usecase.go- fraud_retriever.go- rule_analyzer.go ./ (root) ✔ 프로젝트 실행 및 운영을 위한 파일 영역- 리드미는 필수로 작성 (유즈케이스와 설치 방법은 항상 기술) - gitlab-ci.yml- README.md 상수 컨벤션 기본적으로 카멜케이스와 파스칼케이스를 원칙으로 사용합니다\n→ 하나의 도메인 파일에서 도메인과 관련된 상수가 다른 패키지에 속해 있는 경우, 수정에도 어렵고 추적에도 귀찮음이 동반 됨을 느꼈습니다\n→ 하나의 책임을 지는 파일 내에서 private 상수로서 관리 된다면 유지보수에도 용이할 것이고 코드 파악에도 용이할 것이라 생각합니다\n복수 패키지에서 다수 의존될 여지가 있는 경우 (Pascal) internal layer의 constants.go 파일에 상수 값들을 정의 합니다\npackage internal const ( LanguageCodeKorean = \u0026#34;ko\u0026#34; LanguageCodeEnglish = \u0026#34;en\u0026#34; LanguageCodeChinese = \u0026#34;zh_CN\u0026#34; LanguageCodeJapanese = \u0026#34;ja\u0026#34; ) 하나의 패키지 내 혹은 하나의 파일에서 사용할 경우 (Camel) 동일 패키지 내에서는 private 변수에 참조할 수 있습니다\npackage handler const ( // resultSuccess : 성공 응답 resultSuccess = \u0026#34;true\u0026#34; // resultFailure : 실패 응답 resultFailure = \u0026#34;false\u0026#34; ) 불가피하게 다른 패키지로부터 참조되어야 하는 경우 상수는 private으로, struct의 Public 함수로 참조 될 수 있게 합니다\npackage handler const ( // samplerEndpoint : 매치 샘플링 엔드포인드 samplerEndpoint = \u0026#34;/v1/:match_id\u0026#34; ) // Endpoint : 핸들러의 엔드포인트를 반환 func (h *SamplerHandler) Endpoint() string { return samplerEndpoint } 데이터 모델 컨벤션 데이터 모델은 가급적 별도 파일이 아닌, 수행되는 파일에서 정의하여 사용합니다\n→ model을 별도로 지정해 둘 경우, 특정 도메인에 대한 수정이 있을 때 참조된 여러 파일을 수정해야 하는 불편함이 존재합니다\n→ 같은 계층 간의 데이터 이동에 대해서는 파라미터로 주고 받고 다른 레이어 간 통신은 *레이어 간 데이터 모델 컨벤션에 따라 데이터 모델을 주고 받습니다\n→ parameter가 두 개 이상일 경우, 데이터 모델로 만들어 관리합니다\n레이어 간 데이터 모델 컨벤션 handler → service\nrequest → serviceDTO\nfunc (h *Handler) CreateMatch(c *gin.Context) { var req matchRequest if err := c.ShouldBindJSON(\u0026amp;req); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // Service 호출 err := h.service.Create(req.ToServiceDTO()) // so on } service → data\nserviceDTO → entity\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { ... // repository 계층에 MatchEntity 삽입 요청 id, err := b.repository.Insert(match.ToEntity()) if err != nil { return 0, err } return id, nil } data → service\nentity → serviceDTO\nfunc (r *MatchRepository) Insert(entity MatchEntity) (int, error) { // 데이터 레이어에서 UserEntity 가져오기 result, err := s.db.Create(\u0026amp;entity) ... return result.ID, nil } 데이터 모델에서의 조건 검사 모델을 주고 받는 경우, 가독성을 위해 조건 검사는 함수로 실시 합니다\n단위 테스트에 용이 하며, 한눈에 비즈니스 로직을 파악하기 쉬워 집니다\n[AS-IS]\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { if strings.HasPrefix(match.Version, \u0026#34;rc\u0026#34;) \u0026amp;\u0026amp; match.detail == \u0026#34;test\u0026#34; { return } // 비즈니스 로직 } [TO-BE]\nfunc (b *MatchCreater) Create(match MatchDTO) (int, error) { if match.IsTest() { return } // 비즈니스 로직 } 테스트 컨벤션 비즈니스 로직의 테스트는 선택사항이 아닌 필수입니다. 이미 정의된 에러에 대한 테스트케이스는 최대한 상세하고 간결하게 작성합니다.\nDeterministic 비동기 단위 테스트 비동기로 처리하고 결과 값을 확인하지 않거나 time sleep 이후의 로깅을 멈추세요\nDI + Eventually를 통한 flaky test를 방지합니다\n로거 주입 // NewQueue 비즈니스 로직을 수행할 Queue 생성자 func NewQueue( config Config, httpClient *http.Client, logger *zerolog.Logger, ) (queue Queue, err error) { // queue는 Start()를 통해 thread executor가 실행될때에 생성됩니다. queue = Queue{ config: config, client: httpClient, logger: logger, quitChan: make(chan struct{}), } return } 응답 값 테스트 큐 로직 실패 테스트 t.Run(\u0026#34;큐 처리 실패시, 실패 로깅 테스트\u0026#34;, func(t *testing.T) { // given var buffer bytes.Buffer ... 로거 의존성 주입 // when ... 비동기 작업 수행 event1, err := queue.Push([]byte(validJSON1)) assert.NoError(t, err) event2, err := queue.Push([]byte(validJSON2)) assert.NoError(t, err) // then assert.Eventually(t, func() bool { output := buffer.String() return strings.Contains(output, event1.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, event2.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, `\u0026#34;success\u0026#34;:false`) }, 1*time.Second, 10*time.Millisecond) }) 큐 로직 성공 테스트 t.Run(\u0026#34;큐 처리 성공시, 성공 로깅 테스트\u0026#34;, func(t *testing.T) { // given var buffer bytes.Buffer ... 로거 의존성 주입 // when ... 비동기 작업 수행 event1, err := queue.Push([]byte(validJSON1)) assert.NoError(t, err) event2, err := queue.Push([]byte(validJSON2)) assert.NoError(t, err) // then assert.Eventually(t, func() bool { output := buffer.String() return strings.Contains(output, event1.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, event2.TraceID().String()) \u0026amp;\u0026amp; strings.Contains(output, `\u0026#34;success\u0026#34;:true`) }, 1*time.Second, 10*time.Millisecond) }) ","permalink":"https://dings-things.github.io/blog/posts/go-convention/","summary":"효율적인 Go Project Structure Guide","title":"[Go] Go Convention"},{"content":"class Me: def __init__(self): self.name = \u0026#34;Jung Woo Lee\u0026#34; self.born_year = 1996 self.MBTI = \u0026#34;ENTP\u0026#34; self.location = \u0026#34;Seoul, Korea\u0026#34; self.school = \u0026#34;Tsinghua University\u0026#34; self.interests = [\u0026#34;BE\u0026#34;, \u0026#34;DevOps\u0026#34;, \u0026#34;MLOps\u0026#34;, \u0026#34;Go\u0026#34;, \u0026#34;Kafka\u0026#34;, \u0026#34;TDD\u0026#34;, \u0026#34;Automation\u0026#34;] ","permalink":"https://dings-things.github.io/blog/about/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Jung Woo Lee\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eborn_year\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1996\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMBTI\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;ENTP\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elocation\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Seoul, Korea\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eschool\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Tsinghua University\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einterests\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;BE\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;DevOps\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;MLOps\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Go\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Kafka\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;TDD\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Automation\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"About"},{"content":" 소스 코드 : https://github.com/dings-things/coffee_pal\n목적 일을 하는 것에서 그치는 것이 아닌, 일을 잘 하고 싶은 조직에서 좋은 문화를 구성하는 것은 일의 생산성이나 품질에도 여러 이점을 가져온다\n필자가 개발하고자 하는 \u0026ldquo;CoffeePal\u0026quot;은 문제에 막혀 길을 잃어버린 사람이나 소소한 스몰 토크로 일에도 능률을 키울 수 있는 그러한 앱을 만들 고자 커피 친구라는 의미에서 커피팔을 기획하게 되었다\n개발에 앞서\u0026hellip; 먼저 사내 커뮤니케이션 툴인 Slack에서 상호작용을 통해, 쉽고 빠르게 커피 친구를 매칭해줘야 하는 요구사항이 있다\n이에 앞서 간단하게 Slack Workflow를 통하여, 전반적인 흐름을 파악해 본다\nTrigger Point 생성 테스트 용이기 때문에, Trigger는 :커피: 이모지로 반응하였을 때 워크플로가 실행 되도록 한다\n활성화 하기 반응한 메시지를 전송한 사용자에게 메시지를 보내어, 커피팔 매칭을 시작할 지 여부를 확인한다\n양식에서 정보 수집 개인화된 서비스를 위해 MBTI, 생년월일을 입력 받는다. 해당 데이터의 기입은 Optional 하게 만든다\n대상, 일시, 주제를 지정한다 커피팔 대상과 커피 일정, 그리고 전반적인 주제를 사전에 정의한다.\n커피팔 대상에게 초대 메시지 보내기 앞서 지정한 데이터를 통해 커피팔에게 간략하게 초대 메시지를 보낸다\n개인적으로 Slack 워크플로를 처음 사용해 보았는데, UI가 깔끔하고 사용성이 괜찮음을 느꼈다\n다만, 사용자와 \u0026ldquo;상호작용\u0026quot;이라기 보다는, 일방적인 소통에 가깝기 때문에 slack app으로 확장 해보도록 한다\n먹고 싶지 않은 음식을 억지로 먹여주는 느낌\u0026hellip; 이랄까요?\n요구사항 미리 저장된 데이터를 기반으로 사용자 기반의 매칭을 할 수 있어야 한다\n개인정보 입력 시, 매칭 시스템 Trigger App을 사용한 상호작용을 위해 컴퓨팅 리소스를 확보한다\n사내 서버 방화벽 관리 어려움 소켓 통신을 통한 빠른 응답 AWS Lambda 프리티어 기준 무료 서버리스 AWS API GW와 연계 가능 프리티어 종료 후, 유지 비용 고려 사용자에게 한눈에 봐도 알 수 있는 UI 제공\nSlack Block kit 활용 구축하기 Lambda로 구축하기 Slack APP 생성 Lambda 설정 Socket Mode 설정 Slack APP 생성 1. App 생성하기 slack API에서 App 생성하기 Slack APP 생성 2. From scratch를 클릭 Slack APP 생성 3. 앱 workspace와 이름 지정하기 Slack APP 생성 4. 유저 상호작용을 위한 봇 설정 Slack APP 생성 5. 이벤트 활성화 Lambda 설정 1. Lambda 페이지에서 함수 생성하기 Lambda 설정 2. 함수 설정, 런타임 및 아키텍처 설정 Lambda 설정 3. API Gateway 설정 API Gateway는 HTTP 요청을 Lambda 함수로 라우팅 할 수 있는 매우 유용한 트리거입니다. Slack Events API와 Lambda를 연동하기 위해서는 API Gateway를 통한 설정이 필요합니다.\n라고 생각하던 와중\u0026hellip; 서버가 이미 있다면 굳이 람다로 구현을 해야하는가? 이미 있는 서버를 안쓰는 것이 더 낭비가 아닌가? 🤔 고민에 빠졌습니다\n서버는 남는 개발 서버를 활용하여 처리를 하고 소켓 모드로 일괄 처리하는 방안을 생각하게 되었습니다\nSocket Mode 설정 소켓 모드란? 소켓 모드를 켜면 이러한 페이로드를 공개 HTTP 앤드포인트인 요청 URL로 보내는 대신 WebSocket 연결을 통해 앱의 상호 작용과 이벤트를 라우팅합니다. 앤드 포인트를 사용하지 않음으로서 여러 요청에 대한 보안적인 위협을 피할 수 있습니다. 또한 여러 Event에 대해 일일이 구독을 하지 않아도 됩니다\n1. 애플리케이션 전역 토큰 생성 전역 토큰에 권한을 부여 → 서버 내에서 권한을 사용하여 슬랙 제어 2. 토큰의 Scope 지정 channels:read : 채널의 사용자 정보 취득 chat:write : 채널에서 쓰기 권한 chat:write.public : 채널에 invite 되어 있지 않아도 쓰기 권한 groups:read : private 채널 정보 취득 groups:write : private 채널에 쓰기 권한 im:write : DM 발송 권한 mpim:write : group DM 발송 권한 reminders:write : 리마인더 설정 권한 개발 Slack Bolt Slack 애플리케이션을 개발하기 위한 프레임워크 주로 Node.js, Python, JavaScript와 같은 언어로 작성되었으며, Slack 플랫폼과 통합된 애플리케이션을 쉽게 만들 수 있도록 도와줍니다.\n굳이\u0026hellip;? 싶지만\u0026hellip;\n안쓰면 불필요한 작업이 너무 많아집니다. 이는 곧 낮은 생산 속도, 유지 보수도 힘들어지죠\n쓰지 않을 때 from slack_sdk import WebClient from slack_sdk.errors import SlackApiError import os import json import base64 import urllib.parse def lambda_handler(event, context): bot_token = os.getenv(\u0026#39;BOT_KEY\u0026#39;) # 토큰으로 인증 client = WebClient(token=bot_token) # Base64 인코딩 여부 확인 및 디코딩 if event.get(\u0026#39;isBase64Encoded\u0026#39;, False): try: # Base64 인코딩된 본문을 디코딩하여 문자열로 변환 decoded_body = base64.b64decode(event[\u0026#39;body\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;) event_body = urllib.parse.unquote_plus(decoded_body)[8:] except Exception as e: print(f\u0026#34;Error decoding base64 body: {e}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps({\u0026#39;message\u0026#39;: \u0026#39;Invalid base64 encoded body\u0026#39;}) } ele: event_body = event[\u0026#39;body\u0026#39;] print(event_body) # 디코딩된 본문을 JSON으로 파싱 try: event_data = json.loads(event_body) except json.JSONDecodeError: print(\u0026#34;JSONDecodeError occurred. The body may not be in valid JSON format.\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps({\u0026#39;message\u0026#39;: \u0026#39;Invalid request body\u0026#39;}) } # Event 타입 확인 event_type = event_data.get(\u0026#39;event\u0026#39;, {}).get(\u0026#39;type\u0026#39;) # Event 타입에 따라 분기로 처리 쓸 때 app = App(token=settings.SLACK_BOT_TOKEN) logger = logging.getLogger(__name__) # app_home_opened 이벤트 핸들러 등록 @app.event(\u0026#34;app_home_opened\u0026#34;) def handle_app_home_opened( event: Union[ str, Pattern, Dict[str, Optional[Union[str, Sequence[Optional[Union[str, Pattern]]]]]], ], client: WebClient = None, ) -\u0026gt; SlackResponse: ... # 버튼 액션 핸들러 등록 @app.action(\u0026#34;suggest_coffee_chat_button\u0026#34;) def handle_random_coffee_chat_button( ack, body, client: WebClient = None ) -\u0026gt; SlackResponse: ... 특정 이벤트 / 액션 / 뷰 를 디버깅 할 때에 Bolt를 활용하면 인증, event, action에 따른 분기 처리, 미들웨어 설정 등등\u0026hellip;\n서비스 로직을 수행하기전 거쳐야 했던 중복되는 과정들을 생략하고 서비스 로직에 집중할 수 있습니다.\n유지보수 ↑ 가독성 ↑ Bolt에서 제공되는 기능 중 크게 5가지를 사용하게 됩니다.\nmiddleware 앱 전반의 로깅 및 인증 관리 action 버튼 클릭, Select 메뉴 등의 상호작용 시 발생 view 모달과 같은 복잡한 인터페이스를 생성 및 관리 event Slack 워크스페이스 내에서 발생하는 다양한 이벤트. 가령 채널에 참가 / 사용자의 메시지 전송 등등 Block Kit 슬랙 앱 개발의 꽃은 역시 Block Kit이라 말할 수 있습니다. 각 화살표는 Block을 나타내며 type에 따라 구분되는데 이를 Stacking 하여 하나의 View를 형성합니다.\nex.\nHOME_OPENED = { \u0026#34;type\u0026#34;: \u0026#34;home\u0026#34;, \u0026#34;blocks\u0026#34;: [ ... ], } HOME 구성 요소 Section 섹션을 활용하여 직관적인 UI로 사용자 경험을 최적화 합니다\n가로 섹션 세로 섹션 Input Slack API는 Restful API 답게 Stateless (무상태성)을 띕니다. 각 요청이 독립적이며, 서버가 클라이언트의 이전 요청에 대한 정보를 유지하지 않는것이죠\nInput 없이는 유저의 이전 View에서의 상태를 알 수 없기 때문에 상호작용이 불가합니다. 랜덤 커피챗을 예로 들어 보겠습니다 서버가 만약 순간적인 단절이 생겼을 때에도 다시 요청 시, 이전 Input 값을 토대로 무상태성 요청을 보낼 수 있어\n안정성이 보장됩니다\n개선 사항 Slack DataStore를 이용한 유저의 상태 값 저장 TTL을 지정하여 예약된 커피챗 일정의 조회 / 수정 / 삭제 기능 인사정보를 조회하여 나만의 맞춤형 커피팔 선정 인사 API 권한을 얻어 직급 / 나이 / 직군 별 맞춤형 커피팔을 추첨하는 기능 UI 개선 딱 봐도 이거네~ 누구나 알기 쉽게 사용자 편의성을 고려한 View 구성 CI/CD 및 인프라 구성 허락을 구한다면.. 별도 인프라로 full time 사용가능한 앱 구성 CI CD 파이프라인으로 누구나 기여하여 새로운 기능을 추가하도록 오픈소스화!! 마치며 개발자로 살아오며 “우분투\u0026rdquo; 정신에 깊게 공감하고 있었습니다\n\u0026lsquo;우리가 함께 있기에 내가 있다(I am because you are)\u0026rsquo;\n우리가 함께할 수 있는 환경을 구성하는 것도 중요하다 생각됩니다. 모든 이가 소통에 두려움을 느끼지 않고 \u0026ldquo;함께\u0026quot;가 되었으면 하는 마음에\n커피팔 을 만들게 되었습니다 기술적인 어려움에 부딪히거나, 보다 긴밀한 협업을 위해 아이스 브레이킹이 필요하시다면 여러분도 슬랙봇을 만들어 보세요 :)\n","permalink":"https://dings-things.github.io/blog/posts/coffee-pal/","summary":"나 개발잔데 옆에 사람이랑 슬랙으로 대화한다.. 우리 이제 친해져요","title":"[DX] 사내 커피 챗 슬랙 봇 개발기"},{"content":"배경 개발자가 직접 로그 모니터링을 통하여 장애 대응 아래와 같은 이유로 로그 모니터링에도 제약 사항이 존재 Field Type의 불일치로 인한 Elasticsearch field mapping Error 발생 → 로그 이벤트의 DROP 시스템 로그로 기록되는 경우, 스택 트레이스를 위하여 별도로 SE에게 시스템 로그를 요구하는 공수가 필요 목표 Go를 사용하는 프로젝트에서 공통적으로 표준이 될 수 있는 센트리 구조 확립 센트리에 대한 기능 명세 / 가이드라인 제공 센트리 적용 이후, 빠른 장애 대응을 통한 안정적인 서비스 구축 본 글은 센트리 계정이 있으며, 센트리 프로젝트를 이미 생성하였다 가정하고 진행됩니다.\nSentry에 대하여 Capture Exception 에러 추적(Capture Exception): 애플리케이션에서 발생하는 예외와 에러를 자동으로 감지하고 기록합니다. 센트리는 스택 트레이스(stack trace)와 함께 에러 발생 시점의 환경 정보를 제공하여, 에러의 원인을 쉽게 파악할 수 있도록 도와줍니다.\nTransaction 성능 모니터링(Transactions): 애플리케이션의 성능을 모니터링하며, 웹 요청이나 API 호출 등의 트랜잭션을 추적합니다. 각 트랜잭션의 응답 시간, 성공 및 실패 비율과 같은 세부 정보를 제공하여 성능 병목 현상을 식별하고 개선할 수 있도록 도와줍니다.\nTrace 트레이싱(Trace): 애플리케이션의 트랜잭션을 세부적으로 추적하여, 서비스 간 호출, 데이터베이스 쿼리 등의 작업에 걸리는 시간을 분석합니다. 이를 통해 애플리케이션 전체의 성능을 이해하고, 문제가 되는 부분을 파악할 수 있습니다.\nAlert 이슈 관리 및 알림: 센트리는 에러와 성능 문제를 이슈로 관리하며, 발생 시 지정된 이메일이나 슬랙(Slack) 등의 통지 채널을 통해 알림을 보냅니다. 개발자는 이슈를 할당받고, 처리 상태를 업데이트하며, 문제 해결을 위해 협업할 수 있습니다.\nRelease Tracking 릴리즈 추적(Release Tracking): 애플리케이션의 버전을 추적하여, 새로운 릴리즈가 에러 비율에 미치는 영향을 분석할 수 있습니다. 이를 통해 최근 배포된 변경사항이 문제를 일으키고 있는지 파악할 수 있습니다.\nSentry Alerts 센트리 알람을 통해 협업 툴과 연동하여 개발자가 쉽게 대응할 수 있도록 합니다.\n설정 STEP BY STEP 대시보드 - Alert - Create Alert 트리거 설정\nIssues : 에러의 stacktrace를 기반으로 이슈가 생성되는데, 에러의 유형 별로 센트리 알람 트리거 에러 유형 별로 처리가 필요할 때 사용 ex. API를 기준으로 HTTP status 코드를 기반으로 설정 ex. Service의 유형 기반으로 설정 Number of Errors : 에러의 횟수 기반으로 센트리 알람 트리거 동일한 유형의 에러이며, 횟수 기반 처리가 필요할 때 사용 Users Experiencing Errors : 정의된 User 기반 임계치 설정으로 센트리 알람 트리거 특정 Page 내에서 사용자 경험 최적화 또는 이슈 발생을 확인이 필요할 때 사용 ex. 100 명의 유저가 로그인 페이지에서 에러가 발생 세부 조건 설정\nWHEN : 알람이 트리거 되는 시점 정의\nany (아래 조건 중 하나라도 만족할 경우) / all (모든 조건을 만족하는 경우) 선택 이슈의 상태 / 이슈의 횟수를 기준으로 선정 IF : 이벤트의 세부 조건\n태그 기반 / 발생 빈도 기반 / 카테고리 기반 THEN : 액션 선정\n메일 / 슬랙 / 팀즈 등으로 액션 지정 개발하기 Client Options Dsn: _Data Source Name_의 약자로, Sentry 프로젝트를 식별하는 고유한 문자열입니다. 이 값을 설정함으로써 에러와 이벤트가 보고될 정확한 Sentry 프로젝트를 지정할 수 있습니다. [Projects - Settings - Client Keys] Environment: 애플리케이션의 실행 환경(예: production, staging, development)을 지정합니다. 이 정보는 에러 필터링과 분석 시 중요한 차원으로 사용됩니다. 각 실행 환경 별로 필터링하여 알림 설정을 하거나, 모니터링 가능 Issue Filtering Release: 애플리케이션의 릴리즈 버전을 지정합니다. 이 값을 통해 에러가 발생한 애플리케이션의 구체적인 버전을 추적하고, 릴리즈 간 에러 비율을 비교할 수 있습니다. SampleRate: 0에서 1 사이의 값을 설정하여, 보고될 이벤트의 샘플링 비율을 결정합니다. 예를 들어, 0.1로 설정하면 10%의 이벤트만이 실제로 보고됩니다. 이는 대량의 트래픽이 발생하는 애플리케이션에서 유용하게 사용될 수 있습니다. API 트래픽 량이 많을 수록 0에 가깝게 지정 네트워크 트래픽 감소 / 성능 최적화 / 비용 절감을 위해 적절히 지정 TracesSampleRate: 성능 모니터링에 사용되며, SampleRate와 비슷하게 트랜잭션 데이터의 샘플링 비율을 결정합니다. 이를 통해 성능 데이터의 양을 조절할 수 있습니다. BeforeSend: 보고되기 전에 이벤트를 수정하거나 필터링할 수 있는 콜백 함수를 설정합니다. 예를 들어, 특정 조건을 만족하는 이벤트만을 보고하거나, 민감한 정보를 제거하는 데 사용될 수 있습니다. AttachStacktrace: 자동으로 스택 트레이스를 이벤트에 첨부할지 여부를 결정합니다. 이 옵션을 활성화하면 에러가 아닌 로그 메시지에도 스택 트레이스 정보가 포함됩니다. ServerName: 이벤트가 보고될 때 서버 이름을 명시적으로 설정할 수 있습니다. 이 정보는 에러 분석 시 서버 구분에 도움을 줄 수 있습니다. Integrations: Sentry와 함께 사용할 추가적인 통합 기능들을 설정합니다. Sentry는 다양한 플랫폼과 프레임워크에 대한 통합을 제공하여, 보다 쉽게 에러 추적 및 성능 모니터링을 구현할 수 있도록 돕습니다. Transport는 Sentry 서버로 이벤트를 전송하는 메커니즘을 정의합니다. 이 옵션을 사용하여 개발자는 기본 HTTP 전송 방식 대신 커스텀 전송 방식을 구현할 수 있습니다 timeout 값은 네트워크 지연이나 서버 응답 시간의 변동성을 고려하여 설정되어야 합니다 Initialize Go-Sentry SDK 사용 시, 최초 초기화 당시에 HTTP Client의 TCP 커넥션을 자동으로 처리 합니다.\nApplicaiton 의 main.go 에서 최초로 Init() 설정하는 것이 Best Practice로 소개됩니다.\nerr := sentry.Init( sentry.ClientOptions{ Dsn: si.conf.Sentry.DSN, SampleRate: si.conf.Sentry.SampleRate, EnableTracing: si.conf.Sentry.EnableTrace, Debug: si.conf.Sentry.Debug, TracesSampleRate: si.conf.Sentry.TracesSampleRate, Environment: si.conf.Sentry.Environment, AttachStacktrace: true, Transport: \u0026amp;sentry.HTTPSyncTransport{ Timeout: si.conf.Sentry.Timeout, }, }, ) Capture Exception 발생한 예외(에러)와 관련된 스택 트레이스를 자동으로 캡처하고 추적합니다.\n// 현재 컨텍스트와 연관된 Hub 생성 또는 가져오기 hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } // 에러 캡처 hub.CaptureException(err) Go Error 사용에 따른 스택 트레이스 차이점 정확한 에러의 발생처를 알기 위해서는 pkg/errors 라이브러리를 사용하자!\nerrors 패키지: 기본적으로 스택 트레이스 정보를 제공하지 않습니다. 에러는 단순히 메시지를 포함하는 값이며, 디버깅을 위한 추가적인 컨텍스트나 위치 정보는 포함되어 있지 않습니다.\ngithub.com/pkg/errors 패키지: 에러에 자동으로 스택 트레이스를 포함합니다. 이를 통해 에러가 어디서 발생했는지, 에러의 원인을 추적하는 데 필요한 상세한 호출 스택 정보를 얻을 수 있습니다.\ntest. errors 패키지와 pkg/errors 에 따른 스택 트레이스\npackage main import ( \u0026#34;context\u0026#34; stdErr \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; sentry \u0026#34;github.com/getsentry/sentry-go\u0026#34; pkgErr \u0026#34;github.com/pkg/errors\u0026#34; ) var ( PkgErr1 = pkgErr.New(\u0026#34;pkg error 1\u0026#34;) PkgErr2 = pkgErr.New(\u0026#34;pkg error 2\u0026#34;) StdErr1 = stdErr.New(\u0026#34;standard error1\u0026#34;) StdErr2 = stdErr.New(\u0026#34;standard error2\u0026#34;) ) func main() { err := sentry.Init( sentry.ClientOptions{ Dsn: \u0026#34;\u0026#34;, Debug: true, AttachStacktrace: true, }, ) if err != nil { // sentry 초기화 실패 시, panic 시스템 os exit panic(err) } ctx := context.Background() hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } err = errPkgNested() go hub.CaptureException(err) fmt.Println(\u0026#34;Standard error nested\u0026#34;) time.Sleep(5 * time.Second) } func errStdNested() error { return stdErr.Join(PkgErr1, PkgErr2) } func errPkgNested() error { return pkgErr.Wrap(PkgErr1, PkgErr2.Error()) } Scope() Sentry에서 Scope는 특정 에러 또는 이벤트에 추가적인 컨텍스트 정보를 제공하는 메커니즘입니다. 에러의 재현을 위해서 요청 파라미터 등을 Scope에 저장하여 애플리케이션의 고도화가 가능합니다.\nSentry 클라이언트를 통해 생성되는 허브는 Context 단위로 싱글턴 패턴을 유지하며, go context.Context 와 함께 메타데이터를 저장하여, 추적에 용이하도록 돕습니다.\nfunc (rm *sentryScopeMiddleware) Register(originalHandler http.Handler) http.Handler { if !rm.initializer.Enabled() { // sentry가 비활성화 되어 있는 경우, 센트리 활성화 rm.initializer.Init() } return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { hub := sentry.GetHubFromContext(r.Context()) if hub == nil { hub = sentry.CurrentHub().Clone() r = r.WithContext(sentry.SetHubOnContext(r.Context(), hub)) } hub.Scope().SetRequest(r) }) } Sentry Advancement SentryInitializer 하나의 애플리케이션에서 싱글턴을 유지하기 위해 설정을 통한 초기화 여부를 확인하는 클래스\npackage core import ( \u0026#34;sync\u0026#34; \u0026#34;github.com/getsentry/sentry-go\u0026#34; ) type ( // SentryInitializer : Sentry 설정 초기화를 담당하는 구현체 SentryInitializer struct { conf *Config enabled bool mutex sync.RWMutex // enabled 필드에 대한 읽기/쓰기 동기화를 위한 RWMutex } ) // NewSentryInitializer : SentryInitializer 생성자 func NewSentryInitializer(conf *Config) SentryInitializer { return SentryInitializer{ conf: conf, } } // Init : SentryInitializer 초기화 // // - sentry 패키지 변수를 통해 싱글턴 처리하므로 최초 설정만 요구됨 func (si *SentryInitializer) Init() error { si.mutex.Lock() // enabled lock for writing defer si.mutex.Unlock() err := sentry.Init( sentry.ClientOptions{ Dsn: si.conf.Sentry.DSN, SampleRate: si.conf.Sentry.SampleRate, EnableTracing: si.conf.Sentry.EnableTrace, Debug: si.conf.Sentry.Debug, TracesSampleRate: si.conf.Sentry.TracesSampleRate, Environment: si.conf.Sentry.Environment, AttachStacktrace: true, Transport: \u0026amp;sentry.HTTPSyncTransport{ Timeout: si.conf.Sentry.Timeout, }, }, ) if err != nil { // sentry 초기화 실패 시, panic 시스템 os exit panic(err) } // 활성화 상태로 변경 si.enabled = true return nil } // Enabled : Sentry 활성화 여부 // // - Init()이 호출된 경우, 활성화 상태로 변경 func (si *SentryInitializer) Enabled() bool { si.mutex.RLock() // read lock defer si.mutex.RUnlock() return si.enabled } 동시성 문제로 **Enabled()**의 동기화를 위해 락으로 관리\nErrorCapturer SentryInitializer를 임베딩하여, 센트리를 통한 센트리 허브에서 에러를 캡쳐링하는 클래스 package core import ( \u0026#34;context\u0026#34; \u0026#34;github.com/getsentry/sentry-go\u0026#34; ) type ( // ErrorCapturer : 에러 캡처 인터페이스 ErrorCapturer interface { CaptureError(ctx context.Context, err error) } sentryErrorCapturer struct { SentryInitializer } ) // NewSentryErrorCapturer : SentryErrorCapturer 생성자 func NewSentryErrorCapturer(initializer SentryInitializer) ErrorCapturer { return \u0026amp;sentryErrorCapturer{ initializer: initializer, } } // CaptureError : Sentry로 에러 캡처 func (sec *sentryErrorCapturer) CaptureError(ctx context.Context, err error) { // 에러가 없는 경우, 무시 if err == nil { return } if !sec.SentryInitializer.Enabled() { // sentry 초기화를 통해 활성화 sec.SentryInitializer.Init() } // 현재 컨텍스트와 연관된 Hub 생성 또는 가져오기 hub := sentry.GetHubFromContext(ctx) if hub == nil { hub = sentry.CurrentHub().Clone() // 현재 컨텍스트에 Sentry Hub을 설정 ctx = sentry.SetHubOnContext(ctx, hub) } // 에러 캡처 hub.CaptureException(err) } RecoverMiddleware 핸들러에서 Panic 발생 시, Recover(), 요청을 허브의 메타데이터로 저장하는 클래스 // Register panic() 발생 시 스택 스레이스를 로깅하며 센트리를 통해 남기는 메서드 // // - http handler에 내부적으로 등록 // - API 고루틴 내부적으로 defer()를 통하여 panic 상황에서도 로깅이 가능하도록 한다 // // Parameters: // - originalHandler: 원래의 http handler func (rm *sentryRecoverMiddleware) Register(originalHandler http.Handler) http.Handler { if !rm.initializer.Enabled() { // sentry가 비활성화 되어 있는 경우, 센트리 활성화 rm.initializer.Init() } return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { hub := sentry.GetHubFromContext(r.Context()) if hub == nil { hub = sentry.CurrentHub().Clone() r = r.WithContext(sentry.SetHubOnContext(r.Context(), hub)) } hub.Scope().SetRequest(r) defer func() { if err := recover(); err != nil { hub.RecoverWithContext(r.Context(), err) stackList := strings.Split(string(debug.Stack()), \u0026#34;\\n\u0026#34;) rm.Logger.Error(). Any(\u0026#34;error\u0026#34;, err). Any(\u0026#34;stack_list\u0026#34;, stackList).Send() resp := dto.ACSErrorResponse{ Code: http.StatusInternalServerError, ErrMessage: \u0026#34;서버에서 예기치 못한 에러가 발생하였습니다\u0026#34;, Success: false, } jsonResp := resp.ToJSON() w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) w.WriteHeader(http.StatusInternalServerError) _, err = w.Write(jsonResp) if err != nil { rm.Logger.Error(). Any(\u0026#34;error\u0026#34;, err).Send() } return } }() originalHandler.ServeHTTP(w, r) }) } 비용적인 문제가 있지만 APM과 Error Capture측면에서는 관리적인 편의성을 제공해주는 Sentry!\n","permalink":"https://dings-things.github.io/blog/posts/sentry/","summary":"APM과 에러 스테이스가 가능한 툴이 있다?","title":"[Third-Party] Sentry 연동"},{"content":"배경 k8s 환경 Deploy 후, 부하테스트 과정에서 간헐적으로 502 / 504 에러 발생 확인 Pod들이 교체 되면서 기존 요청에 대한 응답을 반환하지 못한 채 종료 됨 → 504 Gateway Timeout 신규 Pod이 올라가고 대체되는 Pod이 Terminate 됨 → 502 Bad Gateway 롤링업데이트가 진행되지만 Readiness Probe 설정 없이는 순단이 발생할 여지가 있음을 확인\n설정 부하테스트 툴 설치 bombardier : 쉽고 간편한 go cli 부하테스트 툴 vegeta : 스크립트 작성으로 보다 유연한 요청 가능, status code 를 상세히 응답하는 툴\n각 툴의 자세한 설치 과정은 생략 합니다.\nReadniess Probe Pod이 서비스 트래픽을 처리할 준비가 되었는지를 판단하는 데 사용되는 메커니즘\n특정 컨테이너가 시작된 후에도 일부 작업이 완료될 때까지 외부 트래픽을 처리할 준비가 되지 않았을 수 있기 때문에 이를 확인하는 역할을 함\n트래픽 라우팅 제어: Readiness Probe가 성공적으로 완료될 때까지 Kubernetes는 해당 Pod으로 트래픽을 라우팅하지 않습니다. 이는 Pod이 준비되지 않은 상태에서 요청을 처리하지 않도록 보장합니다. 준비가 완료된 후에만 트래픽이 Pod으로 라우팅되기 때문에, Pod이 올바르게 설정되고 필요한 리소스를 확보한 상태에서만 요청을 처리하게 됩니다. Pod의 상태 확인: Readiness Probe는 특정 조건이 충족될 때까지 Kubernetes에 Pod이 트래픽을 받을 준비가 되지 않았다고 알리며, 준비가 완료된 후에는 트래픽을 받을 준비가 되었음을 알립니다. Pod이 준비되지 않은 경우, Kubernetes는 Pod을 서비스의 엔드포인트에서 제거합니다. 502가 발생하는 원인 중 하나이다\nReadiness Probe를 지정하지 않은 경우, 컨테이너가 올라가는 시점에서 트래픽이 들어오게 된다.\n이때에, Pod 내부의 서버 초기화가 완전히 되지 않은 시점에서 요청이 온 경우 → 502 Bad Gateway를 응답한다\ndeployment.yml 수정 사항 ... readinessProbe: httpGet: port: 8080 path: /alive scheme: HTTP initialDelaySeconds: 30 periodSeconds: 30 ... Healthcheck 응답용 Endpoint를 생성해두고 응답 상태코드가 200으로 돌아오면 요청을 받는 형식으로 설정\n테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4205.76 1250.10 16927.12 Latency 47.81ms 10.16ms 2.07s Latency Distribution 50% 45.08ms 75% 49.77ms 90% 57.60ms 95% 64.29ms 99% 81.95ms HTTP codes: 1xx - 0, 2xx - 0, 3xx - 0, 4xx - 753060, 5xx - 12 others - 0 Throughput: 3.24MB/s 여전히 5XX 에러는 존재한다.\nlifecycle \u0026amp; preStop lifecycle 설정이란? 컨테이너의 생명주기 동안 특정 시점에 실행될 작업을 정의할 수 있는 Kubernetes의 구성 옵션 (AOP와 유사\u0026hellip;하다는 생각)\npostStart: 컨테이너가 시작된 직후에 실행됩니다. 컨테이너가 시작된 후 추가적인 초기화 작업을 수행하는 데 사용 preStop: 컨테이너가 종료되기 직전에 실행됩니다. 종료 전에 필요한 작업을 수행하도록 설정 가능 preStop preStop 훅은 컨테이너가 종료될 때 실행되는 스크립트나 명령어를 지정. 이 훅은 컨테이너가 종료되기 전에 반드시 수행해야 하는 작업이 있을 때 매우 유용\n트래픽 분리: Pod이 종료되기 전에 해당 Pod을 서비스 트래픽에서 안전하게 분리하기 위해 사용됩니다. 정리 작업: 종료 전에 리소스 정리, 연결 종료, 파일 저장 등의 작업을 수행할 수 있습니다. 대기 시간 설정: 컨테이너가 실제로 종료되기 전에 일정 시간 동안 대기하도록 설정하여, 클라이언트와의 연결이 완전히 종료되도록 할 수 있습니다. 앞서 설정한 Readiness Probe 설정 이후에도, lifecycle 설정을 하지 않는다면 간헐적인 502 에러가 발생될 수 있다\n파드는 종료될 때 SIGTERM, SIGKILL 처리와 서비스 제외 처리가 비동기로 처리됨\n서비스가 분리되기 전에 Pod이 클라이언트 요청에 정상적으로 응답할 수 없을 수 있다.\n즉, 서비스 분리 → 잔류하는 요청 처리 → pod 종료 를 통해 Graceful Shutdown이 가능하도록 설정한다\ndeployment.yml 수정 사항 ... lifecycle: preStop: exec: command: - /bin/sh - -c - sleep 40 # 서비스 분리가 발생한 후 40초 동안 대기 ... 컨테이너 종료 요청: Kubernetes가 Pod을 종료하기로 결정하면, 컨테이너에 SIGTERM 신호 preStop 훅 실행: SIGTERM 신호가 전송된 후, sleep 40 실행, 컨테이너가 40초 동안 대기 유예 기간 시작 (terminationGracePeriodSeconds): preStop 훅이 실행되면서, 동시에 terminationGracePeriodSeconds에 정의된 유예 기간이 시작 이 기간 동안 Kubernetes는 컨테이너가 정상적으로 종료되기를 대기 컨테이너 종료: preStop 훅이 완료되고, 유예 기간이 끝나면 Kubernetes는 컨테이너를 종료 테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4205.05 1355.65 20756.97 Latency 47.92ms 8.71ms 2.07s Latency Distribution 50% 45.47ms 75% 49.26ms 90% 57.32ms 95% 64.39ms 99% 80.67ms HTTP codes: 1xx - 0, 2xx - 751239, 3xx - 0, 4xx - 0, 5xx - 3 others - 0 Throughput: 2.82MB/s 여전히 5XX 에러는 존재한다.\nterminationGracePeriodSeconds Pod 종료 시나리오:\nKubernetes가 Pod을 종료하기로 결정하면, 먼저 Pod 내의 컨테이너에 SIGTERM 신호를 보냄 SIGTERM 신호를 받은 애플리케이션은 현재 처리 중인 요청을 완료하고, 필요한 정리 작업을 수행 가능 유예 기간 설정:\nterminationGracePeriodSeconds는 이 유예 기간을 정의. 이 기간 동안 Kubernetes는 컨테이너가 정상적으로 종료될 시간을 대기 기본값은 30초입니다. 이 시간이 지나면 Kubernetes는 컨테이너가 여전히 실행 중인 경우 강제로 종료(SIGKILL) SIGKILL 신호:\nterminationGracePeriodSeconds 기간이 만료되었을 때도 컨테이너가 종료되지 않았다면, Kubernetes는 SIGKILL 신호를 줌, 애플리케이션이 강제 종료됨 일정 lifecycle.preStop 설정을 통해, 40초의 유예시간을 두어 애플리케이션에 잔류하는 요청을 응답할 시간을 주었음.\n하지만 terminationGracePeriodSeconds 는 기본 30초로 설정되기에 30초가 지나도록 Pod이 실행중인 경우 SIGKILL을 전송하여 파드를 강제 종료시킴\ndeployment.yml 수정 사항 ... terminationGracePeriodSeconds: 50 ... INGRESS와 연결된 ALB 속성을 꼭 확인하자! terminationGracePeriodSeconds가 ALB 타임아웃보다 긴 경우, 특정 시나리오에서 504 Gateway Timeout 오류가 발생할 수 있음\n예상 발생 시나리오 : 요청 중간에 종료 발생 → ALB 타임아웃 도달 → 응답 전 Pod 종료\n이를 예방하기 위해, lifecycle.preStop (40s) \u0026lt; terminationGracePeriodSeconds (50s) \u0026lt; ALB Timeout (60s) 로 지정\n테스트 bombardier -c 200 -d 3m -l https://{endpoint} [================================================================================================================] 3m0s Done! Statistics Avg Stdev Max Reqs/sec 4293.51 1286.80 12924.64 Latency 46.74ms 8.94ms 547.25ms Latency Distribution 50% 44.48ms 75% 46.87ms 90% 54.16ms 95% 66.82ms 99% 81.69ms HTTP codes: 1xx - 0, 2xx - 770240, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 2.89MB/s REF 카카오 테크 k8s 무중단 배포 Pod 라이프사이클 ","permalink":"https://dings-things.github.io/blog/posts/k8s-zero-downtime/","summary":"간헐적으로 발생하는 502와 504.. 왜 발생하고 어떻게 예방할까","title":"[Infra] 쿠버네틱스 무중단 배포 설정하기"},{"content":"목적 일반적인 Transaction이 필요한 RDB의 경우, 자체적으로 격리 수준을 설정하거나 Rollback과 Commit을 통해 트랜잭션을 구현한다.\n하지만 Redis는 어떠한가? Redis에서 데이터의 일관성과 원자성을 보장받기 위해 주어진 옵션은 그렇게 명확하지 않다.\n하나의 Transaction을 격리 시켜야 하며, All or Nothing 원자성을 Redis에서 지켜야 할 때에 도움이 되고자 기록합니다.\n선택지 Redis TxPipeline Lua Script Redis TxPipeline Redis에서 여러 Command를 일괄적으로 처리하기 위해 떠올리게 되는 것은 Pipeline일 것이다\nPipeline은 연결된 Redis Client로 여러 개의 커맨드를 한번에 보내고 여러개의 응답을 한번에 받는 것을 가능하도록 한다\n다만 일반적인 파이프라인이 트랜잭션이 보장된다고 할 수 없다. 즉, 파이프라인 실행 도중 해당 데이터에 대하여 다른 커맨드로 인해 변경될 수 있으며 데이터의 일관성에 문제가 발생할 수 있다\nEdge Case 네트워크 지연: Redis Pipeline을 사용하면 여러 개의 커맨드를 한 번에 보내고, 한 번에 여러 개의 응답을 받는 것이 가능합니다. 그러나 네트워크 지연으로 인해 커맨드가 서버에 도착하는 순서와 응답이 도착하는 순서가 일치하지 않을 수 있습니다. 따라서 응답이 먼저 도착하는 경우에도, 실제로는 나중에 실행한 커맨드의 결과일 수 있습니다. 다중 스레드 환경: Redis 서버는 다중 스레드로 동작하며, 여러 클라이언트가 동시에 요청을 보낼 수 있습니다. 따라서 여러 클라이언트가 동시에 Pipeline을 사용할 경우, 커맨드의 실행 순서가 보장되지 않을 수 있습니다. Redis 서버 설정: Redis 서버의 설정에 따라 일관성이 달라질 수 있습니다. 예를 들어, Redis 서버가 \u0026ldquo;slaveof\u0026rdquo; 설정을 사용하여 데이터를 레플리케이션하는 경우, 일관성이 보장되지 않을 수 있습니다. 이를 해결하는 것이 TxPipeline이다\nPros 트랜잭션 보장: TxPipeline을 사용하면 일괄 처리된 커맨드는 하나의 트랜잭션으로 간주되어, 실행 중 다른 커맨드가 중간에 끼어들지 않습니다. 이로써 데이터의 일관성을 보장합니다. 성능 향상: 여러 개의 커맨드를 한 번에 보내므로 네트워크 오버헤드를 줄일 수 있어 성능이 향상될 수 있습니다. 원자성 보장: TxPipeline 내에서 실행되는 모든 커맨드는 성공하거나 실패되며, 롤백은 지원하지 않습니다. Cons 메모리 사용: 모든 커맨드와 결과가 메모리에 저장되므로, 큰 트랜잭션을 처리할 때 메모리 사용량이 증가할 수 있습니다. 복잡성: TxPipeline은 다른 파이프라인과 혼합해서 사용할 때 주의가 필요하며, 트랜잭션의 범위를 신중하게 관리해야 합니다. 테스트 WATCH를 통해 특정 키의 변경을 감시하고, 이를 통해 트랜잭션의 일관성을 보장할 수 있습니다. 만약 WATCH 중에 감시된 키가 다른 클라이언트에 의해 변경되면, 해당 트랜잭션은 실패\nex. TxPipeline 도중 에러 발생 시나리오\nMULTI SET key1 value1 SET key2 value2 SET key3 value3 EXEC 시나리오 : SET key2 value2 커맨드가 실패\nCASE 1 : 메모리 부족 \u0026#34;OOM command not allowed when used memory \u0026gt; \u0026#39;maxmemory\u0026#39;\u0026#34; CASE 2 : 잘못된 데이터 형식 \u0026#34;WRONGTYPE Operation against a key holding the wrong kind of value\u0026#34; 일반적으로 일어날 수 있는 경우가 드무며, 가장 예상 가능한 시나리오는 Redis Client Connection이 끊어진 케이스가 될것이다. 만약 Client Connection이 끊어진 경우, 실패한 키에 대하여 롤백을 수동으로 진행한다 하여도 롤백 자체가 수행되지 않기 때문에 완벽한 해답은 되지 않는다\n즉, TxPipeline은 일관성은 보장 되지만 완벽한 원자성은 보장되지 않는다\nLua Script Lua 스크립트 내에서 여러 Redis 커맨드를 실행하고, 이를 원자적으로 실행할 수 있다\nEdge Case 스크립트 전송 중 네트워크 지연이나 중단: 클라이언트가 Lua 스크립트를 Redis 서버로 전송하는 과정에서 네트워크 지연이나 중단이 발생하면, 스크립트는 서버에 제대로 도달하지 못하고 실행되지 않을 수 있습니다. 실행 결과 수신 중 네트워크 문제: 스크립트가 성공적으로 실행된 후, 그 결과를 클라이언트가 수신하는 과정에서 네트워크 지연이나 중단이 발생할 수 있습니다. 이 경우, 스크립트는 Redis 서버에서 정상적으로 실행되었지만, 클라이언트는 실행 결과를 받지 못할 수 있습니다. Pros: 경량 및 빠른 실행: Lua는 경량 스크립팅 언어로, 실행 시스템 자원을 적게 소모하며 빠르게 실행됩니다. 이러한 특징은 임베디드 시스템이나 게임 엔진 등 리소스가 제한된 환경에서 유용합니다. 내장 스크립트 언어: Lua는 많은 애플리케이션과 게임 엔진에서 내장 스크립트 언어로 사용됩니다. 이는 애플리케이션의 확장성을 높이고 사용자 정의 스크립트를 통해 기능을 확장하기에 용이합니다. 흔히 이전에 Statement로 관리 되던 DB 명령 방식 ORM이 등장한 배경을 생각해보았을 때, 커맨드(query)를 코드로 관리할 수 없기 때문에 Lua를 사용함에 회의적인 개인적 생각 가독성과 간결성: Lua는 간결하고 가독성이 높은 문법을 가지고 있어 쉽게 이해하고 작성할 수 있습니다. lua Script를 위해 문법을 수정해야 하기 때문에 러닝 커브가 동반될 수 있음 Cons: 작은 생태계: 다른 언어에 비해 Lua의 생태계는 상대적으로 작습니다. 따라서 다양한 라이브러리 및 모듈을 찾기 어려울 수 있습니다. 제한된 자료형: Lua는 몇 가지 기본 자료형만을 지원하며, 정수와 부동 소수점 수의 구분이 없어서 정확한 숫자 처리가 어려울 수 있습니다. 엄격한 문법: Lua는 문법 검사가 엄격하며, 초보자에게는 초기 학습 곡선이 높을 수 있습니다. 쓰레드 처리 어려움: Lua는 기본적으로 싱글 스레드 환경에서 동작하며, 멀티 스레드 처리가 어려울 수 있습니다. 테스트 결국 Lua 또한 트랜잭션에 대한 롤백은 지원하지 않습니다.\n기본적으로 삽입 요청 시, Validation을 체크하는 것을 고려할 때에 일어날 수 있는 최악의 시나리오는 네트워크의 단절이며 해당 방법은 어떠한 방법으로도 복구 될 수 없습니다.\nRedis Pipeline에 저장된 커맨드가 원자적으로 한번에 실행 될 수 없기 때문입니다\n테스트 시나리오\nkey1 ~ key5 까지 세팅하는 도중 에러 발생 시, 롤백 테스트\n실행 코드 (go)\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; ) var ctx = context.Background() func main() { rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, // Redis 서버 주소 }) luaScript := ` for i = 1, #KEYS do if KEYS[i] == \u0026#39;key3\u0026#39; then error(\u0026#39;key3 설정 시 에러 발생\u0026#39;) else redis.call(\u0026#39;SET\u0026#39;, KEYS[i], ARGV[i]) end end ` keys := []string{\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;key3\u0026#34;, \u0026#34;key4\u0026#34;, \u0026#34;key5\u0026#34;} values := []interface{}{\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;value3\u0026#34;, \u0026#34;value4\u0026#34;, \u0026#34;value5\u0026#34;} err := rdb.Eval(ctx, luaScript, keys, values...).Err() if err != nil { fmt.Printf(\u0026#34;Lua 스크립트 실행 중 오류 발생: %v\\n\u0026#34;, err) return } fmt.Println(\u0026#34;Lua 스크립트 실행 완료\u0026#34;) } [결과] 종합 Pros \u0026amp; Cons TxPipeline Lua Script 특징 - Redis Pipeline과 동일한 코드로 수행 가능 - 데이터 무결성 보장 - 낙관적 락 (Watch 중인 키에 변경이 일어나면 트랜잭션 실패) - Lua 언어를 통해 스크립트를 작성해야 함 - 데이터 무결성 보장 - 스크립트 전체가 하나의 단위로 실행 트랜잭션 롤백 여부 불가능 불가능 단점 - Lua에 비해 성능이 안 좋음 (Pipeline과는 비슷) - 스크립트를 관리하는 것 또한 리소스가 소모됨 - 러닝 커브 두 가지 선택지 모두, 트랜잭션 실패 시 롤백을 제공하지 않지만 데이터의 무결성은 보장됨. Value 삽입 전에 유효성 검증을 하기 때문에 데이터 삽입으로 인한 에러 발생 가능성은 적음. 최악의 경우: Redis Connection이 끊어진 경우, Redis 트랜잭션 실패 시 삭제하여 롤백을 구현해야 함. 그러나 커넥션이 끊어진 상태라면 삭제 요청 또한 실패할 가능성이 높음. Redis Sentinel을 사용할 경우, 가용성에 대한 엣지 케이스를 고려해야 하는가? 벤치마크 Redis에 1,000개 Key 세팅 기준\n항목 테스트 횟수 평균 실행 시간 (ms) Lua 스크립트 1424 0.83 TxPipeline 460 2.56 Pipeline 506 2.34 성능차이가 크리티컬 하지 않으며, 무결성은 보장되는 것이 좋기 때문에 TxPipeline 또는 Lua 스크립트를 사용하는 것 권장 ","permalink":"https://dings-things.github.io/blog/posts/redis-transaction/","summary":"Redis는 락이 없는데 어떻게 트랜잭션을 보장하죠?","title":"[DB] Redis Transaction"},{"content":"FastAPI Convention에 관하여 FastAPI란? FastAPI의 장점 의존성 주입 자동 문서화 비동기 동작 Pydantic Model 클라우드 서비스가 들어오면서 자연스럽게 MSA 라는 아키텍처 구조가 각광 받았고, 그로 인해 서버의 생태계에 변동이 일어나고 있다. 이제는 Serverless (무상태성)을 띈 Restful API 를 통하여 가벼운 통신 방식을 사용하는 아키텍처가 대세를 이루게 되었는데 이렇게 작게 나뉘어진 서비스에 특화된 것이 FastAPI 이다.\n의존성 (A는 반드시 B가 실행되어야 되는 흐름? A \u0026amp; B 는 의존관계 ) 주입에 핵심적인 Depends 함수로 인하여 인증/ DB 연결 등에서 결합도를 낮추어 유연성을 확보할 수 있게 된다 자동 문서화 문서화는 개발자에게 있어 하기 싫은 방학 숙제와 같다. 다른 프레임워크들과 달리 dependency 를 추가 하지 않아도 리독과 openAPI 자동으로 생성된다. 개발자에게 생산성 증대의 이점을 가져온다. 비동기 동작 Node 처럼 비동기가 기본이 아닌 파이썬은 동기로 동작하지만 GIL(Global Interpreter Lock)으로 인해 쓰레드의 사용도 권장되지 않았기 때문에 동시성 처리를 위한 모듈이 없는 경우가 많다. 하지만 중요한것은 FastAPI 는 이를 지원한다는 점 Pydantic FastAPI 는 Pydantic 을 매우 사랑한다. 간단하게 직렬화, 타입검사 경로 변수 읽기 등등 장점이 수두룩 한데 이는 나중에 더 자세히 다루겠다. 특징 가장 큰 것이 사실상의 표준(de facto standard) 가 없다는 것이다. 여타 프레임워크들과 다르게 역사도 길지 않고 FastAPI의 모토가 자유롭고 경량의 프레임워크를 지향하기에 어쩔수 없게도 코딩 스탠다드가 존재하지 않는다. 좋게 말하면 자유도 높인 프레임워크이지만 어떻게 보면 근본이 없다 보일 수 있을 것이다.\n목적 기존 클래스화 되지 않고 정해진 구조없이 짜여진 코드로 인하여 협업하는 데에 있어 각자의 코딩 색이 너무 진하여 같은 팀이지만 구조화 되지 않은 프로젝트라고 느껴졌다.\n이에 우리만의 Convention을 지정하여 직관적이고 유지보수에 용이한 구조를 만드는 것을 목표로 한다.\nClass Based Convention 현재 문제점 Utility에 의존한 잡다한 Feature methods 너무 많은 책임을 짊어진 클래스 (낮은 응집도) 직관적이지 않은 구조 하나의 비즈니스 레이어가 분산되어 있어 코드 가독성이 떨어짐 Dataclass, Pydantic Model 등 모델에 사용되는 Convention이 지정되어 있지 않음 요구 사항 프로젝트 구조는 일관적, 직관적 클래스는 단 한개의 책임을 가진다 비즈니스 레이어 별로 패키지를 구성한다 요구 사항에 따른 Convention 1. 프로젝트 구조는 일관적, 직관적 [FastAPI에서 제시하는 project structure]\n. ├── app # \u0026#34;app\u0026#34; is a Python package │ ├── __init__.py # this file makes \u0026#34;app\u0026#34; a │ ├── main.py # \u0026#34;main\u0026#34; module, e.g. import app.main │ ├── dependencies.py # \u0026#34;dependencies\u0026#34; module │ └── routers # \u0026#34;routers\u0026#34; is a \u0026#34;Python subpackage\u0026#34; │ │ ├── __init__.py # makes \u0026#34;routers\u0026#34; a \u0026#34;Python subpackage\u0026#34; │ │ ├── items.py # \u0026#34;items\u0026#34; submodule │ │ └── users.py # \u0026#34;users\u0026#34; submodule │ └── internal # \u0026#34;internal\u0026#34; is a \u0026#34;Python subpackage\u0026#34; │ ├── __init__.py # makes \u0026#34;internal\u0026#34; a \u0026#34;Python subpackage\u0026#34; │ └── admin.py # \u0026#34;admin\u0026#34; submodule [제안 하고자 하는 project structure]\nfastapi-project ├── app │ ├── worker (비즈니스 레이어) │ │ ├── enums.py # enums │ │ ├── models.py # pydantic models │ │ ├── dependencies.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ └── utils.py │ ├── configs │ │ ├── config.py # global config (including .env) │ │ └── log_config.py │ ├── models.py # global models │ ├── utils.py # global utils │ ├── exceptions.py # global exceptions │ ├── database.py # db connection related stuff │ └── main.py ├── aws │ ├── client.py # client model for external service │ ├── models.p │ ├── constants.py │ ├── exceptions.py │ └── utils.py ├── tests/ │ ├── domain │ └── aws ├── templates/ │ └── index.html ├── requirements │ ├── dev.txt │ ├── stg.txt │ └── prod.txt ├── .env └── .gitignore 모든 도메인 디렉토리의 root는 app이다\nmain.py에서는 그대로 FastAPI app을 초기화하고 프로젝트의 root 역할을 한다 (보편적으로 src/ 느낌) controller : 각 모듈의 엔드포인트를 가진다 enums : Enum 모델들 models : pydantic 모델들 entities : 엔티티 모델들 service : 모듈 별 비즈니스 로직 담당 dependencies : 유효성 검사 constant : 모듈 내에서 사용되는 상수값 config : 모듈 내의 설정사항 exceptions: 커스텀 예외들! 같은 관심을 갖는 메서드가 두개 이상일 경우 따로 패키지로 분류한다\n외부 패키지의 경우 app에 종속적이지 않기 때문에 app 외부에서 관리한다.\n2. 클래스는 단 한개의 책임을 가진다 저자는 응집도를 잘못 이해하고 있었다. 여러개의 연관된 관심을 가진 메서드들을 묶어 하나의 클래스로 만들고 이게 높은 응집도지 ㅋㅋ 하는 어리석음을 반복하고 있었다.\n객체지향 설계원칙인 SOLID중 이는 SRP (Single Responsibility) 단일 책임 원칙에 해당된다.\n흔히 말하는 GOD 클래스들은 다음과 같다. XXXService, XXXClient, XXXHandler, XXXWorker\n필자 또한 그러하였고 서비스안에 조금이라도 관심이 같다고 판단하면 무수히 많은 피쳐들을 남발하여 추가하였다. 이는 코드 가독성과 유지보수의 이점을 버리는 지름길이라 생각한다.\n가령 아래와 같은 피쳐를 만들어야 한다.\nex. 회원 로그를 txt 파일로 작성하는 피쳐를 만드시오\n[Service]\nclass UserService: def write_log_file(self, user_id:str) -\u0026gt; None [단일책임]\nclass UserLogWriter: def __init__(self, user:User) self.user = user def write(self) -\u0026gt; None 하나의 예시에 불과하지만 서비스들로 구성한 피쳐들이 쌓이면 가독성적이나 특히 유닛테스트에서 큰 골치를 겪을 것이다.\n또한 분산된 메서드들을 조합하는 방식에서 최대한 Pythonic하고 OOP를 따르기 위해 FastAPI의 라우터 또한 손을 보게 되었다.\n굳이 싶긴 하겠지만 시간이 된다면 클래스화하여 컨테이너로 관리하고 싶었고 상속을 통해 보일러플레이트 코드를 최소화하고자 모두 클래스로!! 바꾸게 되었다\nex. [BaseController] [HelloController] 3. 비즈니스 레이어 별로 패키지를 구성한다 간단히 말하자면 User를 도메인으로 가지면서 이에 대한 간단한 CRUD를 가진 애플리케이션을 구성한다고 하였을 경우. 아래와 같이 구성할 수 있다.\nfastapi-project ├── app │ ├── user_manager (비즈니스 레이어) │ │ ├── user_getter.py │ │ ├── user_updater.py │ │ ├── user_creator.py │ │ ├── enums.py # enums │ │ ├── models.py # pydantic models │ │ ├── entities.py # pydantic models │ │ ├── user_database.py │ │ ├── dependencies.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ └── utils.py 가령 DB로 부터 User 엔티티를 얻고자 한다면 UserGetter.get() 과 같이 직관적이게 해당 메서드가 무엇을 리턴하는지 유추할 수 있다.\nFacade Pattern을 적용하여 이들을 조합하는 하나의 Manager 레벨이 증가한다고 하더라도 이는 동일하게 적용 될 수 있다.\nmodels의 클래스 이름이 같을 수 있지 않소? 네, 물론입니다. 특히나 엔티티와 DTO의 네이밍은 겹칠 수 밖에 없죠 그렇기에 naming space를 사용하여 구분 합니다 ex.\nimport app.user_manager.entities as entity import app.user_manager.models as dto user_dto = dto.User user_entity = entity.User 구현보다 중요한 것이 설계이다. 구현 레벨의 설계도 중요하며 이러한 명확한 Convention이 있어야 통일된 Class Diagram과 Sequence Diagram, Module Diagram을 적립 할 수 있을 것이다\n해당 컨벤션이 정답이라고 결코 말할 수 없다. 그냥 이러한 컨벤션을 사용할 수도 있겠구나~ 라고 생각하면 좋을 것 같다\n","permalink":"https://dings-things.github.io/blog/posts/fastapi-convention/","summary":"클래스 기반의 FastAPI Structure Guide","title":"[Python] FastAPI Convention"}]
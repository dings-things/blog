<!doctype html><html lang=ko dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[DB] 분산 환경에서의 Redlock과 Lease | Ding's Coding Forge</title>
<meta name=keywords content="redis,distributed,lock,lease,Fault tolerance,Correctness,Availability"><meta name=description content="비동기 환경에서 분산 락과 소유권을 안전하게 관리하기 위한 Redlock과 Lease 메커니즘을 깊이 있게 탐구합니다."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/posts/distributed-locking/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/distributed-locking/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/distributed-locking/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/posts/distributed-locking/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[DB] 분산 환경에서의 Redlock과 Lease"><meta property="og:description" content="비동기 환경에서 분산 락과 소유권을 안전하게 관리하기 위한 Redlock과 Lease 메커니즘을 깊이 있게 탐구합니다."><meta property="og:locale" content="ko"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-29T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-29T00:00:00+00:00"><meta property="article:tag" content="Redis"><meta property="article:tag" content="Distributed"><meta property="article:tag" content="Lock"><meta property="article:tag" content="Lease"><meta property="article:tag" content="Fault Tolerance"><meta property="article:tag" content="Correctness"><meta property="og:image" content="https://dingyu.dev/posts/distributed-locking/img/redis.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/posts/distributed-locking/img/redis.png"><meta name=twitter:title content="[DB] 분산 환경에서의 Redlock과 Lease"><meta name=twitter:description content="비동기 환경에서 분산 락과 소유권을 안전하게 관리하기 위한 Redlock과 Lease 메커니즘을 깊이 있게 탐구합니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/posts/"},{"@type":"ListItem","position":2,"name":"[DB] 분산 환경에서의 Redlock과 Lease","item":"https://dingyu.dev/posts/distributed-locking/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[DB] 분산 환경에서의 Redlock과 Lease","name":"[DB] 분산 환경에서의 Redlock과 Lease","description":"비동기 환경에서 분산 락과 소유권을 안전하게 관리하기 위한 Redlock과 Lease 메커니즘을 깊이 있게 탐구합니다.","keywords":["redis","distributed","lock","lease","Fault tolerance","Correctness","Availability"],"articleBody":"배경 참여하고 있는 스터디에서 동료가 어느날 Redlock과 관련된 세션을 소개해주셨다.\n너무 좋은 컨텐츠여서 욕심나기에.. 나만의 이해로 더 깊게 파고 들까한다.\nRedlock 알고리즘을 보고 오면 좋을 것 같다.\nLock for what? 주요하게는 효율성과 정확성을 보장하기 위해 Lock을 사용한다\nEfficiency 불필요하게 중복된 작업 수행을 막을 수 있다\nex. N개의 노드에서 동일한 무거운 작업(10분 소요)을 수행 → 비용적/시간적 낭비 Correctness 동시 프로세스가 동일한 공유 자원에 대해 일관되고 정확한 데이터 처리가 가능\nex. N개의 노드에서 사용자의 출금 로직 수행 → 사용자 계좌의 N*요금 만큼 차감 Martin Kleppmann에 따르면 효율성을 위해 Redis Lock을 고려 중이라면 Redlock은 사용하지 않는 것을 추천한다.\n항목 싱글 Redis Lock Redis Redlock 알고리즘 락 획득 대상 하나의 Redis 인스턴스 5개의 독립된 Redis 인스턴스 락 생성 방법 SET key value NX PX 5개 노드 각각에 SET key value NX PX 시도 성공 조건 단일 Redis에서 락 획득 성공 5개 중 3개 이상 서버(majority) 락 획득 성공 장애 대응성 Redis 서버 장애 시 락 정보 소실 일부 서버 장애에도 majority 락이 유지되면 안전 Split Brain (네트워크 분할) 대응 불가능 일부 방어 가능 (단, 완전하지 않음) 일관성(Consistency) 단일 인스턴스 기반 (약한 일관성) 락을 획득하는 동안 일관성 강화 (multi-instance) 복잡도 단순 (구현 쉬움) 복잡 (락 취득 시간, clock drift 고려 필요) Fault Tolerance 낮음 상대적으로 높음 성능 빠름 (단일 노드 접근) 느릴 수 있음 (5개 노드 통신 필요) 주요 사용 예시 작은 시스템, 단일 서버 환경 글로벌 분산 시스템, 고가용성 락 필요 시스템 Redis 노드가 예기치 못하게 종료된 경우\nlock 취득에서 timeout 발생 → 애플리케이션 응답 지연 또는 비즈니스 로직 수행 불가\n불완전한 Lock 앞서 싱글 Redis 노드를 사용할 경우 장애 상황에서 고가용성과 안정성에 보장을 받을 수 없다.\nFail case 1 : GC Stop the World로 인한 취득한 lock의 release GC의 STW 현상은 얼마나 지속될 지 예상 불가능함 Concurrent GC 또한 STW 현상은 피할 수 없음 Fail case 2 : lock 취득 후 외부 port 작업 (API, DB, HDFS…)에서 패킷 loss lock 취득 후, IO 작업 수행 간의 지연 → TTL (lease) 만료 → 다른 스레드에서 lock 취득 후 동일 작업 수행 외부 네트워크 작업에서 패킷 유실로 인한 지연 → TTL (lease) 만료 … SPoF 해결 : Master - Slave 구조 Failover 되는 동안 TTL이 만료 → Unlock으로 인한 데이터 오염\nsequenceDiagram participant A as Client A participant Lock as Lock Service participant B as Client B participant Storage as Shared Storage A-\u003e\u003eLock: Acquire Lock on filename Lock--\u003e\u003eA: Lock Granted (with TTL) A-\u003e\u003eStorage: Read File Note over A: Redis failover (longer than TTL) Lock--\u003e\u003eB: Lock expired, available again B-\u003e\u003eLock: Acquire Lock on filename Lock--\u003e\u003eB: Lock Granted B-\u003e\u003eStorage: Read File B-\u003e\u003eStorage: Update and Write File A-\u003e\u003eStorage: Update and Write File (After GC pause) Note over Storage: Data corruption! 안정성 해결 : Fencing으로 안전한 lock 사용 MVCC에서 first commit wins와 같이, version에 기반하여 storage에서 트랜잭션을 처리하도록 한다. (애초에 그러면 lock을 안써도 되지 않나?)\nclient 1이 lock 획득에 성공(/w token33)하고 storage write를 시도하는 도중 지연이 발생 (GC, 네트워크 지연 등) client 1의 취득한 lock lease 만료 client 2가 lock을 획득(/w token34) 하고 client1의 작업이 종료되기 전에 storage에 write를 완료 client 1이 storage에 write → storage는 token34 이전인 token33은 reject (transaction fail) 가장 큰 문제는.. 과연 pencing token은 누가 생성할 것인가?이다. 분산 환경에서 카운터 증가를 구현하기 위해 또 다른 카운터 리더 선출이 필요해진다.. (무한 굴레)\nRedlock 동작 과정 현재 시간을 밀리초로 기록 동일한 키와 랜덤 값으로 모든 N개의 Redis 인스턴스에서 순차적으로 락을 시도. 각 시도에는 짧은 타임아웃을 설정해, 노드가 다운되면 바로 다음 인스턴스 이동. 락을 획득하는 데 걸린 시간을 계산하고, N개의 인스턴스 중 과반수 이상에서 락을 획득하고, 걸린 시간이 락의 유효 시간보다 짧으면 락을 획득했다고 판단. 락을 획득하면, 유효 시간은 초기 유효 시간에서 걸린 시간을 뺀 값으로 설정. 락을 획득하지 못한 경우, 혹은 락의 유효시간이 마이너스인 경우(획득 과정에서 초과됨), 모든 인스턴스에서 락을 해제. Bad Timing Issue 구분 설명 일반적인 분산 시스템 “시간은 믿을 수 없다\"고 가정 → 안전성은 무조건 지키고, 성능(liveness)만 시간에 의존 Redlock 시간(클럭 정확성, 네트워크 지연 등)에 의존해서 락의 안전성을 보장하려 함 문제점 클럭이 갑자기 변하거나(GC, NTP, 네트워크 지연), 프로세스가 일시 정지되면, 락 만료 시점 계산이 잘못돼서 락이 깨질 수 있음 결과 성능 문제(liveness degradation)가 아니라, 아예 데이터 손상이나 중복 실행(safety violation) 이 일어날 수 있음 sequenceDiagram participant C1 as Client 1 participant C2 as Client 2 participant A as Redis Node A participant B as Redis Node B participant C as Redis Node C participant D as Redis Node D participant E as Redis Node E %% First Scenario: Clock Jump C1-\u003e\u003eA: Acquire lock C1-\u003e\u003eB: Acquire lock C1-\u003e\u003eC: Acquire lock Note over C: Clock jumps forward -\u003e lock expires prematurely C1-\u003e\u003eD: (Network issue, cannot reach) C1-\u003e\u003eE: (Network issue, cannot reach) C2-\u003e\u003eC: Acquire lock (C believes no lock exists) C2-\u003e\u003eD: Acquire lock C2-\u003e\u003eE: Acquire lock Note over C1,C2: Both clients believe they hold the lock %% Second Scenario: Process Pause (e.g., GC) or Long Network Delay C1-\u003e\u003eA: Lock request sent (in-flight) C1-\u003e\u003eB: Lock request sent (in-flight) C1-\u003e\u003eC: Lock request sent (in-flight) C1-\u003e\u003eD: Lock request sent (in-flight) C1-\u003e\u003eE: Lock request sent (in-flight) Note over C1: Client 1 stops (GC pause or process pause) Note over A: Locks expire during Client 1 pause C2-\u003e\u003eA: Acquire new lock C2-\u003e\u003eB: Acquire new lock C2-\u003e\u003eC: Acquire new lock C2-\u003e\u003eD: Acquire new lock C2-\u003e\u003eE: Acquire new lock C1-\u003e\u003eC1: Client 1 resumes after GC pause C1-\u003e\u003eC1: Receives \"lock acquired\" responses from Redis (stale responses) Note over C1,C2: Both clients now believe they hold the lock 시나리오 설명 첫 번째 (Clock Jump) Redis C 노드의 시계가 갑자기 앞으로 점프하면서 TTL 만료가 빨라진다. Client 1이 락을 잡았다고 생각하지만, Client 2가 동시에 락을 다시 획득하여 둘 다 락을 보유했다고 착각하게 된다. 두 번째 (GC Pause) Client 1이 락을 요청하고 나서 GC로 멈추는 동안 락이 만료된다. Client 2가 락을 다시 획득하고, Client 1은 GC 복귀 후 예전 락 응답을 받아 자신이 락을 잡았다고 착각한다. Synchrony assumptions of Redlock 조건 설명 네트워크 지연 한계(bounded network delay) 패킷이 항상 정해진 최대 시간 내에 도착해야 한다 프로세스 일시정지 한계(bounded process pause) GC나 시스템 중단이 일정 시간 이하로 제한되어야 한다 시계 오차 한계(bounded clock drift) 각 서버의 클럭 오차가 작아야 하고, NTP 동기화가 신뢰할 수 있어야 한다 ➔ 즉, “모든 지연, 중단, 클럭 차이\"가 lock TTL(time-to-live)보다 훨씬 작아야 Redlock이 제대로 작동합니다.\n현실 세상에서 이러한 가정이 성립할 수 있을까요? 깃헙의 90-second packet delay를 떠올리면 절대라는 가정은 성립할 수 없습니다.\n결론적으로는… Redlock 알고리즘은 시간을 전재로 하는 알고리즘이며, 이는 클럭 점프/GC STW/네트워크 유실 등등 여러한 이유에서 정확성을 갖지 못한다.\nRedis는 애초에 “합의” 목적으로 나온 솔루션이 아닌 KV Store에 초점이 맞춰져 있기에 완벽한 Lock 취득을 위해서는 RedLock이 아닌 Zookeeper, Raft와 같은 방안을 선정하도록 한다.\n","wordCount":"1060","inLanguage":"ko","image":"https://dingyu.dev/posts/distributed-locking/img/redis.png","datePublished":"2025-04-29T00:00:00Z","dateModified":"2025-04-29T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/posts/distributed-locking/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=번역 type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=en href=https://dingyu.dev/en/ title=English aria-label=English>English</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/about/ title=소개><span>소개</span></a></li><li><a href=https://dingyu.dev/categories/ title=카테고리><span>카테고리</span></a></li><li><a href=https://dingyu.dev/tags/ title=태그><span>태그</span></a></li><li><a href=https://dingyu.dev/archives/ title=아카이브><span>아카이브</span></a></li><li><a href=https://dingyu.dev/search/ title="검색 (Alt + /)" accesskey=/><span>검색</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/>홈</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[DB] 분산 환경에서의 Redlock과 Lease</h1><div class=post-description>비동기 환경에서 분산 락과 소유권을 안전하게 관리하기 위한 Redlock과 Lease 메커니즘을 깊이 있게 탐구합니다.</div><div class=post-meta><span title='2025-04-29 00:00:00 +0000 UTC'>4월 29, 2025</span>&nbsp;·&nbsp;5 분&nbsp;·&nbsp;1060 단어&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;번역:<ul class=i18n_list><li><a href=https://dingyu.dev/en/posts/distributed-locking/>En</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/distributed-locking/index.ko.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/redis.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>목차</span></summary><div class=inner><ul><li><a href=#%eb%b0%b0%ea%b2%bd aria-label=배경>배경</a><ul><li><a href=#lock-for-what aria-label="Lock for what?">Lock for what?</a><ul><li><a href=#efficiency aria-label=Efficiency>Efficiency</a></li><li><a href=#correctness aria-label=Correctness>Correctness</a></li></ul></li><li><a href=#%eb%b6%88%ec%99%84%ec%a0%84%ed%95%9c-lock aria-label="불완전한 Lock">불완전한 Lock</a><ul><li><a href=#spof-%ed%95%b4%ea%b2%b0--master---slave-%ea%b5%ac%ec%a1%b0 aria-label="SPoF 해결 : Master - Slave 구조">SPoF 해결 : Master - Slave 구조</a></li><li><a href=#%ec%95%88%ec%a0%95%ec%84%b1-%ed%95%b4%ea%b2%b0--fencing%ec%9c%bc%eb%a1%9c-%ec%95%88%ec%a0%84%ed%95%9c-lock-%ec%82%ac%ec%9a%a9 aria-label="안정성 해결 : Fencing으로 안전한 lock 사용">안정성 해결 : Fencing으로 안전한 lock 사용</a></li></ul></li><li><a href=#redlock aria-label=Redlock>Redlock</a><ul><li><a href=#%eb%8f%99%ec%9e%91-%ea%b3%bc%ec%a0%95 aria-label="동작 과정">동작 과정</a></li><li><a href=#bad-timing-issue aria-label="Bad Timing Issue">Bad Timing Issue</a></li><li><a href=#synchrony-assumptions-of-redlock aria-label="Synchrony assumptions of Redlock">Synchrony assumptions of Redlock</a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=배경>배경<a hidden class=anchor aria-hidden=true href=#배경>#</a></h1><p>참여하고 있는 스터디에서 동료가 어느날 Redlock과 관련된 세션을 소개해주셨다.</p><p>너무 좋은 컨텐츠여서 욕심나기에.. 나만의 이해로 더 깊게 파고 들까한다.</p><blockquote><p><a href=https://chaewonkong.github.io/posts/2025-03-13-dist-lock-with-redis/>Redlock 알고리즘</a>을 보고 오면 좋을 것 같다.</p></blockquote><h2 id=lock-for-what>Lock for what?<a hidden class=anchor aria-hidden=true href=#lock-for-what>#</a></h2><p>주요하게는 <code>효율성</code>과 <code>정확성</code>을 보장하기 위해 Lock을 사용한다</p><h3 id=efficiency>Efficiency<a hidden class=anchor aria-hidden=true href=#efficiency>#</a></h3><p>불필요하게 중복된 작업 수행을 막을 수 있다</p><ul><li>ex. N개의 노드에서 동일한 무거운 작업(10분 소요)을 수행 → 비용적/시간적 낭비</li></ul><h3 id=correctness>Correctness<a hidden class=anchor aria-hidden=true href=#correctness>#</a></h3><p>동시 프로세스가 동일한 공유 자원에 대해 일관되고 정확한 데이터 처리가 가능</p><ul><li>ex. N개의 노드에서 사용자의 출금 로직 수행 → 사용자 계좌의 N*요금 만큼 차감</li></ul><p><a href=https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html>Martin Kleppmann</a>에 따르면 효율성을 위해 Redis Lock을 고려 중이라면 Redlock은 사용하지 않는 것을 추천한다.</p><p><img loading=lazy src=/posts/distributed-locking/redilock.png></p><table><thead><tr><th style=text-align:left>항목</th><th style=text-align:left>싱글 Redis Lock</th><th style=text-align:left>Redis Redlock 알고리즘</th></tr></thead><tbody><tr><td style=text-align:left>락 획득 대상</td><td style=text-align:left>하나의 Redis 인스턴스</td><td style=text-align:left>5개의 독립된 Redis 인스턴스</td></tr><tr><td style=text-align:left>락 생성 방법</td><td style=text-align:left><code>SET key value NX PX &lt;TTL></code></td><td style=text-align:left>5개 노드 각각에 <code>SET key value NX PX &lt;TTL></code> 시도</td></tr><tr><td style=text-align:left>성공 조건</td><td style=text-align:left>단일 Redis에서 락 획득 성공</td><td style=text-align:left>5개 중 3개 이상 서버(majority) 락 획득 성공</td></tr><tr><td style=text-align:left>장애 대응성</td><td style=text-align:left>Redis 서버 장애 시 락 정보 소실</td><td style=text-align:left>일부 서버 장애에도 majority 락이 유지되면 안전</td></tr><tr><td style=text-align:left>Split Brain (네트워크 분할) 대응</td><td style=text-align:left>불가능</td><td style=text-align:left>일부 방어 가능 (단, 완전하지 않음)</td></tr><tr><td style=text-align:left>일관성(Consistency)</td><td style=text-align:left>단일 인스턴스 기반 (약한 일관성)</td><td style=text-align:left>락을 획득하는 동안 일관성 강화 (multi-instance)</td></tr><tr><td style=text-align:left>복잡도</td><td style=text-align:left>단순 (구현 쉬움)</td><td style=text-align:left>복잡 (락 취득 시간, clock drift 고려 필요)</td></tr><tr><td style=text-align:left>Fault Tolerance</td><td style=text-align:left>낮음</td><td style=text-align:left>상대적으로 높음</td></tr><tr><td style=text-align:left>성능</td><td style=text-align:left>빠름 (단일 노드 접근)</td><td style=text-align:left>느릴 수 있음 (5개 노드 통신 필요)</td></tr><tr><td style=text-align:left>주요 사용 예시</td><td style=text-align:left>작은 시스템, 단일 서버 환경</td><td style=text-align:left>글로벌 분산 시스템, 고가용성 락 필요 시스템</td></tr></tbody></table><p><img loading=lazy src=/posts/distributed-locking/spof.png></p><blockquote><p><strong>Redis 노드가 예기치 못하게 종료된 경우</strong></p><p>lock 취득에서 timeout 발생 → 애플리케이션 응답 지연 또는 비즈니스 로직 수행 불가</p></blockquote><h2 id=불완전한-lock>불완전한 Lock<a hidden class=anchor aria-hidden=true href=#불완전한-lock>#</a></h2><p>앞서 싱글 Redis 노드를 사용할 경우 장애 상황에서 <code>고가용성</code>과 <code>안정성</code>에 보장을 받을 수 없다.</p><ol><li>Fail case 1 : GC Stop the World로 인한 취득한 lock의 release<ul><li>GC의 STW 현상은 얼마나 지속될 지 예상 불가능함</li><li>Concurrent GC 또한 STW 현상은 피할 수 없음</li></ul></li><li>Fail case 2 : lock 취득 후 외부 port 작업 (API, DB, HDFS&mldr;)에서 패킷 loss<ul><li>lock 취득 후, IO 작업 수행 간의 지연 → TTL (lease) 만료 → 다른 스레드에서 lock 취득 후 동일 작업 수행</li><li>외부 네트워크 작업에서 패킷 유실로 인한 지연 → TTL (lease) 만료 &mldr;</li></ul></li></ol><h3 id=spof-해결--master---slave-구조>SPoF 해결 : Master - Slave 구조<a hidden class=anchor aria-hidden=true href=#spof-해결--master---slave-구조>#</a></h3><p>Failover 되는 동안 TTL이 만료 → Unlock으로 인한 데이터 오염</p><pre class=mermaid>sequenceDiagram
    participant A as Client A
    participant Lock as Lock Service
    participant B as Client B
    participant Storage as Shared Storage

    A->>Lock: Acquire Lock on filename
    Lock-->>A: Lock Granted (with TTL)

    A->>Storage: Read File
    Note over A: Redis failover (longer than TTL)

    Lock-->>B: Lock expired, available again
    B->>Lock: Acquire Lock on filename
    Lock-->>B: Lock Granted

    B->>Storage: Read File
    B->>Storage: Update and Write File

    A->>Storage: Update and Write File (After GC pause)

    Note over Storage: Data corruption!
</pre><h3 id=안정성-해결--fencing으로-안전한-lock-사용>안정성 해결 : Fencing으로 안전한 lock 사용<a hidden class=anchor aria-hidden=true href=#안정성-해결--fencing으로-안전한-lock-사용>#</a></h3><p><strong>MVCC</strong>에서 <code>first commit wins</code>와 같이, version에 기반하여 storage에서 트랜잭션을 처리하도록 한다. (애초에 그러면 lock을 안써도 되지 않나?)</p><p><img loading=lazy src=/posts/distributed-locking/image.png></p><ol><li>client 1이 lock 획득에 성공(/w token33)하고 storage write를 시도하는 도중 지연이 발생 (GC, 네트워크 지연 등)</li><li>client 1의 취득한 lock lease 만료</li><li>client 2가 lock을 획득(/w token34) 하고 client1의 작업이 종료되기 전에 storage에 write를 완료</li><li>client 1이 storage에 write → storage는 token34 이전인 token33은 reject (transaction fail)</li></ol><p>가장 큰 문제는.. 과연 pencing token은 누가 생성할 것인가?이다. 분산 환경에서 카운터 증가를 구현하기 위해 또 다른 카운터 리더 선출이 필요해진다.. (무한 굴레)</p><h2 id=redlock>Redlock<a hidden class=anchor aria-hidden=true href=#redlock>#</a></h2><h3 id=동작-과정>동작 과정<a hidden class=anchor aria-hidden=true href=#동작-과정>#</a></h3><ol><li>현재 시간을 밀리초로 기록</li><li>동일한 키와 랜덤 값으로 모든 N개의 Redis 인스턴스에서 순차적으로 락을 시도. 각 시도에는 짧은 타임아웃을 설정해, 노드가 다운되면 바로 다음 인스턴스 이동.</li><li>락을 획득하는 데 걸린 시간을 계산하고, N개의 인스턴스 중 과반수 이상에서 락을 획득하고, 걸린 시간이 락의 유효 시간보다 짧으면 락을 획득했다고 판단.</li><li>락을 획득하면, 유효 시간은 초기 유효 시간에서 걸린 시간을 뺀 값으로 설정.</li><li>락을 획득하지 못한 경우, 혹은 락의 유효시간이 마이너스인 경우(획득 과정에서 초과됨), 모든 인스턴스에서 락을 해제.</li></ol><h3 id=bad-timing-issue>Bad Timing Issue<a hidden class=anchor aria-hidden=true href=#bad-timing-issue>#</a></h3><table><thead><tr><th>구분</th><th>설명</th></tr></thead><tbody><tr><td>일반적인 분산 시스템</td><td>&ldquo;시간은 믿을 수 없다"고 가정 → 안전성은 무조건 지키고, 성능(liveness)만 시간에 의존</td></tr><tr><td>Redlock</td><td>시간(클럭 정확성, 네트워크 지연 등)에 <strong>의존</strong>해서 락의 안전성을 보장하려 함</td></tr><tr><td>문제점</td><td>클럭이 갑자기 변하거나(GC, NTP, 네트워크 지연), 프로세스가 일시 정지되면, 락 만료 시점 계산이 잘못돼서 <strong>락이 깨질 수 있음</strong></td></tr><tr><td>결과</td><td>성능 문제(liveness degradation)가 아니라, 아예 <strong>데이터 손상이나 중복 실행(safety violation)</strong> 이 일어날 수 있음</td></tr></tbody></table><pre class=mermaid>sequenceDiagram
    participant C1 as Client 1
    participant C2 as Client 2
    participant A as Redis Node A
    participant B as Redis Node B
    participant C as Redis Node C
    participant D as Redis Node D
    participant E as Redis Node E

    %% First Scenario: Clock Jump
    C1->>A: Acquire lock
    C1->>B: Acquire lock
    C1->>C: Acquire lock
    Note over C: Clock jumps forward -> lock expires prematurely
    C1->>D: (Network issue, cannot reach)
    C1->>E: (Network issue, cannot reach)

    C2->>C: Acquire lock (C believes no lock exists)
    C2->>D: Acquire lock
    C2->>E: Acquire lock
    Note over C1,C2: Both clients believe they hold the lock

    %% Second Scenario: Process Pause (e.g., GC) or Long Network Delay
    C1->>A: Lock request sent (in-flight)
    C1->>B: Lock request sent (in-flight)
    C1->>C: Lock request sent (in-flight)
    C1->>D: Lock request sent (in-flight)
    C1->>E: Lock request sent (in-flight)

    Note over C1: Client 1 stops (GC pause or process pause)

    Note over A: Locks expire during Client 1 pause

    C2->>A: Acquire new lock
    C2->>B: Acquire new lock
    C2->>C: Acquire new lock
    C2->>D: Acquire new lock
    C2->>E: Acquire new lock

    C1->>C1: Client 1 resumes after GC pause
    C1->>C1: Receives "lock acquired" responses from Redis (stale responses)

    Note over C1,C2: Both clients now believe they hold the lock
</pre><table><thead><tr><th>시나리오</th><th>설명</th></tr></thead><tbody><tr><td>첫 번째 (Clock Jump)</td><td>Redis C 노드의 시계가 갑자기 앞으로 점프하면서 TTL 만료가 빨라진다. Client 1이 락을 잡았다고 생각하지만, Client 2가 동시에 락을 다시 획득하여 둘 다 락을 보유했다고 착각하게 된다.</td></tr><tr><td>두 번째 (GC Pause)</td><td>Client 1이 락을 요청하고 나서 GC로 멈추는 동안 락이 만료된다. Client 2가 락을 다시 획득하고, Client 1은 GC 복귀 후 예전 락 응답을 받아 자신이 락을 잡았다고 착각한다.</td></tr></tbody></table><h3 id=synchrony-assumptions-of-redlock>Synchrony assumptions of Redlock<a hidden class=anchor aria-hidden=true href=#synchrony-assumptions-of-redlock>#</a></h3><table><thead><tr><th>조건</th><th>설명</th></tr></thead><tbody><tr><td>네트워크 지연 한계(bounded network delay)</td><td>패킷이 항상 정해진 최대 시간 내에 도착해야 한다</td></tr><tr><td>프로세스 일시정지 한계(bounded process pause)</td><td>GC나 시스템 중단이 일정 시간 이하로 제한되어야 한다</td></tr><tr><td>시계 오차 한계(bounded clock drift)</td><td>각 서버의 클럭 오차가 작아야 하고, NTP 동기화가 신뢰할 수 있어야 한다</td></tr></tbody></table><p>➔ 즉, &ldquo;모든 지연, 중단, 클럭 차이"가 lock TTL(time-to-live)보다 훨씬 작아야 Redlock이 제대로 작동합니다.</p><p>현실 세상에서 이러한 가정이 성립할 수 있을까요? 깃헙의 <a href=https://github.blog/news-insights/the-library/downtime-last-saturday/>90-second packet delay</a>를 떠올리면 절대라는 가정은 성립할 수 없습니다.</p><p>결론적으로는&mldr; Redlock 알고리즘은 시간을 전재로 하는 알고리즘이며, 이는 클럭 점프/GC STW/네트워크 유실 등등 여러한 이유에서 정확성을 갖지 못한다.</p><p>Redis는 애초에 &ldquo;합의&rdquo; 목적으로 나온 솔루션이 아닌 KV Store에 초점이 맞춰져 있기에 완벽한 Lock 취득을 위해서는 RedLock이 아닌 Zookeeper, Raft와 같은 방안을 선정하도록 한다.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/tags/redis/>Redis</a></li><li><a href=https://dingyu.dev/tags/distributed/>Distributed</a></li><li><a href=https://dingyu.dev/tags/lock/>Lock</a></li><li><a href=https://dingyu.dev/tags/lease/>Lease</a></li><li><a href=https://dingyu.dev/tags/fault-tolerance/>Fault Tolerance</a></li><li><a href=https://dingyu.dev/tags/correctness/>Correctness</a></li><li><a href=https://dingyu.dev/tags/availability/>Availability</a></li></ul><nav class=paginav><a class=next href=https://dingyu.dev/posts/local-sasl-kafka/><span class=title>다음 페이지 »</span><br><span>[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="복사";function s(){t.innerHTML="복사 완료!",setTimeout(()=>{t.innerHTML="복사"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
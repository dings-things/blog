<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Flink Dynamic Job Case Study | Ding's Coding Forge</title>
<meta name=keywords content="kafka,flink,apache,fds,dynamic job"><meta name=description content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/posts/flink-dynamic-job/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.ba0de23ad40e17ca82720b577f8ae6ec11a26fb07407316cff70888e344ad129.css integrity="sha256-ug3iOtQOF8qCcgtXf4rm7BGib7B0BzFs/3CIjjRK0Sk=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dingyu.dev/posts/flink-dynamic-job/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/posts/flink-dynamic-job/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Flink Dynamic Job Case Study"><meta property="og:description" content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-06T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Flink"><meta property="article:tag" content="Apache"><meta property="article:tag" content="Fds"><meta property="article:tag" content="Dynamic Job"><meta property="og:image" content="https://dingyu.dev/posts/flink-dynamic-job/img/flink.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/posts/flink-dynamic-job/img/flink.png"><meta name=twitter:title content="[EDA] Flink Dynamic Job Case Study"><meta name=twitter:description content="This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Flink Dynamic Job Case Study","item":"https://dingyu.dev/posts/flink-dynamic-job/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Flink Dynamic Job Case Study","name":"[EDA] Flink Dynamic Job Case Study","description":"This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system.","keywords":["kafka","flink","apache","fds","dynamic job"],"articleBody":" REFS Rules Based Stream Processing with Apache Flink’s Broadcast Pattern Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System Build a dynamic rules engine with Amazon Managed Service for Apahce Flink 리서치 배경 Window Time 동안 필터링 조건에 따른 횟수 기반의 탐지 정책을 구축하는 방안 케이스 스터디가 필요함 하나의 Job 코드에서 모든 정책에 대한 처리 하는 방안에 대한 리서치가 필요 정책 별 인스턴스 할당은 가상화 된 컨테이너를 활용하더라도 리소스 낭비가 심함 정책은 관리자에 의해 수정될 수 있으며, 정책 변경에 따른 재배포를 최소화해야 함 사전 지식 동적 파티셔닝 Kafka는 Event Key를 기반으로 해싱 후, 모듈러 연산을 통해 파티셔닝 됨\nKafka Streams, Flink에서 Event의 Key가 아닌 값으로 group by (keyBy) 할 경우, 해당 Key를 기준으로 리셔플이 발생\n(리셔플 발생 시, 네트워크를 통해 Task Manager 간의 데이터 재구성이 진행되며 심각한 오버헤드가 될 수 있음) 이를 적절히 해결하기 위해, 동일한 키를 가진 스트림 트랜잭션이 **같은 작업자(subtask)**에서 처리될 수 있도록 구성해야 함\nex. ) Group By Target이 “ID” or “IP” 으로 source에서 미리 두개의 topic으로 발행하는 것도 방법이 됨\n용어 정의 구성 요소 설명 주요 역할 특징 JobManager Flink의 중앙 관리 노드로, 작업(Job)의 생명 주기를 관리합니다. - 작업 계획 수립 및 분배- ExecutionGraph 생성- Checkpoint 관리 및 장애 복구- 리소스(TaskManager 슬롯) 할당 - 클러스터당 하나의 JobManager 실행- 모든 작업의 상태와 진행 상황을 모니터링- Checkpoint와 Savepoint를 통해 상태를 저장 및 복구 TaskManager Flink의 작업을 실행하는 워커 노드입니다. - SubTask 실행- 네트워크 통신 및 데이터 전송- 상태(State)와 메모리 관리 - 병렬 처리 단위를 실행하는 물리적 노드- 클러스터 내 여러 TaskManager 존재- 각 TaskManager는 여러 슬롯(Slot)을 가질 수 있으며, 슬롯마다 SubTask 실행 SubTask Flink 작업의 병렬 실행 단위로, TaskManager 내에서 실행됩니다. - 파티셔닝된 데이터를 처리- 연산자(Operator)의 로직 실행- 독립적인 상태(State) 관리 - keyBy를 통해 파티셔닝된 데이터만 처리- 병렬도(parallelism)에 따라 생성- SubTask 간에는 데이터가 공유되지 않으며 독립적으로 작동 Broadcast 작은 크기의 데이터 스트림을 모든 SubTask에 복제하여 전달하는 메커니즘입니다. - 규칙(Rule) 데이터 전파- 설정 정보 동기화- 컨트롤 메시지 공유 - Broadcast 데이터를 모든 SubTask에 복사- 일반 데이터 스트림과 결합 가능- 네트워크 부하가 발생할 수 있으므로 작은 크기의 데이터에 적합 구현 방안 rule DB의 CDC를 기반으로 액션 이벤트 + 활성화된 정책 이벤트를 병합하여 이벤트 발행 액션 이벤트가 1이고 활성화된 이벤트가 N개라면 총 N개의 병합(액션+정책 정보 포함) 이벤트 발행 DynamicKeyFunction을 토대로 source stream에서 group by에 따라 이벤트를 파티셔닝 새로운 keyBy() 조건에 따른 리셔플을 동적으로 처리 → Job 코드 수정 X, 재배포 X 기존 keyBy() 조건인 경우 기존 TaskSlot에서 처리 DynamicEvaluationFunction에서는 소스로부터 데이터를 읽어와 이벤트가 정책에 부합하는 지 확인, 정책에 부합한다면 restrict event로 발행 Broadcast State REFS : A Practical guid to broadcast state in Flink\nBroadcast State 는 하나의 데이터 스트림을 다른 데이터 스트림의 모든 작업(Task)에 동일한 상태(State)로 전파하여 공유할 수 있도록 설계된 기능\n주로 동일한 설정값이나 기준 데이터를 실시간 업데이트하여 다른 데이터와 조합해 처리해야 하는 애플리케이션에서 사용 됨\nBroadcast State의 동작 구조 두 개의 스트림이 필요: Broadcast Stream: 이 스트림의 이벤트는 모든 작업(Task)의 병렬 인스턴스에 **공유 상태(State)**로 전파됨 일반 Stream: 이 스트림의 이벤트는 각 작업의 병렬 인스턴스로 개별적으로 전달됨 이벤트 처리 방식: Broadcast Stream의 이벤트는 상태로 유지되어 모든 병렬 작업에서 참조 가능 일반 Stream의 이벤트는 개별 작업에서 Broadcast Stream의 상태와 함께 처리 적합한 사용 사례 Low Throughput vs High Throughput 스트림 결합:\nBroadcast Stream은 상대적으로 낮은 속도(low throughput)로 동작하며, 이를 일반 스트림(high throughput)과 결합해 효율적으로 처리 소스 액션 이벤트 스트림과 알림 정책을 스트림 기반으로 전환하여, 동적으로 결합하여 사용할 수 있도록 함 동적 처리 로직 업데이트:\nBroadcast Stream을 사용해 처리 로직 또는 기준 데이터를 실시간으로 업데이트 정책 변경 시, Broadcast stream으로 정책 정보 전달, 실시간으로 변경된 정책으로 Evaluate Data Stream : Source Event (결제 이벤트)\nBroadcast Stream : 정책 Event (Retention Time은 무제한)\n원본 이벤트 (액션 이벤트)에 정책 Event를 병합하여 처리 Operator Task는 Broadcast Stream 기반으로 하는 Broadcast State(K/V Store) 를 바탕으로 정책 Evaluate Dynamic Data Paritioning REFS : Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System\nProduction System에서 runtime에 Job을 재배포할 필요 없이 Rule을 더하거나 지울 수 있도록 시스템을 구현한다\nKeyBy와 Partitioning KeyBy 메서드: Flink의 keyBy 메서드를 사용하면 스트림의 이벤트에 **키(Key)**를 지정 가능 같은 키를 가진 이벤트는 같은 파티션으로 할당되며, 다음 Operator의 같은 Task에서 처리됨 Key 지정의 일반적인 패턴: 대부분의 스트리밍 애플리케이션에서는 키를 정적인 필드로 고정 e.g. 유저 로그인(login stream)에서 memberID를 키로 사용해 윈도우 기반 집계를 수행 Horizontal Scalability: 정적 키를 사용하면 수평적 확장성(horizontal scalability)을 제공하여 높은 처리량을 지원 구분 정적 키 (Static Key) 동적 키 (Dynamic Key) 정의 런타임 전에 미리 고정된 필드로 데이터를 그룹화 런타임 시점에 비즈니스 로직에 따라 동적으로 키를 설정 설정 고정된 필드 기반의 keyBy (예: Transaction::getAccountId). JSON이나 Rule 엔진과 같은 외부 설정으로 키를 구성(예: groupingKeyNames 필드에서 동적으로 결정) 유연성 비즈니스 로직 변경에 대응하기 어려움 비즈니스 요구사항 변화에 따라 키 설정을 변경 가능 구현 난이도 단순하고 구현하기 쉬움 상대적으로 복잡하며, 런타임 시 Rule 파싱 및 키 설정 로직 추가 필요 성능 최적화에 유리하며, 실행 시 오버헤드가 적음 키 계산 로직 및 유연성으로 인해 약간의 추가 성능 오버헤드 발생 적용 사례 - Account ID 기반 그룹화- 동일 IP 기반 집계- 사용자별 활동 추적 - 다양한 필드 기반 그룹화 (예: 송신자, 수신자)- 조건에 따라 동적으로 그룹화- Rule 기반 실시간 처리 장점 - 구현 및 유지보수가 용이- 성능 최적화에 유리- 단순한 집계 작업에 적합 - 복잡한 비즈니스 로직을 처리 가능- 유연하고 확장성이 높음- 다양한 Use Case에 적합 단점 - 복잡한 요구사항을 처리하기 어려움- 비즈니스 변화 시 재배포 필요 - 구현이 복잡하고 런타임 오버헤드 발생- 실수로 인해 키 설정 오류 발생 가능 셔플이 발생하지 않도록, 정책에 따라 생성된 SubTask가 동일한 KeyedStream을 사용할 수 있도록 한다 Static 하게 지정된 Key가 아닌 정책에 따라 동적으로 KeyedStream을 생성하거나 재사용하도록 구성하는 방안\n성능이나 코드파악에서는 하드코딩된 명시적인 Key가 관리하기엔 용이할 수 있다. 하지만, 지속가능한 아키텍처를 구현하기 위해서 어느정도의 TradeOff를 감수하고 동적 키 파티셔닝을 구현하는 것임\n*T : Transaction (결제 이벤트를 의미)\nT1_Rule1, T1_Rule2, T1_Rule3 는 Flink SubTask를 의미\n각각은 groupingKey (keyBy)에 따라 셔플링되어 각 네트워크를 통해 SubTask로 전달\n다른 정책, 동일 KeyBy 정책 Evaluate 조건은 다를지라도 Group By하는 Key가 같을 경우, 동일 SubTask 내에서 정책 평가를 진행\n동일 SubTask에 여러 정책을 Evaluate 할 경우, SubTask 내부에서 순차적으로 정책 평가를 진행\n병렬도를 늘리고 싶다면 소스이벤트의 다른 필드를 키로 하여 파티션을 나눌수 있겠지만 그만큼 셔플링으로 인한 오버헤드가 발생됨\n정책을 동적으로 만들 수 있는 파라미터 정의\n필드명 설명 예시 RuleID 정책 고유 ID 78, 889 Aggregation Field 집계 결과가 저장되는 필드 명 id_count, hpid_count Grouping Fields 집계할 필드 ID, IP Aggregation Function 집계 연산 sum, count, avg Window Duration 집계 기간 10m, 10s, 90d Limit 임계치 3, 5 Limit Operator 임계치 연산자 gt, lt, equal Filter 필터링 조건 { “filter_option”: “option_value”} e.x “정책 2: 로그인 단계에서 3분 이내에 동일 ID의 서로 다른 IP가 4개 초과인 경우 알림”\n{ \"ruleId\": 2, \"ruleState\": \"ACTIVE\", \"groupingKeyNames\": [\"id\"], \"aggregateFieldName\": \"ip\", \"aggregatorFunctionType\": \"UNIQUE_COUNT\", \"filter\" : { \"action\": \"login\" }. \"limitOperatorType\": \"gt\", \"limit\": 4, \"windowMinutes\": \"3m\" } Rules BroadCasting REFS : Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic\n앞서 설명한 **DynamicKeyFunction()**은 데이터를 동적으로 파티셔닝하여 셔플링으로 인한 오버헤드를 최소화 DynamicEvaluationFunction() 은 정책에 따른 평가를 수행하는 데이터를 의미\n컴파일 되기 전에 미리 Rules 를 List로 읽어와 실행하는 것은 가능하다\n하지만 컴파일 된 후, 정책 변경 시에 결코 동적으로 정책에 따른 SubTask Operator를 동작 시킬 수 없다\n이를 해결하기 위해 Rules Broadcasting을 구현 Source Topic으로 부터 액션 이벤트를 받아오고, Rule Source를 Broadcast로 병합하여 정책 평가\n만약! 정책 DB가 Soft Delete 이라면 CDC의 disabled 컬럼을 통해 rule_id operator를 드롭하도록 한다 신규 추가된 정책은 새롭게 operator task로 생성한다\nBroadcasting Flow 항목 설명 Payment Event Source 병렬적으로 Kafka 파티션에서 이벤트를 컨슘. Dynamic Key Function DynamicKeyFunction()을 통해 병렬 Task로 파티셔닝. 지정된 키에 따라 복합키 또는 단일키를 해싱하여 네트워크로 데이터 전송 Dynamic Evaluation Function - 필터링 조건에 따라 Data Window를 상태 저장소(State Backend)에 저장- 임계치를 초과하면 Sinking 처리 Restriction Topic 제재(Restriction) Topic으로 제재 정보를 포함하여 발행 *병렬도는 부하 테스트를 통해 Consumer Lag을 최소화하는 병렬도 산정\nRule DB의 CDC는 Broadcast Channel을 통해 main processing data flow에 병합 됨 Broadcast는 각 메시지를 모든 병렬 인스턴스로 뿌림 (key나 source 파티션에 관계없이 모두 전달됨) FDS 시스템에서의 개략적 설계 방안 processBroadcastElement: Broadcast source stream의 이벤트 발생 시 트리거 됨 CDC 로 기존 정책 remove + 새로운 정책 insert processElement: Source stream의 이벤트 발생 시 트리거 됨 현재 활성화된 정책들을 불러와 활성화된 조건 마다 Rule 조건 + Payment 이벤트를 병합한 이벤트를 발행 정책 별 group by 조건에 따라 파티셔닝 됨 (keyBy) Broadcast Stream 에서 읽어온 데이터는 Broadcast State (K/V map)에 상태를 저장한다\nBroadcast Stream에 새로운 메시지가 도착하면 processBroadcastElement() 가 호출된다\n해당 class를 상속하는 DynamicKeyFunction을 구현하면 runtime에 분산 키를 수정할 수 있다\nCustom Window Processing REFS : Advanced Flink Application Patterns Vol.3: Custom Window Processing\nFlink에서는 다양한 유즈케이스에 맞춘 Window API를 제공함\n종류 설명 사용 예시 Tumbling Window - 고정된 간격으로 데이터를 그룹화- 각 윈도우는 겹치지 않고 연속적으로 이어짐 - timeWindow(Time.minutes(1))- 1분마다 평균, 합계 등의 집계 처리 Sliding Window - 고정된 크기의 윈도우가 겹치며 이동.- 슬라이드 간격(slide)에 따라 중복된 데이터를 처리할 수 있음 - timeWindow(Time.minutes(1), Time.seconds(30))- 1분 윈도우, 30초 간격으로 이동하며 집계 처리. Session Window - 데이터가 **활동 간격(session gap)**에 따라 윈도우가 시작되고 종료됨.- 활동 간 데이터가 없는 경우 윈도우가 닫히고 결과 출력. - sessionWindow(Time.minutes(5))- 유저별 활동 세션 분석. 이 중, 고려해볼 Window는 Tumbling과 Sliding Window\nWindow API 사용 시 제약 사항 유형 Tumbling Window Sliding Window 정책 예시 Time Window동안 동일 이벤트가 6번 발생하면 제재한다 Time Window동안 동일 이벤트가 4번 발생하면 제재한다 가정 제약사항 Tumbling Window는 고정된 간격으로 겹치지 않게 이어지기 때문에 탐지할 수 없음 슬라이드 간격에 따라 중복된 데이터가 처리됨, Sliding 간격을 촘촘히 하더라도 정확한 탐지가 불가능 Tumbling Window 예외 케이스 예시 Sliding Window 예외 케이스 예시 가장 큰 제약 사항 Flink API의 sliding window example을 보면, slide S인 sliding window를 쓰면, S/2 만큼의 evaluation delay가 생기게 된다\n윈도우 API의 트리거는 윈도우의 종료 시점에 실행되며, 종료 시점까지는 Delay가 필연적으로 발생한다\n→ Fraud Detection Delay 동안 어뷰저의 Negative action을 방치하므로 회사의 손실을 야기시킨다\nCustom Window Function Implementation DynamicEvaluationFunction()에 대한 구현 Consume Event: Source로 부터 이벤트를 가져옴 DynamicKeyFunction에 따라, 정책 정보 + 액션 이벤트가 함께 이벤트에 포함됨 Add Event: 이벤트를 집계하기 위해 상태 저장소에 현재 이벤트 저장 Get Rule: Broadcast State로 부터 현재 활성화된 정책 불러오기 만약 정책이 존재하지 않는다면 비활성화된 정책임 (처리할 필요 X return) Rule Condition Check: 현재 이벤트가 필터링 조건에 부합하는지 체크 부합하지 않는다면 return Get Window States: 이벤트 시간 기준으로 정책에 등록된 duration 동안 정책을 만족하는 이벤트 집계 Produce Restrict Topic: 집계된 결과가 정책을 만족하면 다음 Enforcement Topic으로 발행 Cleanup: Retention 기간이 만료된 이벤트 제거 Window State에 저장될 이벤트에 대한 고찰 이벤트는 source가 되는 이벤트의 발행 시점 timestamp를 갖게 된다 파티셔닝은 group by 조건에 따라 발생되기에 동일한 timestamp를 가진 이벤트가 여러개가 발생될 수 있다 중복 적재가 되더라도 무관한 자료구조인 Set을 활용하는 것이 바람직. Key는 timestamp\nMapState\u003cLong, Set\u003cPaymentEvent\u003e\u003e windowState; 상태 저장소는 Key Value Store이기 때문에 List Type을 사용할 수 없다\n필연적으로 모든 Map의 timestamp를 순회하면서 만족하는 값을 찾아야 하는데…\n이 부분에 대한 리서치는 조금 더 필요할 듯 event 전체를 순회하는게 아니라 timestamp만 순회하여 메모리는 크게 이슈가 되지 않을듯 (다만 loop 동안 CPU가 괜찮을까..?)\nEvent Retention에 대한 고찰 보관 기간 즉, Event의 TTL을 어떻게 잡을 것인가 ?\nDynamicEvaluationFunction() 에서는 같은 key scope를 가지는 결제 이벤트를 받을 수 있지만, 다른 Rule에 의해 evaluate되고, 다른 길이의 time window를 가질 수 있다\n그렇기에 Rule Stream (Broadcast Stream)에서 이벤트를 컨슈밍하는 시점에서 가장 긴 Duration을 업데이트할 수 있도록 한다\nex. UpdateWidestWindow\n@Override public void processBroadcastElement(Rule rule, Context ctx, Collector\u003cAlert\u003e out) { ... updateWidestWindowRule(rule, boradcastState); } private void updatWidestWindowRule(Rule rule, BoradcastState\u003cInteger, Rule\u003e broadcastState) { Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY); if (widestWindowRule == null) { broadcastState.put(WIDEST_WRULE_KEY, rule); return; } if (widestWindowRule.getWindowMillis() \u003c rule.getWindowMillis()) { broacastState.put(WIDEST_RULE_KEY, rule); } } 즉 Dynamic Evaluation에서는 가장 Duration이 긴 정책을 기반으로 Event의 TTL을 지정한다\n","wordCount":"1863","inLanguage":"en","image":"https://dingyu.dev/posts/flink-dynamic-job/img/flink.png","datePublished":"2024-12-06T00:00:00Z","dateModified":"2024-12-06T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/posts/flink-dynamic-job/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dingyu.dev/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/search/ title="🔍 (Alt + /)" accesskey=/><span>🔍</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Flink Dynamic Job Case Study</h1><div class=post-description>This post explores dynamic rule-based stream processing using Apache Flink for real-time fraud detection. It covers key topics such as dynamic key partitioning, broadcast state for rule updates, and custom window processing to efficiently evaluate transactions without redeploying jobs. The implementation ensures low-latency fraud detection by minimizing shuffle overhead, dynamically applying grouping keys, and leveraging stateful processing. Additionally, it discusses event retention strategies, performance considerations, and architecture trade-offs for building a scalable, high-performance fraud detection system.</div><div class=post-meta><span title='2024-12-06 00:00:00 +0000 UTC'>December 6, 2024</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1863 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/flink-dynamic-job/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/flink.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><ul><ul><ul><li><a href=#refs aria-label=REFS>REFS</a></li></ul></ul></ul><li><a href=#%eb%a6%ac%ec%84%9c%ec%b9%98-%eb%b0%b0%ea%b2%bd aria-label="리서치 배경">리서치 배경</a></li><li><a href=#%ec%82%ac%ec%a0%84-%ec%a7%80%ec%8b%9d aria-label="사전 지식">사전 지식</a><ul><ul><li><a href=#%eb%8f%99%ec%a0%81-%ed%8c%8c%ed%8b%b0%ec%85%94%eb%8b%9d aria-label="동적 파티셔닝">동적 파티셔닝</a></li><li><a href=#%ec%9a%a9%ec%96%b4-%ec%a0%95%ec%9d%98 aria-label="용어 정의">용어 정의</a></li></ul></ul></li><li><a href=#%ea%b5%ac%ed%98%84-%eb%b0%a9%ec%95%88 aria-label="구현 방안">구현 방안</a><ul><li><a href=#broadcast-state aria-label="Broadcast State">Broadcast State</a><ul><li><a href=#broadcast-state%ec%9d%98-%eb%8f%99%ec%9e%91-%ea%b5%ac%ec%a1%b0 aria-label="Broadcast State의 동작 구조"><strong>Broadcast State의 동작 구조</strong></a></li><li><a href=#%ec%a0%81%ed%95%a9%ed%95%9c-%ec%82%ac%ec%9a%a9-%ec%82%ac%eb%a1%80 aria-label="적합한 사용 사례"><strong>적합한 사용 사례</strong></a></li></ul></li><li><a href=#dynamic-data-paritioning aria-label="Dynamic Data Paritioning">Dynamic Data Paritioning</a><ul><li><a href=#keyby%ec%99%80-partitioning aria-label="KeyBy와 Partitioning"><strong>KeyBy와 Partitioning</strong></a><ul><li><a href=#%eb%8b%a4%eb%a5%b8-%ec%a0%95%ec%b1%85-%eb%8f%99%ec%9d%bc-keyby aria-label="다른 정책, 동일 KeyBy">다른 정책, 동일 KeyBy</a></li></ul></li></ul></li><li><a href=#rules-broadcasting aria-label="Rules BroadCasting">Rules BroadCasting</a><ul><li><a href=#broadcasting-flow aria-label="Broadcasting Flow">Broadcasting Flow</a></li><li><a href=#fds-%ec%8b%9c%ec%8a%a4%ed%85%9c%ec%97%90%ec%84%9c%ec%9d%98-%ea%b0%9c%eb%9e%b5%ec%a0%81-%ec%84%a4%ea%b3%84-%eb%b0%a9%ec%95%88 aria-label="FDS 시스템에서의 개략적 설계 방안">FDS 시스템에서의 개략적 설계 방안</a></li></ul></li><li><a href=#custom-window-processing aria-label="Custom Window Processing">Custom Window Processing</a><ul><li><a href=#window-api-%ec%82%ac%ec%9a%a9-%ec%8b%9c-%ec%a0%9c%ec%95%bd-%ec%82%ac%ed%95%ad aria-label="Window API 사용 시 제약 사항">Window API 사용 시 제약 사항</a><ul><li><a href=#tumbling-window-%ec%98%88%ec%99%b8-%ec%bc%80%ec%9d%b4%ec%8a%a4-%ec%98%88%ec%8b%9c aria-label="Tumbling Window 예외 케이스 예시">Tumbling Window 예외 케이스 예시</a></li><li><a href=#sliding-window-%ec%98%88%ec%99%b8-%ec%bc%80%ec%9d%b4%ec%8a%a4-%ec%98%88%ec%8b%9c aria-label="Sliding Window 예외 케이스 예시">Sliding Window 예외 케이스 예시</a></li><li><a href=#%ea%b0%80%ec%9e%a5-%ed%81%b0-%ec%a0%9c%ec%95%bd-%ec%82%ac%ed%95%ad aria-label="가장 큰 제약 사항">가장 큰 제약 사항</a></li></ul></li><li><a href=#custom-window-function-implementation aria-label="Custom Window Function Implementation">Custom Window Function Implementation</a><ul><li><a href=#window-state%ec%97%90-%ec%a0%80%ec%9e%a5%eb%90%a0-%ec%9d%b4%eb%b2%a4%ed%8a%b8%ec%97%90-%eb%8c%80%ed%95%9c-%ea%b3%a0%ec%b0%b0 aria-label="Window State에 저장될 이벤트에 대한 고찰">Window State에 저장될 이벤트에 대한 고찰</a></li><li><a href=#event-retention%ec%97%90-%eb%8c%80%ed%95%9c-%ea%b3%a0%ec%b0%b0 aria-label="Event Retention에 대한 고찰">Event Retention에 대한 고찰</a></li></ul></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><blockquote><h4 id=refs>REFS<a hidden class=anchor aria-hidden=true href=#refs>#</a></h4></blockquote><ul><li><a href=https://brggs.co.uk/blog/broadcast-state-pattern-rules-based-flink/>Rules Based Stream Processing with Apache Flink&rsquo;s Broadcast Pattern</a></li><li><a href=https://flink.apache.org/2020/01/15/advanced-flink-application-patterns-vol.1-case-study-of-a-fraud-detection-system/>Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></li><li><a href=https://aws.amazon.com/ko/blogs/big-data/build-a-dynamic-rules-engine-with-amazon-managed-service-for-apache-flink/>Build a dynamic rules engine with Amazon Managed Service for Apahce Flink</a></li></ul><h1 id=리서치-배경>리서치 배경<a hidden class=anchor aria-hidden=true href=#리서치-배경>#</a></h1><hr><ul><li><code>Window Time</code> 동안 <strong>필터링 조건에 따른 횟수 기반의 탐지 정책을 구축</strong>하는 방안 케이스 스터디가 필요함</li><li><strong>하나의 Job 코드</strong>에서 <strong>모든 정책에 대한 처리 하는 방안</strong>에 대한 리서치가 필요<ul><li>정책 별 인스턴스 할당은 가상화 된 컨테이너를 활용하더라도 리소스 낭비가 심함</li></ul></li><li>정책은 관리자에 의해 수정될 수 있으며, 정책 변경에 따른 재배포를 최소화해야 함</li></ul><h1 id=사전-지식>사전 지식<a hidden class=anchor aria-hidden=true href=#사전-지식>#</a></h1><hr><h3 id=동적-파티셔닝>동적 파티셔닝<a hidden class=anchor aria-hidden=true href=#동적-파티셔닝>#</a></h3><p><code>Kafka</code>는 <code>Event Key</code>를 기반으로 <strong>해싱</strong> 후, <strong>모듈러 연산</strong>을 통해 <strong>파티셔닝</strong> 됨</p><p><code>Kafka Streams</code>, <code>Flink</code>에서 <strong>Event의 Key가 아닌 값으로 group by (keyBy) 할 경우</strong>, <strong>해당 Key를 기준으로 리셔플</strong>이 발생</p><p>(리셔플 발생 시, 네트워크를 통해 <code>Task Manager</code> 간의 데이터 재구성이 진행되며 심각한 오버헤드가 될 수 있음)
<img loading=lazy src=/posts/flink-dynamic-job/image.png></p><p>이를 적절히 해결하기 위해, <strong>동일한 키를 가진 스트림 트랜잭션</strong>이 **같은 작업자(subtask)**에서 <strong>처리</strong>될 수 있도록 구성해야 함</p><p>ex. ) Group By Target이 &ldquo;ID&rdquo; or &ldquo;IP&rdquo; 으로 source에서 미리 두개의 topic으로 발행하는 것도 방법이 됨</p><h3 id=용어-정의>용어 정의<a hidden class=anchor aria-hidden=true href=#용어-정의>#</a></h3><table><thead><tr><th><strong>구성 요소</strong></th><th><strong>설명</strong></th><th><strong>주요 역할</strong></th><th><strong>특징</strong></th></tr></thead><tbody><tr><td><strong>JobManager</strong></td><td>Flink의 중앙 관리 노드로, 작업(Job)의 생명 주기를 관리합니다.</td><td>- 작업 계획 수립 및 분배- ExecutionGraph 생성- Checkpoint 관리 및 장애 복구- 리소스(TaskManager 슬롯) 할당</td><td>- 클러스터당 하나의 JobManager 실행- 모든 작업의 상태와 진행 상황을 모니터링- Checkpoint와 Savepoint를 통해 상태를 저장 및 복구</td></tr><tr><td><strong>TaskManager</strong></td><td>Flink의 작업을 실행하는 워커 노드입니다.</td><td>- SubTask 실행- 네트워크 통신 및 데이터 전송- 상태(State)와 메모리 관리</td><td>- 병렬 처리 단위를 실행하는 물리적 노드- 클러스터 내 여러 TaskManager 존재- 각 TaskManager는 여러 슬롯(Slot)을 가질 수 있으며, 슬롯마다 SubTask 실행</td></tr><tr><td><strong>SubTask</strong></td><td>Flink 작업의 병렬 실행 단위로, TaskManager 내에서 실행됩니다.</td><td>- 파티셔닝된 데이터를 처리- 연산자(Operator)의 로직 실행- 독립적인 상태(State) 관리</td><td>- <code>keyBy</code>를 통해 파티셔닝된 데이터만 처리- 병렬도(parallelism)에 따라 생성- SubTask 간에는 데이터가 공유되지 않으며 독립적으로 작동</td></tr><tr><td><strong>Broadcast</strong></td><td>작은 크기의 데이터 스트림을 모든 SubTask에 복제하여 전달하는 메커니즘입니다.</td><td>- 규칙(Rule) 데이터 전파- 설정 정보 동기화- 컨트롤 메시지 공유</td><td>- Broadcast 데이터를 모든 SubTask에 복사- 일반 데이터 스트림과 결합 가능- 네트워크 부하가 발생할 수 있으므로 작은 크기의 데이터에 적합</td></tr></tbody></table><h1 id=구현-방안>구현 방안<a hidden class=anchor aria-hidden=true href=#구현-방안>#</a></h1><hr><ol><li><code>rule DB</code>의 <code>CDC</code>를 기반으로 <strong>액션 이벤트</strong> + <strong>활성화된 정책 이벤트를 병합</strong>하여 <strong>이벤트 발행</strong><ol><li><strong>액션 이벤트가 1</strong>이고 <strong>활성화된 이벤트가 N</strong>개라면 <strong>총 N개의 병합(액션+정책 정보 포함) 이벤트 발행</strong></li></ol></li><li><code>DynamicKeyFunction</code>을 토대로 <code>source stream</code>에서 <strong>group by에 따라 이벤트를 파티셔닝</strong><ol><li><strong>새로운 keyBy() 조건에 따른 리셔플을 동적으로 처리</strong> → Job 코드 수정 X, 재배포 X</li><li><strong>기존 keyBy() 조건인 경우 기존 TaskSlot에서 처리</strong></li></ol></li><li><code>DynamicEvaluationFunction</code>에서는 소스로부터 데이터를 읽어와 <strong>이벤트가 정책에 부합하는 지 확인</strong>, <strong>정책에 부합한다면 restrict event로 발행</strong></li></ol><h2 id=broadcast-state>Broadcast State<a hidden class=anchor aria-hidden=true href=#broadcast-state>#</a></h2><p>REFS : <a href=https://flink.apache.org/2019/06/26/a-practical-guide-to-broadcast-state-in-apache-flink/>A Practical guid to broadcast state in Flink</a></p><p><code>Broadcast State</code> 는 <strong>하나의 데이터 스트림</strong>을 <strong>다른 데이터 스트림의 모든 작업(Task)에 동일한 상태(State)로 전파</strong>하여 공유할 수 있도록 설계된 기능</p><p>주로 <strong>동일한 설정값이나 기준 데이터를 실시간 업데이트</strong>하여 <strong>다른 데이터와 조합</strong>해 <strong>처리</strong>해야 하는 애플리케이션에서 사용 됨</p><h3 id=broadcast-state의-동작-구조><strong>Broadcast State의 동작 구조</strong><a hidden class=anchor aria-hidden=true href=#broadcast-state의-동작-구조>#</a></h3><ol><li><strong>두 개의 스트림이 필요</strong>:<ul><li><strong>Broadcast Stream</strong>: 이 스트림의 이벤트는 <strong>모든 작업(Task)의 병렬 인스턴스</strong>에 **공유 상태(State)**로 전파됨</li><li><strong>일반 Stream</strong>: 이 스트림의 이벤트는 각 작업의 병렬 인스턴스로 개별적으로 전달됨</li></ul></li><li><strong>이벤트 처리 방식</strong>:<ul><li><code>Broadcast Stream</code>의 이벤트는 <strong>상태로 유지</strong>되어 모든 병렬 작업에서 참조 가능</li><li>일반 Stream의 이벤트는 개별 작업에서 <code>Broadcast Stream</code>의 상태와 함께 처리</li></ul></li></ol><h3 id=적합한-사용-사례><strong>적합한 사용 사례</strong><a hidden class=anchor aria-hidden=true href=#적합한-사용-사례>#</a></h3><ul><li><p><strong>Low Throughput vs High Throughput 스트림 결합</strong>:</p><ul><li><code>Broadcast Stream</code>은 상대적으로 낮은 속도(<code>low throughput</code>)로 동작하며, 이를 일반 스트림(<code>high throughput</code>)과 결합해 효율적으로 처리</li><li><strong>소스 액션 이벤트 스트림</strong>과 <strong>알림 정책</strong>을 <strong>스트림 기반으로 전환하여, 동적으로 결합하여 사용</strong>할 수 있도록 함</li></ul></li><li><p><strong>동적 처리 로직 업데이트</strong>:</p><ul><li><code>Broadcast Stream</code>을 사용해 <strong>처리 로직 또는 기준 데이터</strong>를 실시간으로 업데이트</li><li>정책 변경 시, <code>Broadcast stream</code>으로 정책 정보 전달, 실시간으로 변경된 정책으로 Evaluate</li></ul></li></ul><p><img loading=lazy src=/posts/flink-dynamic-job/image-1.png></p><p><strong>Data Stream</strong> : Source Event (결제 이벤트)</p><p><strong>Broadcast Stream</strong> : 정책 Event (Retention Time은 무제한)</p><ul><li><strong>원본 이벤트</strong> (액션 이벤트)에 <strong>정책 Event</strong>를 <strong>병합</strong>하여 처리</li><li><code>Operator Task</code>는 <code>Broadcast Stream</code> 기반으로 하는 <strong>Broadcast State(K/V Store)</strong> 를 바탕으로 <strong>정책 Evaluate</strong></li></ul><p><img loading=lazy src=/posts/flink-dynamic-job/image-2.png></p><h2 id=dynamic-data-paritioning>Dynamic Data Paritioning<a hidden class=anchor aria-hidden=true href=#dynamic-data-paritioning>#</a></h2><p>REFS : <a href=https://flink.apache.org/2020/01/15/advanced-flink-application-patterns-vol.1-case-study-of-a-fraud-detection-system/>Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></p><p>Production System에서 <strong>runtime에 Job을 재배포할 필요 없이 Rule을 더하거나 지울 수 있도록 시스템을 구현</strong>한다</p><h3 id=keyby와-partitioning><strong>KeyBy와 Partitioning</strong><a hidden class=anchor aria-hidden=true href=#keyby와-partitioning>#</a></h3><ul><li><strong>KeyBy 메서드</strong>:<ul><li>Flink의 <code>keyBy</code> 메서드를 사용하면 스트림의 이벤트에 **키(Key)**를 지정 가능</li><li>같은 키를 가진 이벤트는 <strong>같은 파티션</strong>으로 할당되며, <strong>다음 Operator의 같은 Task</strong>에서 처리됨</li></ul></li><li><strong>Key 지정의 일반적인 패턴</strong>:<ul><li>대부분의 스트리밍 애플리케이션에서는 <strong>키를 정적인 필드</strong>로 고정</li><li>e.g. 유저 로그인(<code>login stream</code>)에서 <code>memberID</code>를 키로 사용해 <strong>윈도우 기반 집계</strong>를 수행</li></ul></li><li><strong>Horizontal Scalability</strong>:<ul><li>정적 키를 사용하면 수평적 확장성(horizontal scalability)을 제공하여 높은 처리량을 지원</li></ul></li></ul><table><thead><tr><th><strong>구분</strong></th><th><strong>정적 키 (Static Key)</strong></th><th><strong>동적 키 (Dynamic Key)</strong></th></tr></thead><tbody><tr><td><strong>정의</strong></td><td>런타임 전에 미리 고정된 필드로 데이터를 그룹화</td><td>런타임 시점에 비즈니스 로직에 따라 동적으로 키를 설정</td></tr><tr><td><strong>설정</strong></td><td>고정된 필드 기반의 <code>keyBy</code> (예: <code>Transaction::getAccountId</code>).</td><td>JSON이나 Rule 엔진과 같은 외부 설정으로 키를 구성(예: <code>groupingKeyNames</code> 필드에서 동적으로 결정)</td></tr><tr><td><strong>유연성</strong></td><td>비즈니스 로직 변경에 대응하기 어려움</td><td>비즈니스 요구사항 변화에 따라 키 설정을 변경 가능</td></tr><tr><td><strong>구현 난이도</strong></td><td>단순하고 구현하기 쉬움</td><td>상대적으로 복잡하며, 런타임 시 Rule 파싱 및 키 설정 로직 추가 필요</td></tr><tr><td><strong>성능</strong></td><td>최적화에 유리하며, 실행 시 오버헤드가 적음</td><td>키 계산 로직 및 유연성으로 인해 약간의 추가 성능 오버헤드 발생</td></tr><tr><td><strong>적용 사례</strong></td><td>- Account ID 기반 그룹화- 동일 IP 기반 집계- 사용자별 활동 추적</td><td>- 다양한 필드 기반 그룹화 (예: 송신자, 수신자)- 조건에 따라 동적으로 그룹화- Rule 기반 실시간 처리</td></tr><tr><td><strong>장점</strong></td><td>- 구현 및 유지보수가 용이- 성능 최적화에 유리- 단순한 집계 작업에 적합</td><td>- 복잡한 비즈니스 로직을 처리 가능- 유연하고 확장성이 높음- 다양한 Use Case에 적합</td></tr><tr><td><strong>단점</strong></td><td>- 복잡한 요구사항을 처리하기 어려움- 비즈니스 변화 시 재배포 필요</td><td>- 구현이 복잡하고 런타임 오버헤드 발생- 실수로 인해 키 설정 오류 발생 가능</td></tr><tr><td>셔플이 발생하지 않도록, 정책에 따라 생성된 <strong>SubTask</strong>가 <strong>동일한 KeyedStream</strong>을 사용할 수 있도록 한다</td><td></td><td></td></tr></tbody></table><p>Static 하게 지정된 Key가 아닌 정책에 따라 동적으로 <code>KeyedStream</code>을 생성하거나 재사용하도록 구성하는 방안</p><blockquote><p><strong>성능</strong>이나 <strong>코드파악</strong>에서는 <strong>하드코딩된 명시적인 Key</strong>가 관리하기엔 용이할 수 있다. 하지만, <strong>지속가능한 아키텍처</strong>를 구현하기 위해서 어느정도의 <strong>TradeOff를 감수</strong>하고 동적 키 파티셔닝을 구현하는 것임</p></blockquote><p><img loading=lazy src=/posts/flink-dynamic-job/image-3.png>
*T : Transaction (결제 이벤트를 의미)</p><p><strong>T1_Rule1, T1_Rule2, T1_Rule3</strong> 는 <strong>Flink SubTask</strong>를 의미</p><p>각각은 <strong>groupingKey</strong> (keyBy)에 따라 셔플링되어 각 <strong>네트워크를 통해 SubTask</strong>로 <strong>전달</strong></p><blockquote><h4 id=다른-정책-동일-keyby>다른 정책, 동일 KeyBy<a hidden class=anchor aria-hidden=true href=#다른-정책-동일-keyby>#</a></h4></blockquote><p>정책 Evaluate 조건은 다를지라도 <code>Group By</code>하는 <strong>Key가 같을 경우</strong>, <strong>동일 SubTask 내에서 정책 평가</strong>를 진행</p><blockquote></blockquote><p><strong>동일 SubTask</strong>에 <strong>여러 정책</strong>을 Evaluate 할 경우, <strong>SubTask 내부에서 순차적으로 정책 평가</strong>를 진행</p><blockquote></blockquote><p><strong>병렬도를 늘리고 싶다면</strong> 소스이벤트의 다른 필드를 키로 하여 <strong>파티션</strong>을 나눌수 있겠지만 그만큼 <strong>셔플링으로 인한 오버헤드</strong>가 발생됨</p><p><img loading=lazy src=/posts/flink-dynamic-job/image-4.png></p><p>정책을 동적으로 만들 수 있는 파라미터 정의</p><table><thead><tr><th>필드명</th><th>설명</th><th>예시</th></tr></thead><tbody><tr><td>RuleID</td><td>정책 고유 ID</td><td>78, 889</td></tr><tr><td>Aggregation Field</td><td>집계 결과가 저장되는 필드 명</td><td>id_count, hpid_count</td></tr><tr><td>Grouping Fields</td><td>집계할 필드</td><td>ID, IP</td></tr><tr><td>Aggregation Function</td><td>집계 연산</td><td>sum, count, avg</td></tr><tr><td>Window Duration</td><td>집계 기간</td><td>10m, 10s, 90d</td></tr><tr><td>Limit</td><td>임계치</td><td>3, 5</td></tr><tr><td>Limit Operator</td><td>임계치 연산자</td><td>gt, lt, equal</td></tr><tr><td>Filter</td><td>필터링 조건</td><td>{ &ldquo;filter_option&rdquo;: &ldquo;option_value&rdquo;}</td></tr></tbody></table><p>e.x &ldquo;정책 2: 로그인 단계에서 3분 이내에 동일 ID의 서로 다른 IP가 4개 초과인 경우 알림&rdquo;</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ruleId&#34;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ruleState&#34;</span><span class=p>:</span> <span class=s2>&#34;ACTIVE&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;groupingKeyNames&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;id&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;aggregateFieldName&#34;</span><span class=p>:</span> <span class=s2>&#34;ip&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;aggregatorFunctionType&#34;</span><span class=p>:</span> <span class=s2>&#34;UNIQUE_COUNT&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;filter&#34;</span> <span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;action&#34;</span><span class=p>:</span> <span class=s2>&#34;login&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span><span class=err>.</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;limitOperatorType&#34;</span><span class=p>:</span> <span class=s2>&#34;gt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;limit&#34;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;windowMinutes&#34;</span><span class=p>:</span> <span class=s2>&#34;3m&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=rules-broadcasting>Rules BroadCasting<a hidden class=anchor aria-hidden=true href=#rules-broadcasting>#</a></h2><p>REFS : <a href=https://flink.apache.org/2020/03/24/advanced-flink-application-patterns-vol.2-dynamic-updates-of-application-logic/>Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic</a></p><p>앞서 설명한 **DynamicKeyFunction()**은 <strong>데이터를 동적으로 파티셔닝</strong>하여 셔플링으로 인한 오버헤드를 최소화
<strong>DynamicEvaluationFunction()</strong> 은 정책에 따른 평가를 수행하는 데이터를 의미</p><p>컴파일 되기 전에 미리 Rules 를 List로 읽어와 실행하는 것은 가능하다</p><p>하지만  컴파일 된 후, 정책 변경 시에 결코 동적으로 정책에 따른 SubTask Operator를 동작 시킬 수 없다</p><p>이를 해결하기 위해 <code>Rules Broadcasting</code>을 구현
<code>Source Topic</code>으로 부터 액션 이벤트를 받아오고, <code>Rule Source</code>를 <code>Broadcast</code>로 <strong>병합</strong>하여 <strong>정책 평가</strong></p><p>만약! 정책 DB가 <strong>Soft Delete</strong> 이라면 CDC의 <strong>disabled 컬럼을 통해</strong> <strong>rule_id operator를 드롭</strong>하도록 한다
신규 추가된 정책은 새롭게 <code>operator task</code>로 생성한다</p><h3 id=broadcasting-flow>Broadcasting Flow<a hidden class=anchor aria-hidden=true href=#broadcasting-flow>#</a></h3><p><img loading=lazy src=/posts/flink-dynamic-job/image-5.png></p><table><thead><tr><th><strong>항목</strong></th><th><strong>설명</strong></th></tr></thead><tbody><tr><td><strong>Payment Event Source</strong></td><td>병렬적으로 Kafka 파티션에서 이벤트를 컨슘.</td></tr><tr><td><strong>Dynamic Key Function</strong></td><td><code>DynamicKeyFunction()</code>을 통해 병렬 Task로 파티셔닝. 지정된 키에 따라 복합키 또는 단일키를 해싱하여 네트워크로 데이터 전송</td></tr><tr><td><strong>Dynamic Evaluation Function</strong></td><td>- 필터링 조건에 따라 <strong>Data Window</strong>를 상태 저장소(State Backend)에 저장- 임계치를 초과하면 Sinking 처리</td></tr><tr><td><strong>Restriction Topic</strong></td><td>제재(Restriction) Topic으로 제재 정보를 포함하여 발행</td></tr></tbody></table><p>*<strong>병렬도</strong>는 부하 테스트를 통해 Consumer Lag을 최소화하는 병렬도 산정</p><p><img loading=lazy src=/posts/flink-dynamic-job/image-6.png></p><ul><li>Rule DB의 CDC는 <strong>Broadcast Channel</strong>을 통해 <strong>main processing data flow</strong>에 <strong>병합</strong> 됨</li><li><strong>Broadcast</strong>는 <strong>각 메시지를</strong> <strong>모든 병렬 인스턴스로 뿌림</strong> (key나 source 파티션에 관계없이 모두 전달됨)</li></ul><h3 id=fds-시스템에서의-개략적-설계-방안>FDS 시스템에서의 개략적 설계 방안<a hidden class=anchor aria-hidden=true href=#fds-시스템에서의-개략적-설계-방안>#</a></h3><p><img loading=lazy src=/posts/flink-dynamic-job/image-7.png></p><ul><li><strong>processBroadcastElement:</strong> Broadcast source stream의 이벤트 발생 시 트리거 됨<ul><li><strong>CDC 로 기존 정책 remove + 새로운 정책 insert</strong></li></ul></li><li><strong>processElement:</strong> Source stream의 이벤트 발생 시 트리거 됨<ul><li>현재 활성화된 정책들을 불러와 활성화된 조건 마다 Rule 조건 + Payment 이벤트를 병합한 이벤트를 발행</li><li>정책 별 <code>group by</code> 조건에 따라 파티셔닝 됨 (<code>keyBy</code>)</li></ul></li></ul><p><code>Broadcast Stream</code> 에서 읽어온 데이터는 <code>Broadcast State (K/V map)</code>에 상태를 저장한다</p><p><code>Broadcast Stream</code>에 새로운 메시지가 도착하면 <strong>processBroadcastElement()</strong> 가 호출된다</p><p>해당 class를 상속하는 <code>DynamicKeyFunction</code>을 구현하면 <strong>runtime에 분산 키를 수정</strong>할 수 있다</p><h2 id=custom-window-processing>Custom Window Processing<a hidden class=anchor aria-hidden=true href=#custom-window-processing>#</a></h2><p>REFS : <a href=https://flink.apache.org/2020/07/30/advanced-flink-application-patterns-vol.3-custom-window-processing/>Advanced Flink Application Patterns Vol.3: Custom Window Processing</a></p><p>Flink에서는 다양한 유즈케이스에 맞춘 Window API를 제공함</p><table><thead><tr><th>종류</th><th>설명</th><th>사용 예시</th></tr></thead><tbody><tr><td><strong>Tumbling Window</strong></td><td>- <strong>고정된 간격</strong>으로 데이터를 그룹화- 각 윈도우는 겹치지 않고 연속적으로 이어짐</td><td>- <code>timeWindow(Time.minutes(1))</code>- 1분마다 평균, 합계 등의 집계 처리</td></tr><tr><td><strong>Sliding Window</strong></td><td>- <strong>고정된 크기</strong>의 윈도우가 <strong>겹치며 이동</strong>.- 슬라이드 간격(<code>slide</code>)에 따라 중복된 데이터를 처리할 수 있음</td><td>- <code>timeWindow(Time.minutes(1), Time.seconds(30))</code>- 1분 윈도우, 30초 간격으로 이동하며 집계 처리.</td></tr><tr><td><strong>Session Window</strong></td><td>- 데이터가 **활동 간격(session gap)**에 따라 윈도우가 시작되고 종료됨.- 활동 간 데이터가 없는 경우 윈도우가 닫히고 결과 출력.</td><td>- <code>sessionWindow(Time.minutes(5))</code>- 유저별 활동 세션 분석.</td></tr></tbody></table><p>이 중, 고려해볼 Window는 <strong>Tumbling</strong>과 <strong>Sliding</strong> Window</p><h3 id=window-api-사용-시-제약-사항>Window API 사용 시 제약 사항<a hidden class=anchor aria-hidden=true href=#window-api-사용-시-제약-사항>#</a></h3><table><thead><tr><th>유형</th><th>Tumbling Window</th><th>Sliding Window</th></tr></thead><tbody><tr><td>정책 예시</td><td><strong>Time Window동안 동일 이벤트가 6번 발생하면 제재한다</strong></td><td><strong>Time Window동안 동일 이벤트가 4번 발생하면 제재한다 가정</strong></td></tr><tr><td>제약사항</td><td>Tumbling Window는 고정된 간격으로 겹치지 않게 이어지기 때문에 탐지할 수 없음</td><td>슬라이드 간격에 따라 <strong>중복된 데이터가 처리됨</strong>, Sliding 간격을 촘촘히 하더라도 정확한 탐지가 불가능</td></tr></tbody></table><h4 id=tumbling-window-예외-케이스-예시>Tumbling Window 예외 케이스 예시<a hidden class=anchor aria-hidden=true href=#tumbling-window-예외-케이스-예시>#</a></h4><p><img loading=lazy src=/posts/flink-dynamic-job/image-8.png></p><h4 id=sliding-window-예외-케이스-예시>Sliding Window 예외 케이스 예시<a hidden class=anchor aria-hidden=true href=#sliding-window-예외-케이스-예시>#</a></h4><p><img loading=lazy src=/posts/flink-dynamic-job/image-9.png></p><h4 id=가장-큰-제약-사항>가장 큰 제약 사항<a hidden class=anchor aria-hidden=true href=#가장-큰-제약-사항>#</a></h4><p><img loading=lazy src=/posts/flink-dynamic-job/image-10.png></p><p>Flink API의 <a href=https://nightlies.apache.org/flink/flink-docs-release-1.11/dev/stream/operators/windows.html#sliding-windows>sliding window</a> example을 보면, <strong>slide S인 sliding window</strong>를 쓰면, <strong>S/2 만큼의 evaluation delay</strong>가 생기게 된다</p><p>윈도우 API의 트리거는 <strong>윈도우의 종료 시점에 실행</strong>되며, <strong>종료 시점까지는 Delay가 필연적</strong>으로 발생한다</p><p>→ <strong>Fraud Detection Delay</strong> 동안 <strong>어뷰저의 Negative action</strong>을 방치하므로 <strong>회사의 손실</strong>을 야기시킨다</p><h3 id=custom-window-function-implementation>Custom Window Function Implementation<a hidden class=anchor aria-hidden=true href=#custom-window-function-implementation>#</a></h3><p><code>DynamicEvaluationFunction()</code>에 대한 구현
<img loading=lazy src=/posts/flink-dynamic-job/image-11.png></p><ol><li><strong>Consume Event:</strong> Source로 부터 이벤트를 가져옴<ol><li><code>DynamicKeyFunction</code>에 따라, 정책 정보 + 액션 이벤트가 함께 이벤트에 포함됨</li></ol></li><li><strong>Add Event:</strong> 이벤트를 집계하기 위해 상태 저장소에 현재 이벤트 저장</li><li><strong>Get Rule:</strong> <code>Broadcast State</code>로 부터 현재 활성화된 정책 불러오기<ol><li>만약 정책이 <strong>존재하지 않는다면 비활성화된 정책</strong>임 (처리할 필요 X return)</li></ol></li><li><strong>Rule Condition Check:</strong> 현재 이벤트가 필터링 조건에 부합하는지 체크<ol><li>부합하지 않는다면 return</li></ol></li><li><strong>Get Window States:</strong> 이벤트 시간 기준으로 정책에 등록된 duration 동안 정책을 만족하는 이벤트 집계</li><li><strong>Produce Restrict Topic:</strong> 집계된 결과가 정책을 만족하면 다음 <code>Enforcement Topic</code>으로 발행</li><li><strong>Cleanup:</strong> Retention 기간이 만료된 이벤트 제거</li></ol><h4 id=window-state에-저장될-이벤트에-대한-고찰>Window State에 저장될 이벤트에 대한 고찰<a hidden class=anchor aria-hidden=true href=#window-state에-저장될-이벤트에-대한-고찰>#</a></h4><p>이벤트는 <code>source</code>가 되는 이벤트의 <strong>발행 시점 timestamp</strong>를 갖게 된다
파티셔닝은 <code>group by</code> 조건에 따라 발생되기에 <strong>동일한 timestamp를 가진 이벤트</strong>가 <strong>여러개</strong>가 <strong>발생</strong>될 수 있다
<strong>중복 적재가 되더라도 무관한 자료구조인 Set을 활용</strong>하는 것이 바람직. Key는 timestamp</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>MapState</span><span class=o>&lt;</span><span class=n>Long</span><span class=p>,</span><span class=w> </span><span class=n>Set</span><span class=o>&lt;</span><span class=n>PaymentEvent</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=n>windowState</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><blockquote><p>상태 저장소는 Key Value Store이기 때문에 List Type을 사용할 수 없다</p></blockquote><p>필연적으로 모든 Map의 timestamp를 순회하면서 만족하는 값을 찾아야 하는데&mldr;</p><blockquote></blockquote><p>이 부분에 대한 리서치는 조금 더 필요할 듯
event 전체를 순회하는게 아니라 timestamp만 순회하여 메모리는 크게 이슈가 되지 않을듯 (다만 loop 동안 CPU가 괜찮을까..?)</p><h4 id=event-retention에-대한-고찰>Event Retention에 대한 고찰<a hidden class=anchor aria-hidden=true href=#event-retention에-대한-고찰>#</a></h4><p><img loading=lazy src=/posts/flink-dynamic-job/image-12.png>
보관 기간 즉, Event의 TTL을 어떻게 잡을 것인가 ?</p><p><strong>DynamicEvaluationFunction()</strong> 에서는 같은 key scope를 가지는 결제 이벤트를 받을 수 있지만, 다른 Rule에 의해 evaluate되고, 다른 길이의 time window를 가질 수 있다</p><p>그렇기에 <code>Rule Stream (Broadcast Stream)</code>에서 <strong>이벤트를 컨슈밍하는 시점</strong>에서 <strong>가장 긴 Duration을 업데이트</strong>할 수 있도록 한다</p><p>ex. <code>UpdateWidestWindow</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Override</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>public</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>processBroadcastElement</span><span class=p>(</span><span class=n>Rule</span><span class=w> </span><span class=n>rule</span><span class=p>,</span><span class=w> </span><span class=n>Context</span><span class=w> </span><span class=n>ctx</span><span class=p>,</span><span class=w> </span><span class=n>Collector</span><span class=o>&lt;</span><span class=n>Alert</span><span class=o>&gt;</span><span class=w> </span><span class=n>out</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>updateWidestWindowRule</span><span class=p>(</span><span class=n>rule</span><span class=p>,</span><span class=w> </span><span class=n>boradcastState</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>private</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>updatWidestWindowRule</span><span class=p>(</span><span class=n>Rule</span><span class=w> </span><span class=n>rule</span><span class=p>,</span><span class=w> </span><span class=n>BoradcastState</span><span class=o>&lt;</span><span class=n>Integer</span><span class=p>,</span><span class=w> </span><span class=n>Rule</span><span class=o>&gt;</span><span class=w> </span><span class=n>broadcastState</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Rule</span><span class=w> </span><span class=n>widestWindowRule</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>broadcastState</span><span class=p>.</span><span class=na>get</span><span class=p>(</span><span class=n>WIDEST_RULE_KEY</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>widestWindowRule</span><span class=w> </span><span class=o>==</span><span class=w> </span><span class=kc>null</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>broadcastState</span><span class=p>.</span><span class=na>put</span><span class=p>(</span><span class=n>WIDEST_WRULE_KEY</span><span class=p>,</span><span class=w> </span><span class=n>rule</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>widestWindowRule</span><span class=p>.</span><span class=na>getWindowMillis</span><span class=p>()</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>rule</span><span class=p>.</span><span class=na>getWindowMillis</span><span class=p>())</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>broacastState</span><span class=p>.</span><span class=na>put</span><span class=p>(</span><span class=n>WIDEST_RULE_KEY</span><span class=p>,</span><span class=w> </span><span class=n>rule</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>즉 <code>Dynamic Evaluation</code>에서는 가장 Duration이 긴 정책을 기반으로 Event의 TTL을 지정한다</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/tags/flink/>Flink</a></li><li><a href=https://dingyu.dev/tags/apache/>Apache</a></li><li><a href=https://dingyu.dev/tags/fds/>Fds</a></li><li><a href=https://dingyu.dev/tags/dynamic-job/>Dynamic Job</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/posts/es-to-loki/><span class=title>« Prev</span><br><span>[LGTM] Elasticsearch to Loki 전환기</span>
</a><a class=next href=https://dingyu.dev/posts/gopher-con-2024-minimalistic-go/><span class=title>Next »</span><br><span>[Go] Gophercon 2024 - Building Minimalistic Backend Microservice in Go</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기 | Ding's Coding Forge</title>
<meta name=keywords content="kafka,sasl,bitnami,kafka ui,local test"><meta name=description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/posts/local-sasl-kafka/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.ba0de23ad40e17ca82720b577f8ae6ec11a26fb07407316cff70888e344ad129.css integrity="sha256-ug3iOtQOF8qCcgtXf4rm7BGib7B0BzFs/3CIjjRK0Sk=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dingyu.dev/posts/local-sasl-kafka/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/posts/local-sasl-kafka/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기"><meta property="og:description" content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-28T00:00:00+00:00"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Sasl"><meta property="article:tag" content="Bitnami"><meta property="article:tag" content="Kafka Ui"><meta property="article:tag" content="Local Test"><meta property="og:image" content="https://dingyu.dev/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/posts/local-sasl-kafka/img/kafka.png"><meta name=twitter:title content="[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기"><meta name=twitter:description content="This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/posts/"},{"@type":"ListItem","position":2,"name":"[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기","item":"https://dingyu.dev/posts/local-sasl-kafka/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기","name":"[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기","description":"This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure.","keywords":["kafka","sasl","bitnami","kafka ui","local test"],"articleBody":"Local SASL Mechanism Kafka Docker compose 구성하기 Kafka를 사용하는 서비스에서 인증 방식이 SASL 기반이라면, 로컬에서도 유사한 인증 환경을 구성할 수 있어야 한다. 이 글에서는 로컬 환경에서 SCRAM-SHA-256, SCRAM-SHA-512를 동시에 지원하는 Kafka 클러스터를 구성하고, 이를 기반으로 Event Dispatcher 애플리케이션을 테스트할 수 있는 인프라 환경을 구축한 내용을 정리했다.\nSASL과 TLS의 경우 레퍼런스를 찾기 매우매우 힘들었다… 삽질하는 참에 추후 고생할 나에게 선물을 마련하고자 로컬 환경 SASL Kafka 구성하기를 기록한다\nTLS는 인증서 Makefile 등 너무 복잡하여 추후에 시간이 될 때 포스팅하는것으로..\n구성 목표 Event Dispatcher는 source Kafka에서 이벤트를 consume하고, 이벤트 형태에 따라 분류하여 다른 dest Kafka로 produce하는 구조를 갖는다. source Kafka와 dest Kafka는 서로 다른 클러스터가 아닌, 동일한 클러스터 내에서 다른 SASL 인증 메커니즘을 통해 구분한다. source Kafka는 SCRAM-SHA-256 기반 인증을 사용하고, dest Kafka는 SCRAM-SHA-512 기반 인증을 사용한다. 테스트 환경에서도 코드 수정 없이 실제 운영 환경과 유사한 구조를 구축하는 것이 목표였다. ISR(in-sync replicas)을 2로 두기 위해 Kafka 브로커는 3노드로 구성했다. Kafka UI를 통해 produce 테스트가 가능해야 하며, 이를 통해 애플리케이션의 동작 확인도 가능하도록 한다. 로컬 환경 구성을 고려하게 된 이유 개발 서버에서 테스트 시 스택 트레이스 확인이 어려워 디버깅이 불편했으며, Bastion(보안용 게이트웨이) 사용을 위한 VPN 및 SSH 접근이 상대적으로 피로감을 느끼게 했다 사내 Kafka는 모두 SASL 인증 기반이므로 공통 설정을 만들어두면 다양한 프로젝트에 활용할 수 있다. 설정 값을 테스트할 때 코드 수정과 DEV 환경 배포 없이 변경 가능해야 했다. (트랜잭션 설정, exactly-once, ISR 등) 코드 레벨 수정 없이 테스트하려면 로컬 인프라 구성이 필요했다. Docker Compose 기반 환경 구성 version: '3.9' networks: kafka_network: volumes: kafka_data_0: kafka_data_1: kafka_data_2: services: zookeeper: image: bitnami/zookeeper:3.8.1 container_name: zookeeper environment: - ALLOW_ANONYMOUS_LOGIN=yes ports: - '2181:2181' networks: - kafka_network kafka-0: image: bitnami/kafka:3.7.0 container_name: kafka-0 depends_on: - zookeeper ports: - '${KAFKA_BROKER_0_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_0_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_0:/bitnami/kafka networks: - kafka_network hostname: kafka kafka-1: image: bitnami/kafka:3.7.0 container_name: kafka-1 depends_on: - zookeeper ports: - '${KAFKA_BROKER_1_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_1_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_1:/bitnami/kafka networks: - kafka_network hostname: kafka-1 kafka-2: image: bitnami/kafka:3.7.0 container_name: kafka-2 depends_on: - zookeeper ports: - '${KAFKA_BROKER_2_PORT}:9092' environment: KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CFG_LISTENERS: SASL_PLAINTEXT://:9092 KAFKA_CFG_ADVERTISED_LISTENERS: SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT KAFKA_CFG_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT KAFKA_CFG_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512,SCRAM-SHA-256 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512 KAFKA_CLIENT_USERS: ${512_SASL_USER},${256_SASL_USER} KAFKA_CLIENT_PASSWORDS: ${512_SASL_PASSWORD},${256_SASL_PASSWORD} KAFKA_INTER_BROKER_USER: ${512_SASL_USER} KAFKA_INTER_BROKER_PASSWORD: ${512_SASL_PASSWORD} volumes: - kafka_data_2:/bitnami/kafka networks: - kafka_network hostname: kafka-2 kafka-ui: image: provectuslabs/kafka-ui:latest container_name: kafka-ui depends_on: - kafka-0 ports: - '8080:8080' environment: KAFKA_CLUSTERS_0_NAME: Local-Zookeeper-Cluster KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: SCRAM-SHA-512 KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${512_SASL_USER}\" password=\"${512_SASL_PASSWORD}\"; networks: - kafka_network # user 정보가 broker에 저장이 되어야 정상적으로 시작될 수 있음 your-app: env_file: - .env build: context: . dockerfile: dev.Dockerfile args: - VERSION=dev environment: - BOOTSTRAP_SERVERS_256=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} - BOOTSTRAP_SERVERS_512=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT} image: your-app container_name: your-app networks: - kafka_network restart: always depends_on: - kafka-0 - kafka-1 - kafka-2 어쨰서 bitnami? 환경 변수 기반의 간편한 사용자 등록 Bitnami Kafka는 다음과 같은 환경 변수만 설정하면 자동으로 SASL 사용자 등록을 수행 KAFKA_CLIENT_USERS=user256,user512 KAFKA_CLIENT_PASSWORDS=pass256,pass512 이는 일반 Kafka 공식 이미지에서는 수동으로 kafka-configs.sh 스크립트를 실행하거나 custom entrypoint를 만들어야 가능!\nex.\nbash -c ' /opt/bitnami/scripts/kafka/setup.sh \u0026\u0026 kafka-configs.sh --zookeeper zookeeper:2181 --alter \\ --add-config \"SCRAM-SHA-512=[iterations=8192,password=pass]\" \\ --entity-type users --entity-name user \u0026\u0026 /opt/bitnami/scripts/kafka/run.sh' Bitnami는 컨테이너 기동 시점에 사용자 등록 로직을 자동 수행해줘서 훨씬 편리\nSASL 설정 및 Zookeeper 연동이 기본 내장 Bitnami는 다음 설정들을 Docker 환경변수로 설정 가능 KAFKA_CFG_SASL_ENABLED_MECHANISMS KAFKA_CFG_LISTENER_NAME__SASL_ENABLED_MECHANISMS KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL 즉, 복잡한 server.properties 없이도 docker-compose.yml만으로 SASL 클러스터 구성 가능!\n환경변수 설명 사용처 KAFKA_CFG_ZOOKEEPER_CONNECT Kafka가 사용할 Zookeeper의 주소 (host:port) Kafka가 Zookeeper 기반으로 클러스터 메타데이터를 저장/공유하기 위해 필요함 KAFKA_CFG_LISTENERS 브로커가 어떤 프로토콜과 포트로 외부 연결을 수신할지 설정 (ex: SASL_PLAINTEXT://:9092) 클라이언트 또는 브로커 간 통신을 어떤 방식으로 받을지 정의함 KAFKA_CFG_ADVERTISED_LISTENERS 브로커가 클라이언트에게 자신을 알릴 때 사용하는 주소 (host.docker.internal:${PORT}) Kafka 클라이언트가 브로커에 접속할 때 사용할 외부 IP 또는 호스트명과 포트 정보를 제공함 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP 각 리스너 이름에 대해 사용할 보안 프로토콜을 매핑 (ex: SASL_PLAINTEXT:SASL_PLAINTEXT) 리스너 이름과 보안 프로토콜을 매칭하여 SASL 인증을 활성화하기 위해 사용 KAFKA_CFG_INTER_BROKER_LISTENER_NAME 브로커 간 통신에 사용할 리스너 이름 클러스터 내의 브로커 간 통신을 어떤 리스너(인증 방식)로 할지 지정함 KAFKA_CFG_SASL_ENABLED_MECHANISMS Kafka에서 허용할 SASL 인증 메커니즘 목록 (ex: SCRAM-SHA-512,SCRAM-SHA-256) Kafka 클라이언트와 브로커 간 인증에 사용할 수 있는 SASL 방식들을 정의함 KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL 브로커 간 통신에서 사용할 SASL 인증 메커니즘 브로커들끼리 통신 시 어떤 SCRAM 알고리즘으로 인증할지 설정함 KAFKA_CLIENT_USERS SASL 인증에 사용할 사용자 목록 (쉼표로 구분) Kafka 사용자 등록을 위해 필요하며, 각 사용자마다 비밀번호가 필요함 KAFKA_CLIENT_PASSWORDS 사용자 목록에 대응되는 비밀번호 목록 (쉼표로 구분) 위의 사용자 각각에 대응되는 비밀번호를 정의하여 Kafka 서버에 등록함 KAFKA_INTER_BROKER_USER 브로커 간 통신에서 사용할 사용자 이름 브로커들끼리 SCRAM 인증을 위해 사용하는 사용자 지정 KAFKA_INTER_BROKER_PASSWORD 브로커 간 통신에 사용할 사용자의 비밀번호 위의 사용자와 함께 브로커 간 인증을 위해 사용됨 해당 환경은 다음의 구성 요소로 이루어진다:\nBitnami Kafka 3노드 클러스터 (SCRAM-SHA-256, SCRAM-SHA-512 동시 지원) Zookeeper Kafka UI (관리 및 테스트 용도) Event Dispatcher 애플리케이션 (Kafka Consumer/Producer) .env와 파일을 구성한 후, 다음 명령어로 전체 인프라를 실행할 수 있다\ndocker compose --env-file .env up --build 종료 및 클러스터 초기화를 위해서는 아래 명령어를 사용한다:\ndocker compose down -v .env example:\n256_SASL_USER=user256 256_SASL_PASSWORD=pass256 512_SASL_USER=user512 512_SASL_PASSWORD=pass512 # Kafka Settings KAFKA_BROKER_0_PORT=9092 KAFKA_BROKER_1_PORT=9093 KAFKA_BROKER_2_PORT=9094 구성 세부 내용 요약 아래 다이어그램은 로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름을 정리한 것이다. 내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 이해할 수 있다. 각 단계는 실제 로그 흐름에 기반하여 순서대로 설명하였다.\n1. Zookeeper 초기화 Zookeeper 컨테이너가 standalone 모드로 기동되며 Kafka 브로커의 메타데이터 저장소로 동작한다. 사용자 정보 등록은 Zookeeper가 직접 수행하지 않으며, Kafka 브로커가 기동 시 KAFKA_CLIENT_USERS, KAFKA_CLIENT_PASSWORDS 환경변수를 통해 SCRAM 사용자 정보를 자동으로 등록한다. Zookeeper 컨테이너가 standalone 모드로 기동되며 사용자 정보를 등록할 준비를 한다. user256 (SCRAM-SHA-256), user512 (SCRAM-SHA-512)에 대한 사용자 정보가 Zookeeper에 등록된다. 2. Kafka 브로커 기동 및 Zookeeper 연결 Kafka 브로커 3개(kafka-0, kafka-1, kafka-2)가 순차적으로 Zookeeper와 연결을 시도한다. 연결이 완료되면 각 브로커는 controller 선출에 참여하고, request 처리 준비가 완료되었음을 로그로 출력한다. 3. Controller 동작 Kafka 클러스터 내에서 한 브로커가 controller로 선출된다. controller는 각 브로커의 상태를 확인하고, 토픽 메타데이터를 동기화하며, Partition 할당과 Leader 선출을 수행한다. 내부적으로 LeaderAndIsr, UpdateMetadataRequest 등의 메시지를 각 브로커에 전파하며 클러스터 상태를 안정화시킨다. 4. Kafka UI 연결 Kafka UI는 SASL-SHA-512 사용자(user512)를 이용해 Kafka 브로커에 AdminClient로 연결한다. 인증 후 topic 목록 조회 및 메시지 produce 테스트를 수행한다. 5. Event Dispatcher 연결 Event Dispatcher는 source Kafka에 SCRAM-SHA-256 방식(user256)으로 Consumer 연결을 시도하고 consume을 시작한다. 이후 dest Kafka에는 SCRAM-SHA-512 방식(user512)으로 Producer 연결하여 메시지를 produce한다. 전체 시퀀스 다이어그램 로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름은 다음과 같다\n내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 확인해보자!\nKafka 클러스터는 Zookeeper 기반이며, 3개의 브로커로 구성 SCRAM-SHA-256을 사용하는 user256과 SCRAM-SHA-512를 사용하는 user512가 생성 Kafka UI를 통해 user512 인증으로 접근하여 메시지를 직접 produce 가능 Event Dispatcher는 SASL 256/512 User/Password 설정을 기반으로 source/dest Kafka 각각 다른 인증 방식으로 접근하여 동작한다. 트러블슈팅 및 해결 과정 Kafka SASL 인증 기반 환경을 처음부터 구성하다 보면 여러 트러블을 겪게 된다. 실제 테스트 환경에서 마주쳤던 문제와 그에 대한 해결 과정을 아래에 정리했다.\n1. KAFKA_CFG_ADVERTISED_LISTENERS 설정 오류 초기 구성 시 KAFKA_CFG_ADVERTISED_LISTENERS 값을 잘못 설정하여 Kafka UI 및 Event Dispatcher에서 브로커 접근에 실패했다. localhost로 설정할 경우 Docker 내부의 컨테이너 외부에서는 Kafka 브로커에 접근할 수 없었다.\n현상:\nKafka UI 또는 Event Dispatcher가 브로커와 통신할 수 없음 connection refused 또는 EOF 에러 발생 해결 방법:\nlocalhost 대신 host.docker.internal 또는 실제 호스트 IP로 설정 .env 또는 compose 파일 내 브로커 설정 확인 KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092 2. 서로 다른 SASL 메커니즘을 가진 사용자 인증 실패 Kafka 클러스터 하나에서 SCRAM-SHA-256, SCRAM-SHA-512를 동시에 지원하게끔 설정했지만, 사용자 등록이 제대로 되지 않아 인증에 실패했다.\n현상:\nKafka UI는 인증에 성공하나, Event Dispatcher는 EOF 또는 인증 실패 Kafka 로그에 Failed to authenticate user 메시지 출력 해결 방법:\nKafka 초기화 스크립트에서 사용자 추가 시 --mechanism 플래그 명확히 지정 사용자 등록 확인을 위해 Kafka 실행 로그 확인 또는 kafka-configs.sh 이용해 확인 --entity-type users --entity-name user512 --alter --add-config 'SCRAM-SHA-512=[iterations=4096,password=pass512]' 추후에는 Broker에서 직접 실행할 필요가 없었음을 느끼고 KAFKA_CLIENT_USERS, KAFKA_CLIENT_PASSWORDS 설정! 3. Kafka UI를 통한 produce가 동작하지 않음 Kafka UI를 통해 메시지를 produce할 수 있어야 Event Dispatcher의 consume 확인이 가능하지만, 인증 실패나 메타데이터 조회 실패로 UI가 제대로 동작하지 않았다.\n현상:\nUI 상에서 produce 시도했지만 메시지가 전송되지 않음 토픽 조회 실패 또는 사용자 인증 실패 로그 해결 방법:\nUI 클러스터 설정에 SCRAM 인증 정보를 추가하고 SASL 메커니즘을 정확히 지정 인증에 사용하는 사용자 계정이 SCRAM-SHA-512를 사용하고 있어야 함 4. ISR 설정과 클러스터 ID 충돌 문제 Kafka 브로커를 3개로 구성하여 ISR=2 설정을 테스트하던 중, 클러스터를 재기동하면 클러스터 ID 충돌로 인해 broker가 기동되지 않는 문제가 발생했다.\n현상:\nKafka broker가 기동 중단 또는 controller election 실패 Cluster ID mismatch 또는 log directory is not empty 오류 해결 방법:\n클러스터 재기동 시 아래 명령어로 볼륨까지 완전 제거 docker compose down -v 필요 시 kafka_data_* 디렉터리를 수동으로 삭제하여 클린 상태 유지 5. SASL 메커니즘에 맞는 Producer/Consumer 설정 누락 Event Dispatcher 설정 중 Kafka Producer와 Consumer 설정 시 SASL 인증 방식 지정이 빠져 인증 실패가 발생했다.\n현상:\nkafka: client has run out of available brokers to talk to 에러 접속 시도는 하나 서버에서 연결을 끊음 (EOF) 해결 방법:\n.env에 SASL 관련 설정 추가하고, 라이브러리 설정에 반영 Go 클라이언트 기준으로는 Config.Net.SASL.Mechanism 명시 필요 이러한 문제들을 하나씩 해결해가면서 현재와 같은 안정적인 로컬 테스트 환경을 구성할 수 있었다.\n마무리 Kafka 환경이 점차 보안과 인증 요구사항을 갖게 되면서, SASL 기반 인증 환경을 로컬에서도 구축해보는 것은 매우 의미 있는 작업이었다.\n단일 클러스터에서 다중 SASL 메커니즘을 지원함으로써, 더 이상 클러스터를 이중으로 구성할 필요 없이 하나의 테스트 환경으로 다양한 인증 흐름을 재현할 수 있게 되었다.\n특히… 감동받은 부분은 Kafka UI! GUI로 Message 생성하고 Consume 됨을 확인할 수 있음에 감격했다\n","wordCount":"1519","inLanguage":"en","image":"https://dingyu.dev/posts/local-sasl-kafka/img/kafka.png","datePublished":"2025-03-28T00:00:00Z","dateModified":"2025-03-28T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/posts/local-sasl-kafka/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dingyu.dev/about/ title=About><span>About</span></a></li><li><a href=https://dingyu.dev/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://dingyu.dev/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://dingyu.dev/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://dingyu.dev/search/ title="🔍 (Alt + /)" accesskey=/><span>🔍</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/>Home</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[EDA] Local SASL SCRAM Mechanism Kafka Docker compose 구성하기</h1><div class=post-description>This post documents how to build a local Kafka cluster using Docker Compose that supports both SCRAM-SHA-256 and SCRAM-SHA-512 SASL authentication mechanisms, enabling secure, production-like testing for applications like event dispatchers—all without modifying code or relying on external infrastructure.</div><div class=post-meta><span title='2025-03-28 00:00:00 +0000 UTC'>March 28, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1519 words&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/local-sasl-kafka/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/kafka.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#local-sasl-mechanism-kafka-docker-compose-%ea%b5%ac%ec%84%b1%ed%95%98%ea%b8%b0 aria-label="Local SASL Mechanism Kafka Docker compose 구성하기">Local SASL Mechanism Kafka Docker compose 구성하기</a><ul><li><a href=#%ea%b5%ac%ec%84%b1-%eb%aa%a9%ed%91%9c aria-label="구성 목표">구성 목표</a></li><li><a href=#%eb%a1%9c%ec%bb%ac-%ed%99%98%ea%b2%bd-%ea%b5%ac%ec%84%b1%ec%9d%84-%ea%b3%a0%eb%a0%a4%ed%95%98%ea%b2%8c-%eb%90%9c-%ec%9d%b4%ec%9c%a0 aria-label="로컬 환경 구성을 고려하게 된 이유">로컬 환경 구성을 고려하게 된 이유</a></li><li><a href=#docker-compose-%ea%b8%b0%eb%b0%98-%ed%99%98%ea%b2%bd-%ea%b5%ac%ec%84%b1 aria-label="Docker Compose 기반 환경 구성">Docker Compose 기반 환경 구성</a><ul><li><a href=#%ec%96%b4%ec%a8%b0%ec%84%9c-bitnami aria-label="어쨰서 bitnami?">어쨰서 bitnami?</a></li></ul></li><li><a href=#%ea%b5%ac%ec%84%b1-%ec%84%b8%eb%b6%80-%eb%82%b4%ec%9a%a9-%ec%9a%94%ec%95%bd aria-label="구성 세부 내용 요약">구성 세부 내용 요약</a><ul><li><a href=#1-zookeeper-%ec%b4%88%ea%b8%b0%ed%99%94 aria-label="1. Zookeeper 초기화">1. Zookeeper 초기화</a></li><li><a href=#2-kafka-%eb%b8%8c%eb%a1%9c%ec%bb%a4-%ea%b8%b0%eb%8f%99-%eb%b0%8f-zookeeper-%ec%97%b0%ea%b2%b0 aria-label="2. Kafka 브로커 기동 및 Zookeeper 연결">2. Kafka 브로커 기동 및 Zookeeper 연결</a></li><li><a href=#3-controller-%eb%8f%99%ec%9e%91 aria-label="3. Controller 동작">3. Controller 동작</a></li><li><a href=#4-kafka-ui-%ec%97%b0%ea%b2%b0 aria-label="4. Kafka UI 연결">4. Kafka UI 연결</a></li><li><a href=#5-event-dispatcher-%ec%97%b0%ea%b2%b0 aria-label="5. Event Dispatcher 연결">5. Event Dispatcher 연결</a></li><li><a href=#%ec%a0%84%ec%b2%b4-%ec%8b%9c%ed%80%80%ec%8a%a4-%eb%8b%a4%ec%9d%b4%ec%96%b4%ea%b7%b8%eb%9e%a8 aria-label="전체 시퀀스 다이어그램">전체 시퀀스 다이어그램</a></li></ul></li><li><a href=#%ed%8a%b8%eb%9f%ac%eb%b8%94%ec%8a%88%ed%8c%85-%eb%b0%8f-%ed%95%b4%ea%b2%b0-%ea%b3%bc%ec%a0%95 aria-label="트러블슈팅 및 해결 과정">트러블슈팅 및 해결 과정</a><ul><li><a href=#1-kafka_cfg_advertised_listeners-%ec%84%a4%ec%a0%95-%ec%98%a4%eb%a5%98 aria-label="1. KAFKA_CFG_ADVERTISED_LISTENERS 설정 오류">1. KAFKA_CFG_ADVERTISED_LISTENERS 설정 오류</a></li><li><a href=#2-%ec%84%9c%eb%a1%9c-%eb%8b%a4%eb%a5%b8-sasl-%eb%a9%94%ec%bb%a4%eb%8b%88%ec%a6%98%ec%9d%84-%ea%b0%80%ec%a7%84-%ec%82%ac%ec%9a%a9%ec%9e%90-%ec%9d%b8%ec%a6%9d-%ec%8b%a4%ed%8c%a8 aria-label="2. 서로 다른 SASL 메커니즘을 가진 사용자 인증 실패">2. 서로 다른 SASL 메커니즘을 가진 사용자 인증 실패</a></li><li><a href=#3-kafka-ui%eb%a5%bc-%ed%86%b5%ed%95%9c-produce%ea%b0%80-%eb%8f%99%ec%9e%91%ed%95%98%ec%a7%80-%ec%95%8a%ec%9d%8c aria-label="3. Kafka UI를 통한 produce가 동작하지 않음">3. Kafka UI를 통한 produce가 동작하지 않음</a></li><li><a href=#4-isr-%ec%84%a4%ec%a0%95%ea%b3%bc-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0-id-%ec%b6%a9%eb%8f%8c-%eb%ac%b8%ec%a0%9c aria-label="4. ISR 설정과 클러스터 ID 충돌 문제">4. ISR 설정과 클러스터 ID 충돌 문제</a></li><li><a href=#5-sasl-%eb%a9%94%ec%bb%a4%eb%8b%88%ec%a6%98%ec%97%90-%eb%a7%9e%eb%8a%94-producerconsumer-%ec%84%a4%ec%a0%95-%eb%88%84%eb%9d%bd aria-label="5. SASL 메커니즘에 맞는 Producer/Consumer 설정 누락">5. SASL 메커니즘에 맞는 Producer/Consumer 설정 누락</a></li></ul></li><li><a href=#%eb%a7%88%eb%ac%b4%eb%a6%ac aria-label=마무리>마무리</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=local-sasl-mechanism-kafka-docker-compose-구성하기>Local SASL Mechanism Kafka Docker compose 구성하기<a hidden class=anchor aria-hidden=true href=#local-sasl-mechanism-kafka-docker-compose-구성하기>#</a></h1><p>Kafka를 사용하는 서비스에서 인증 방식이 <code>SASL</code> 기반이라면, 로컬에서도 유사한 인증 환경을 구성할 수 있어야 한다. 이 글에서는 로컬 환경에서 <code>SCRAM-SHA-256</code>, <code>SCRAM-SHA-512</code>를 동시에 지원하는 Kafka 클러스터를 구성하고, 이를 기반으로 Event Dispatcher 애플리케이션을 테스트할 수 있는 인프라 환경을 구축한 내용을 정리했다.</p><p><code>SASL</code>과 <code>TLS</code>의 경우 레퍼런스를 찾기 매우매우 힘들었다&mldr; 삽질하는 참에 추후 고생할 나에게 선물을 마련하고자 로컬 환경 SASL Kafka 구성하기를 기록한다</p><p>TLS는 인증서 Makefile 등 너무 복잡하여 추후에 시간이 될 때 포스팅하는것으로..</p><h2 id=구성-목표>구성 목표<a hidden class=anchor aria-hidden=true href=#구성-목표>#</a></h2><ul><li>Event Dispatcher는 source Kafka에서 이벤트를 consume하고, 이벤트 형태에 따라 분류하여 다른 dest Kafka로 produce하는 구조를 갖는다.</li><li>source Kafka와 dest Kafka는 서로 다른 클러스터가 아닌, 동일한 클러스터 내에서 다른 SASL 인증 메커니즘을 통해 구분한다.</li><li>source Kafka는 SCRAM-SHA-256 기반 인증을 사용하고, dest Kafka는 SCRAM-SHA-512 기반 인증을 사용한다.</li><li>테스트 환경에서도 코드 수정 없이 실제 운영 환경과 유사한 구조를 구축하는 것이 목표였다.</li><li>ISR(in-sync replicas)을 2로 두기 위해 Kafka 브로커는 3노드로 구성했다.</li><li>Kafka UI를 통해 produce 테스트가 가능해야 하며, 이를 통해 애플리케이션의 동작 확인도 가능하도록 한다.</li></ul><h2 id=로컬-환경-구성을-고려하게-된-이유>로컬 환경 구성을 고려하게 된 이유<a hidden class=anchor aria-hidden=true href=#로컬-환경-구성을-고려하게-된-이유>#</a></h2><ul><li>개발 서버에서 테스트 시 스택 트레이스 확인이 어려워 디버깅이 불편했으며, Bastion(보안용 게이트웨이) 사용을 위한 VPN 및 SSH 접근이 상대적으로 피로감을 느끼게 했다</li><li>사내 Kafka는 모두 SASL 인증 기반이므로 공통 설정을 만들어두면 다양한 프로젝트에 활용할 수 있다.</li><li>설정 값을 테스트할 때 코드 수정과 DEV 환경 배포 없이 변경 가능해야 했다. (트랜잭션 설정, exactly-once, ISR 등)</li><li>코드 레벨 수정 없이 테스트하려면 로컬 인프라 구성이 필요했다.</li></ul><h2 id=docker-compose-기반-환경-구성>Docker Compose 기반 환경 구성<a hidden class=anchor aria-hidden=true href=#docker-compose-기반-환경-구성>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.9&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_1</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka_data_2</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>zookeeper</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/zookeeper:3.8.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>ALLOW_ANONYMOUS_LOGIN=yes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;2181:2181&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_0_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_0_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_0:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-1</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_1_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_1_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_1:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-2</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:3.7.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;${KAFKA_BROKER_2_PORT}:9092&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_ADVERTISED_LISTENERS</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT://host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT:SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_ENABLED_MECHANISMS</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512,SCRAM-SHA-256</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_USERS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER},${256_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLIENT_PASSWORDS</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD},${256_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_USER</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_USER}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_INTER_BROKER_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${512_SASL_PASSWORD}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_data_2:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>kafka-2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka-ui</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>provectuslabs/kafka-ui:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-ui</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;8080:8080&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_NAME</span><span class=p>:</span><span class=w> </span><span class=l>Local-Zookeeper-Cluster</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class=p>:</span><span class=w> </span><span class=l>host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SASL_PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM</span><span class=p>:</span><span class=w> </span><span class=l>SCRAM-SHA-512</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.security.scram.ScramLoginModule required username=&#34;${512_SASL_USER}&#34; password=&#34;${512_SASL_PASSWORD}&#34;;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c># user 정보가 broker에 저장이 되어야 정상적으로 시작될 수 있음</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>your-app</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>env_file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>.env</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>context</span><span class=p>:</span><span class=w> </span><span class=l>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>dockerfile</span><span class=p>:</span><span class=w> </span><span class=l>dev.Dockerfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>VERSION=dev</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS_256=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS_512=host.docker.internal:${KAFKA_BROKER_0_PORT},host.docker.internal:${KAFKA_BROKER_1_PORT},host.docker.internal:${KAFKA_BROKER_2_PORT}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>your-app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>your-app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka_network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>restart</span><span class=p>:</span><span class=w> </span><span class=l>always</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>kafka-2</span><span class=w>
</span></span></span></code></pre></div><h3 id=어쨰서-bitnami>어쨰서 bitnami?<a hidden class=anchor aria-hidden=true href=#어쨰서-bitnami>#</a></h3><ol><li>환경 변수 기반의 간편한 사용자 등록
Bitnami Kafka는 다음과 같은 환경 변수만 설정하면 자동으로 SASL 사용자 등록을 수행</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_USERS</span><span class=o>=</span>user256,user512
</span></span><span class=line><span class=cl><span class=nv>KAFKA_CLIENT_PASSWORDS</span><span class=o>=</span>pass256,pass512
</span></span></code></pre></div><p>이는 일반 Kafka 공식 이미지에서는 수동으로 kafka-configs.sh 스크립트를 실행하거나 custom entrypoint를 만들어야 가능!</p><p>ex.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>bash -c <span class=s1>&#39;
</span></span></span><span class=line><span class=cl><span class=s1>/opt/bitnami/scripts/kafka/setup.sh &amp;&amp;
</span></span></span><span class=line><span class=cl><span class=s1>kafka-configs.sh --zookeeper zookeeper:2181 --alter \
</span></span></span><span class=line><span class=cl><span class=s1>    --add-config &#34;SCRAM-SHA-512=[iterations=8192,password=pass]&#34; \
</span></span></span><span class=line><span class=cl><span class=s1>    --entity-type users --entity-name user &amp;&amp;
</span></span></span><span class=line><span class=cl><span class=s1>/opt/bitnami/scripts/kafka/run.sh&#39;</span>
</span></span></code></pre></div><p>Bitnami는 컨테이너 기동 시점에 사용자 등록 로직을 자동 수행해줘서 훨씬 편리</p><ol start=2><li>SASL 설정 및 Zookeeper 연동이 기본 내장
Bitnami는 다음 설정들을 Docker 환경변수로 설정 가능</li></ol><ul><li>KAFKA_CFG_SASL_ENABLED_MECHANISMS</li><li>KAFKA_CFG_LISTENER_NAME__SASL_ENABLED_MECHANISMS</li><li>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</li></ul><p>즉, 복잡한 server.properties 없이도 docker-compose.yml만으로 SASL 클러스터 구성 가능!</p><table><thead><tr><th>환경변수</th><th>설명</th><th>사용처</th></tr></thead><tbody><tr><td><code>KAFKA_CFG_ZOOKEEPER_CONNECT</code></td><td>Kafka가 사용할 Zookeeper의 주소 (<code>host:port</code>)</td><td>Kafka가 Zookeeper 기반으로 클러스터 메타데이터를 저장/공유하기 위해 필요함</td></tr><tr><td><code>KAFKA_CFG_LISTENERS</code></td><td>브로커가 어떤 프로토콜과 포트로 외부 연결을 수신할지 설정 (ex: <code>SASL_PLAINTEXT://:9092</code>)</td><td>클라이언트 또는 브로커 간 통신을 어떤 방식으로 받을지 정의함</td></tr><tr><td><code>KAFKA_CFG_ADVERTISED_LISTENERS</code></td><td>브로커가 클라이언트에게 자신을 알릴 때 사용하는 주소 (<code>host.docker.internal:${PORT}</code>)</td><td>Kafka 클라이언트가 브로커에 접속할 때 사용할 외부 IP 또는 호스트명과 포트 정보를 제공함</td></tr><tr><td><code>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP</code></td><td>각 리스너 이름에 대해 사용할 보안 프로토콜을 매핑 (ex: <code>SASL_PLAINTEXT:SASL_PLAINTEXT</code>)</td><td>리스너 이름과 보안 프로토콜을 매칭하여 SASL 인증을 활성화하기 위해 사용</td></tr><tr><td><code>KAFKA_CFG_INTER_BROKER_LISTENER_NAME</code></td><td>브로커 간 통신에 사용할 리스너 이름</td><td>클러스터 내의 브로커 간 통신을 어떤 리스너(인증 방식)로 할지 지정함</td></tr><tr><td><code>KAFKA_CFG_SASL_ENABLED_MECHANISMS</code></td><td>Kafka에서 허용할 SASL 인증 메커니즘 목록 (ex: <code>SCRAM-SHA-512,SCRAM-SHA-256</code>)</td><td>Kafka 클라이언트와 브로커 간 인증에 사용할 수 있는 SASL 방식들을 정의함</td></tr><tr><td><code>KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL</code></td><td>브로커 간 통신에서 사용할 SASL 인증 메커니즘</td><td>브로커들끼리 통신 시 어떤 SCRAM 알고리즘으로 인증할지 설정함</td></tr><tr><td><code>KAFKA_CLIENT_USERS</code></td><td>SASL 인증에 사용할 사용자 목록 (쉼표로 구분)</td><td>Kafka 사용자 등록을 위해 필요하며, 각 사용자마다 비밀번호가 필요함</td></tr><tr><td><code>KAFKA_CLIENT_PASSWORDS</code></td><td>사용자 목록에 대응되는 비밀번호 목록 (쉼표로 구분)</td><td>위의 사용자 각각에 대응되는 비밀번호를 정의하여 Kafka 서버에 등록함</td></tr><tr><td><code>KAFKA_INTER_BROKER_USER</code></td><td>브로커 간 통신에서 사용할 사용자 이름</td><td>브로커들끼리 SCRAM 인증을 위해 사용하는 사용자 지정</td></tr><tr><td><code>KAFKA_INTER_BROKER_PASSWORD</code></td><td>브로커 간 통신에 사용할 사용자의 비밀번호</td><td>위의 사용자와 함께 브로커 간 인증을 위해 사용됨</td></tr></tbody></table><p>해당 환경은 다음의 구성 요소로 이루어진다:</p><ul><li>Bitnami Kafka 3노드 클러스터 (SCRAM-SHA-256, SCRAM-SHA-512 동시 지원)</li><li>Zookeeper</li><li>Kafka UI (관리 및 테스트 용도)</li><li>Event Dispatcher 애플리케이션 (Kafka Consumer/Producer)</li></ul><p><code>.env</code>와 파일을 구성한 후, 다음 명령어로 전체 인프라를 실행할 수 있다</p><pre tabindex=0><code>docker compose --env-file .env up --build
</code></pre><p>종료 및 클러스터 초기화를 위해서는 아래 명령어를 사용한다:</p><pre tabindex=0><code>docker compose down -v
</code></pre><p><code>.env</code> example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-env data-lang=env><span class=line><span class=cl><span class=nv>256_SASL_USER</span><span class=o>=</span>user256
</span></span><span class=line><span class=cl><span class=nv>256_SASL_PASSWORD</span><span class=o>=</span>pass256
</span></span><span class=line><span class=cl><span class=nv>512_SASL_USER</span><span class=o>=</span>user512
</span></span><span class=line><span class=cl><span class=nv>512_SASL_PASSWORD</span><span class=o>=</span>pass512
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kafka Settings</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_0_PORT</span><span class=o>=</span><span class=m>9092</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_1_PORT</span><span class=o>=</span><span class=m>9093</span>
</span></span><span class=line><span class=cl><span class=nv>KAFKA_BROKER_2_PORT</span><span class=o>=</span><span class=m>9094</span>
</span></span></code></pre></div><h2 id=구성-세부-내용-요약>구성 세부 내용 요약<a hidden class=anchor aria-hidden=true href=#구성-세부-내용-요약>#</a></h2><p>아래 다이어그램은 로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름을 정리한 것이다. 내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 이해할 수 있다. 각 단계는 실제 로그 흐름에 기반하여 순서대로 설명하였다.</p><h3 id=1-zookeeper-초기화>1. Zookeeper 초기화<a hidden class=anchor aria-hidden=true href=#1-zookeeper-초기화>#</a></h3><ul><li>Zookeeper 컨테이너가 standalone 모드로 기동되며 Kafka 브로커의 메타데이터 저장소로 동작한다.</li><li>사용자 정보 등록은 Zookeeper가 직접 수행하지 않으며, Kafka 브로커가 기동 시 <code>KAFKA_CLIENT_USERS</code>, <code>KAFKA_CLIENT_PASSWORDS</code> 환경변수를 통해 SCRAM 사용자 정보를 자동으로 등록한다.</li><li>Zookeeper 컨테이너가 standalone 모드로 기동되며 사용자 정보를 등록할 준비를 한다.</li><li><code>user256</code> (SCRAM-SHA-256), <code>user512</code> (SCRAM-SHA-512)에 대한 사용자 정보가 Zookeeper에 등록된다.</li></ul><h3 id=2-kafka-브로커-기동-및-zookeeper-연결>2. Kafka 브로커 기동 및 Zookeeper 연결<a hidden class=anchor aria-hidden=true href=#2-kafka-브로커-기동-및-zookeeper-연결>#</a></h3><ul><li>Kafka 브로커 3개(kafka-0, kafka-1, kafka-2)가 순차적으로 Zookeeper와 연결을 시도한다.</li><li>연결이 완료되면 각 브로커는 controller 선출에 참여하고, request 처리 준비가 완료되었음을 로그로 출력한다.</li></ul><h3 id=3-controller-동작>3. Controller 동작<a hidden class=anchor aria-hidden=true href=#3-controller-동작>#</a></h3><ul><li>Kafka 클러스터 내에서 한 브로커가 controller로 선출된다.</li><li>controller는 각 브로커의 상태를 확인하고, 토픽 메타데이터를 동기화하며, Partition 할당과 Leader 선출을 수행한다.</li><li>내부적으로 <code>LeaderAndIsr</code>, <code>UpdateMetadataRequest</code> 등의 메시지를 각 브로커에 전파하며 클러스터 상태를 안정화시킨다.</li></ul><h3 id=4-kafka-ui-연결>4. Kafka UI 연결<a hidden class=anchor aria-hidden=true href=#4-kafka-ui-연결>#</a></h3><ul><li>Kafka UI는 SASL-SHA-512 사용자(user512)를 이용해 Kafka 브로커에 AdminClient로 연결한다.</li><li>인증 후 topic 목록 조회 및 메시지 produce 테스트를 수행한다.</li></ul><h3 id=5-event-dispatcher-연결>5. Event Dispatcher 연결<a hidden class=anchor aria-hidden=true href=#5-event-dispatcher-연결>#</a></h3><ul><li>Event Dispatcher는 source Kafka에 SCRAM-SHA-256 방식(user256)으로 Consumer 연결을 시도하고 consume을 시작한다.</li><li>이후 dest Kafka에는 SCRAM-SHA-512 방식(user512)으로 Producer 연결하여 메시지를 produce한다.</li></ul><h3 id=전체-시퀀스-다이어그램>전체 시퀀스 다이어그램<a hidden class=anchor aria-hidden=true href=#전체-시퀀스-다이어그램>#</a></h3><p><img loading=lazy src=/posts/local-sasl-kafka/image.png></p><p>로컬 환경에서 Kafka 클러스터가 기동되고 Event Dispatcher와 Kafka UI가 상호 작용하는 흐름은 다음과 같다</p><p>내부적으로 어떤 초기화가 발생하고, 인증 및 통신이 어떤 순서로 진행되는지 확인해보자!</p><ul><li>Kafka 클러스터는 <code>Zookeeper</code> 기반이며, 3개의 브로커로 구성</li><li>SCRAM-SHA-256을 사용하는 <code>user256</code>과 SCRAM-SHA-512를 사용하는 <code>user512</code>가 생성</li><li>Kafka UI를 통해 <code>user512</code> 인증으로 접근하여 메시지를 직접 produce 가능</li><li>Event Dispatcher는 SASL 256/512 User/Password 설정을 기반으로 source/dest Kafka 각각 다른 인증 방식으로 접근하여 동작한다.</li></ul><h2 id=트러블슈팅-및-해결-과정>트러블슈팅 및 해결 과정<a hidden class=anchor aria-hidden=true href=#트러블슈팅-및-해결-과정>#</a></h2><p>Kafka SASL 인증 기반 환경을 처음부터 구성하다 보면 여러 트러블을 겪게 된다. 실제 테스트 환경에서 마주쳤던 문제와 그에 대한 해결 과정을 아래에 정리했다.</p><h3 id=1-kafka_cfg_advertised_listeners-설정-오류>1. KAFKA_CFG_ADVERTISED_LISTENERS 설정 오류<a hidden class=anchor aria-hidden=true href=#1-kafka_cfg_advertised_listeners-설정-오류>#</a></h3><p>초기 구성 시 <code>KAFKA_CFG_ADVERTISED_LISTENERS</code> 값을 잘못 설정하여 Kafka UI 및 Event Dispatcher에서 브로커 접근에 실패했다. <code>localhost</code>로 설정할 경우 Docker 내부의 컨테이너 외부에서는 Kafka 브로커에 접근할 수 없었다.</p><p><strong>현상:</strong></p><ul><li>Kafka UI 또는 Event Dispatcher가 브로커와 통신할 수 없음</li><li><code>connection refused</code> 또는 <code>EOF</code> 에러 발생</li></ul><p><strong>해결 방법:</strong></p><ul><li><code>localhost</code> 대신 <code>host.docker.internal</code> 또는 실제 호스트 IP로 설정</li><li><code>.env</code> 또는 compose 파일 내 브로커 설정 확인</li></ul><pre tabindex=0><code>KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092
</code></pre><h3 id=2-서로-다른-sasl-메커니즘을-가진-사용자-인증-실패>2. 서로 다른 SASL 메커니즘을 가진 사용자 인증 실패<a hidden class=anchor aria-hidden=true href=#2-서로-다른-sasl-메커니즘을-가진-사용자-인증-실패>#</a></h3><p>Kafka 클러스터 하나에서 <code>SCRAM-SHA-256</code>, <code>SCRAM-SHA-512</code>를 동시에 지원하게끔 설정했지만, 사용자 등록이 제대로 되지 않아 인증에 실패했다.</p><p><strong>현상:</strong></p><ul><li>Kafka UI는 인증에 성공하나, Event Dispatcher는 EOF 또는 인증 실패</li><li>Kafka 로그에 <code>Failed to authenticate user</code> 메시지 출력</li></ul><p><strong>해결 방법:</strong></p><ul><li>Kafka 초기화 스크립트에서 사용자 추가 시 <code>--mechanism</code> 플래그 명확히 지정</li><li>사용자 등록 확인을 위해 Kafka 실행 로그 확인 또는 <code>kafka-configs.sh</code> 이용해 확인</li></ul><pre tabindex=0><code>--entity-type users --entity-name user512 --alter --add-config &#39;SCRAM-SHA-512=[iterations=4096,password=pass512]&#39;
</code></pre><ul><li>추후에는 Broker에서 직접 실행할 필요가 없었음을 느끼고 <code>KAFKA_CLIENT_USERS</code>, <code>KAFKA_CLIENT_PASSWORDS</code> 설정!</li></ul><h3 id=3-kafka-ui를-통한-produce가-동작하지-않음>3. Kafka UI를 통한 produce가 동작하지 않음<a hidden class=anchor aria-hidden=true href=#3-kafka-ui를-통한-produce가-동작하지-않음>#</a></h3><p>Kafka UI를 통해 메시지를 produce할 수 있어야 Event Dispatcher의 consume 확인이 가능하지만, 인증 실패나 메타데이터 조회 실패로 UI가 제대로 동작하지 않았다.</p><p><strong>현상:</strong></p><ul><li>UI 상에서 produce 시도했지만 메시지가 전송되지 않음</li><li>토픽 조회 실패 또는 사용자 인증 실패 로그</li></ul><p><strong>해결 방법:</strong></p><ul><li>UI 클러스터 설정에 SCRAM 인증 정보를 추가하고 SASL 메커니즘을 정확히 지정</li><li>인증에 사용하는 사용자 계정이 SCRAM-SHA-512를 사용하고 있어야 함</li></ul><h3 id=4-isr-설정과-클러스터-id-충돌-문제>4. ISR 설정과 클러스터 ID 충돌 문제<a hidden class=anchor aria-hidden=true href=#4-isr-설정과-클러스터-id-충돌-문제>#</a></h3><p>Kafka 브로커를 3개로 구성하여 ISR=2 설정을 테스트하던 중, 클러스터를 재기동하면 클러스터 ID 충돌로 인해 broker가 기동되지 않는 문제가 발생했다.</p><p><strong>현상:</strong></p><ul><li>Kafka broker가 기동 중단 또는 controller election 실패</li><li><code>Cluster ID mismatch</code> 또는 <code>log directory is not empty</code> 오류</li></ul><p><strong>해결 방법:</strong></p><ul><li>클러스터 재기동 시 아래 명령어로 볼륨까지 완전 제거</li></ul><pre tabindex=0><code>docker compose down -v
</code></pre><ul><li>필요 시 <code>kafka_data_*</code> 디렉터리를 수동으로 삭제하여 클린 상태 유지</li></ul><h3 id=5-sasl-메커니즘에-맞는-producerconsumer-설정-누락>5. SASL 메커니즘에 맞는 Producer/Consumer 설정 누락<a hidden class=anchor aria-hidden=true href=#5-sasl-메커니즘에-맞는-producerconsumer-설정-누락>#</a></h3><p>Event Dispatcher 설정 중 Kafka Producer와 Consumer 설정 시 SASL 인증 방식 지정이 빠져 인증 실패가 발생했다.</p><p><strong>현상:</strong></p><ul><li><code>kafka: client has run out of available brokers to talk to</code> 에러</li><li>접속 시도는 하나 서버에서 연결을 끊음 (EOF)</li></ul><p><strong>해결 방법:</strong></p><ul><li><code>.env</code>에 SASL 관련 설정 추가하고, 라이브러리 설정에 반영</li><li>Go 클라이언트 기준으로는 <code>Config.Net.SASL.Mechanism</code> 명시 필요</li></ul><hr><p>이러한 문제들을 하나씩 해결해가면서 현재와 같은 안정적인 로컬 테스트 환경을 구성할 수 있었다.</p><h2 id=마무리>마무리<a hidden class=anchor aria-hidden=true href=#마무리>#</a></h2><p>Kafka 환경이 점차 보안과 인증 요구사항을 갖게 되면서, SASL 기반 인증 환경을 로컬에서도 구축해보는 것은 매우 의미 있는 작업이었다.</p><p>단일 클러스터에서 다중 SASL 메커니즘을 지원함으로써, 더 이상 클러스터를 이중으로 구성할 필요 없이 하나의 테스트 환경으로 다양한 인증 흐름을 재현할 수 있게 되었다.</p><p>특히&mldr; 감동받은 부분은 Kafka UI! GUI로 Message 생성하고 Consume 됨을 확인할 수 있음에 감격했다</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/tags/kafka/>Kafka</a></li><li><a href=https://dingyu.dev/tags/sasl/>Sasl</a></li><li><a href=https://dingyu.dev/tags/bitnami/>Bitnami</a></li><li><a href=https://dingyu.dev/tags/kafka-ui/>Kafka Ui</a></li><li><a href=https://dingyu.dev/tags/local-test/>Local Test</a></li></ul><nav class=paginav><a class=next href=https://dingyu.dev/posts/dance-with-burrow/><span class=title>Next »</span><br><span>[EDA] Kafka (MSK) Monitoring with Burrow Prometheus And Thanos</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
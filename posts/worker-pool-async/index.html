<!doctype html><html lang=ko dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[Go] Worker Pool과 비동기 작업의 성능 프로파일링 | Ding's Coding Forge</title>
<meta name=keywords content="go,async,sync,pprof"><meta name=description content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><meta name=author content="dingyu"><link rel=canonical href=https://dingyu.dev/posts/worker-pool-async/><meta name=google-site-verification content="8XY1hI6NVxQIrN7bQbnX-9TG9HHFw5HOQmlb6vcsFdQ"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.678f9035c217c5346e0b3de5bdc9ebac02c53b0502219858f8653d8d181c97b3.css integrity="sha256-Z4+QNcIXxTRuCz3lvcnrrALFOwUCIZhY+GU9jRgcl7M=" rel="preload stylesheet" as=style><link rel=icon href=https://dingyu.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dingyu.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dingyu.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dingyu.dev/apple-touch-icon.png><link rel=mask-icon href=https://dingyu.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://dingyu.dev/posts/worker-pool-async/><link rel=alternate hreflang=en href=https://dingyu.dev/en/posts/worker-pool-async/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XH8830R9KK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XH8830R9KK")}</script><meta property="og:url" content="https://dingyu.dev/posts/worker-pool-async/"><meta property="og:site_name" content="Ding's Coding Forge"><meta property="og:title" content="[Go] Worker Pool과 비동기 작업의 성능 프로파일링"><meta property="og:description" content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><meta property="og:locale" content="ko"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-27T00:00:00+00:00"><meta property="article:tag" content="Go"><meta property="article:tag" content="Async"><meta property="article:tag" content="Sync"><meta property="article:tag" content="Pprof"><meta property="og:image" content="https://dingyu.dev/posts/worker-pool-async/img/go-thumbnail.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dingyu.dev/posts/worker-pool-async/img/go-thumbnail.png"><meta name=twitter:title content="[Go] Worker Pool과 비동기 작업의 성능 프로파일링"><meta name=twitter:description content="This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dingyu.dev/posts/"},{"@type":"ListItem","position":2,"name":"[Go] Worker Pool과 비동기 작업의 성능 프로파일링","item":"https://dingyu.dev/posts/worker-pool-async/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[Go] Worker Pool과 비동기 작업의 성능 프로파일링","name":"[Go] Worker Pool과 비동기 작업의 성능 프로파일링","description":"This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks.","keywords":["go","async","sync","pprof"],"articleBody":"\npprof 적용은 pprof로 GC 튜닝하기를 참고 해주세요\n배경 비즈니스 요구사항에 따른 서비스를 수행하는 서비스 서버를 **“서비스 서버”**라 칭합니다\n[AS-IS] 서비스 서버에서는 매번 단 건의 HTTP Request로 서버내에서 발생한 이벤트를 발행하고 있었습니다 비동기로 HTTP 요청을 수행하고는 있었지만, HTTP 요청 수에 비례하여 Batch Loader 응답지연 시간이 리니어하게 증가하고 있었습니다. 문제 과도한 네트워크 요청 : 이벤트가 발생할 때마다 HTTP 요청을 보내므로, 이벤트 발생 빈도가 높아질수록 네트워크 트래픽이 과도하게 증가 레이턴시 증가 : 요청이 많아지면 큐잉이 발생하여 응답 시간 지연 확장성 부재 : 다수의 서비스에서 제각각의 구현 방식으로 Batch Loader에 적재중. HTTP 요청이 아닌 이벤트 스트리밍 기반으로 확장하였을 때, 불필요하게 반복적인 수정 작업을 다수의 서버에서 진행하게 됨 [TO-BE] 문제 해결 과도한 네트워크 요청 해결 : 서비스 서버 내에서 이벤트에 대한 큐를 두어, 최대 버퍼 limit을 초과 하거나 Batch 주기에 도달하는 경우, buffer를 Batch Loader로 이벤트 발행. 오버헤드인 HTTP Request 를 최소화 레이턴시 증가 해결 : 서버에서 지정해둔 Interval Duration에 따라 buffer를 모아 요청하기에 큐잉으로 인한 레이턴시 증가는 해결됨. 확장성 증가 : 서비스 서버에서 사용할 공통 라이브러리를 Repository로 구축하여, Batch Loader 서버의 변경 또는 확장에 따른 서비스 서버들의 반복적인 수정 작업을 최소화. Batch Loader 서버와는 느슨한 결합을 갖도록 함 해결 방안 Batch Loader 서버와는 느슨한 결합을 가지도록 공통 라이브러리를 구축하는 의사 결정 완료 공통 라이브러리에서 이벤트 버퍼를 모아 요청을 하는 모듈을 **“Batch Processor”**라 칭합니다.\n요구사항 IO Bound Task를 최소화 goroutine 생명주기를 제어 가능해야 함 1안 : Worker Pool 방안 여러개의 worker들이 각각의 Interval Duration 동안 내부적인 버퍼를 채워 동기적으로 API로 요청하는 방안\nPros deep copy가 발생되지 않는다 성능 개선을 위해 Worker Pool을 튜닝할 수 있다 Cons Interval Duration 주기로 Worse Case Worker Pool 수 만큼 HTTP Request 발생 서비스 서버는 Worker Pool의 Magic Number를 찾기 위해 테스트를 진행해야함 2안 : 하나의 Worker + Async HTTP Request Pros Interval Duration 동안 한번만 HTTP Request 발생 Worker Pool Magic Number를 찾기 위한 테스트가 불필요 Cons deep copy로 인한 CPU 부하 가능성 (byte array size 만큼 순회하면서 값 할당) deep copy로 인한 Memory 부하 가능성 (byte array를 copy하면서 추가적인 힙 할당) GC 동작 방식에 따라, 복사된 buffer memory로 인한 GC Trigger -\u003e Stop the World 로 인한 서비스 서버의 지연 가능성 고려 두가지 비교군 중, 공통 라이브러리를 구성하는 것에 있어 사용성이 보장되어야 하기에, 2안이 적합한 방안이라고 생각되었습니다.\n하지만 deep copy로 인한 CPU / memory 상의 오버헤드가 어느정도이고, 영향도가 없을지 검증이 필요했습니다.\n프로파일링 프로파일링 목표 분당 처리량: 1분간 2000 RPS 요청 처리 가능 수 메모리 사용량: deepCopy()로 인한 메모리 부하 확인 GC 발생 오버헤드: 메모리 복사 과정에서의 GC 확인 deep copy 코드\nfunc deepCopy[T any](src []T) []T { if src == nil { return nil } dst := make([]T, len(src)) copy(dst, src) return dst } 테스트 방법 10, 100개의 Worker Pool + Sync IO 방안과 하나의 Worker + Async IO 방안의 테스트를 진행합니다.\n각 비교군은 CPU Profile을 활성화하여 docker image를 빌드합니다.\n분당 처리량 : 1분간 2000 RPS의 요청을 몇개까지 처리 가능한가? API 호출 이후 호출된 Event의 개수 로깅 메모리 : deepCopy()로 인한 메모리 부하가 얼마나 생기는 지 확인 메모리 copy 과정에서 GC 발생으로 인한 오버헤드 확인 heap Profile을 통한 관측 curl {endpoint}/debug/pprof/heap\\?seconds\\=30 --output {output_path} 처리된 개수는 어떻게 세나요? API send() 메서드 중 로깅을 통해 확인\nfunc (q *BatchProcessor) send(payload []byte, traceIDs []string) { ... response, err := q.client.Do(request) ... q.logger.Info().Int(\u0026#34;count\u0026#34;, len(traceIDs)).Send() } count를 파싱하여 stop 이전에 처리된 개수를 확인 합니다\n[e.g.] logfile 예시\nlog file ( sum = … + 1020 + 1000 ) ... 2024-10-14T05:11:06Z INF count=1020 2024-10-14T05:11:07Z INF count=1000 2024-10-14T05:11:07Z INF stopping BatchProcessor, waiting for remaining events to be sent func=BatchProcessor.Stop 2024-10-14T05:11:07Z INF count=288 CPU Profile selectgo : select 구문 중 여러 채널에서 데이터를 동시에 기다리면서 그 중 하나가 준비되면 해당 작업을 수행하는 기능\n채널 1: queue 에서 Pop()하여 stack buffer에 적재, buffer maxlimit을 초과하는 경우 API 전송 및 buffer Flush 채널 2: time.Ticker 일정 시간 마다 내부 버퍼 스택으로 API 전송 및 Flush 채널 3: 종료 시그널을 받아, 남아있는 버퍼 스택을 API 전송 및 고루틴 종료 Worker Pool (100) + Sync IO runWithSync() 분석\n각 worker들은 공유 자원인 queue 채널을 소비하며, 워커의 수가 많아질 수록 내부적인 lock과 acquireSudog(채널 수신 대기)에 드는 비용이 발생 runtime 스케쥴러에 의해, 동시성 처리에 드는 비용이 예상외의 오버헤드 selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 85% Worker Pool (10) + Sync IO runWithSync() 분석\nsellock 비율이 100 worker pool에 비해 현저히 감소하는 것을 확인 selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 66% 하나의 Worker + Async IO run() 분석\ndeepCopy(그림 중 runtime.memmove)로 인한 오버헤드는 10ms selectgo 중, 오버헤드인 runtime.recv (외부 API 호출 시, goroutine 준비 작업)+ deep copy의 비율은 50% Heap Profile run() / runWithSync() 함수가 실행되는 동안 수행되는 DeepCopy에 초점을 맞추어 프로파일링\nWorker Pool deepCopy() 로 인한 오버헤드 없음\n100 workers 중 8.2MB 중 HTTP Request가 7.7MB 소모 하나의 Worker + Async IO 총 12.21MB의 run 과정 중 내부 버퍼를 쓰는 작업인 Write를 제외한 오버헤드를 산정\nworker run / Request 비율 100 worker pool 중, 8.2MB:7.7MB 12.21MB 인 경우 11.4MB가 HTTP Request에 사용 deepCopy에 드는 오버헤드는 150kB (1.22%) 매우 미미한 수준 테스트 결과 분류 분당 처리량 CPU 오버헤드 메모리 오버헤드 10 worker 83,663 66% 0% 100 worker 84,042 85% 0% 1 worker + async 119,720 50% 1.22% 정리 Worker Pool을 사용할 경우, Queue의 동시성 처리를 위해 사용되는 오버헤드가 상당하다 Worker Number를 늘리더라도 동시성 처리 오버헤드가 상승되기에 number of worker 와 처리량은 리니어하게 상승하진 않는다 IO Bound Task를 수행할 경우, Worker Pool 보다는 비동기로 처리하는 것이 성능상의 이점이 크다 CPU Bound Task의 경우, runtime에 의해 goroutine 이 수행되기 까지 대기 시간이 걸리기에 worker pool을 사용하는 것이 좋다 순서가 보장되어야 하는 경우에는 IO Bound Task 일지라도 Worker Pool을 사용하는 것이 좋다 ","wordCount":"896","inLanguage":"ko","image":"https://dingyu.dev/posts/worker-pool-async/img/go-thumbnail.png","datePublished":"2024-10-27T00:00:00Z","dateModified":"2024-10-27T00:00:00Z","author":{"@type":"Person","name":"dingyu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dingyu.dev/posts/worker-pool-async/"},"publisher":{"@type":"Organization","name":"Ding's Coding Forge","logo":{"@type":"ImageObject","url":"https://dingyu.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dingyu.dev/ accesskey=h title="Ding's Coding Forge (Alt + H)"><img src=https://dingyu.dev/apple-touch-icon.png alt aria-label=logo height=35>Ding's Coding Forge</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button><span class=nav-separator>|</span><div class=lang-select-dropdown><button class=lang-select-dropdown-trigger aria-label=번역 type=button><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" width="24" height="18"><path d="M478.33 433.6l-90-218a22 22 0 00-40.67.0l-90 218a22 22 0 1040.67 16.79L316.66 406h102.67l18.33 44.39A22 22 0 00458 464a22 22 0 0020.32-30.4zM334.83 362 368 281.65 401.17 362z" fill="currentcolor"/><path d="M267.84 342.92a22 22 0 00-4.89-30.7c-.2-.15-15-11.13-36.49-34.73 39.65-53.68 62.11-114.75 71.27-143.49H330a22 22 0 000-44H214V70a22 22 0 00-44 0v20H54a22 22 0 000 44h197.25c-9.52 26.95-27.05 69.5-53.79 108.36-31.41-41.68-43.08-68.65-43.17-68.87a22 22 0 00-40.58 17c.58 1.38 14.55 34.23 52.86 83.93.92 1.19 1.83 2.35 2.74 3.51-39.24 44.35-77.74 71.86-93.85 80.74a22 22 0 1021.07 38.63c2.16-1.18 48.6-26.89 101.63-85.59 22.52 24.08 38 35.44 38.93 36.1a22 22 0 0030.75-4.9z" fill="currentcolor"/></svg></button><div class=lang-select-dropdown-content><a lang=en href=https://dingyu.dev/en/ title=English aria-label=English>English</a></div></div></div></div><ul id=menu><li><a href=https://dingyu.dev/about/ title=소개><span>소개</span></a></li><li><a href=https://dingyu.dev/categories/ title=카테고리><span>카테고리</span></a></li><li><a href=https://dingyu.dev/tags/ title=태그><span>태그</span></a></li><li><a href=https://dingyu.dev/archives/ title=아카이브><span>아카이브</span></a></li><li><a href=https://dingyu.dev/search/ title="검색 (Alt + /)" accesskey=/><span>검색</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dingyu.dev/>홈</a>&nbsp;»&nbsp;<a href=https://dingyu.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[Go] Worker Pool과 비동기 작업의 성능 프로파일링</h1><div class=post-description>This post explores profiling and optimizing worker pools vs. asynchronous execution in Go using pprof. It analyzes the performance impact of concurrent HTTP requests, comparing sync worker pools (10 vs. 100 workers) and a single async worker in terms of throughput, CPU overhead, and memory allocation. Profiling results reveal that worker pools suffer from high concurrency overhead, while asynchronous execution significantly improves throughput with minimal memory cost. Additionally, the post discusses when to use worker pools vs. async processing, highlighting key trade-offs for IO-bound vs. CPU-bound tasks.</div><div class=post-meta><span title='2024-10-27 00:00:00 +0000 UTC'>10월 27, 2024</span>&nbsp;·&nbsp;5 분&nbsp;·&nbsp;896 단어&nbsp;·&nbsp;dingyu&nbsp;|&nbsp;번역:<ul class=i18n_list><li><a href=https://dingyu.dev/en/posts/worker-pool-async/>En</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/dings-things/blog/tree/main/content/posts/worker-pool-async/index.ko.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://dingyu.dev/img/go-thumbnail.png alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>목차</span></summary><div class=inner><ul><li><a href=#%eb%b0%b0%ea%b2%bd aria-label=배경>배경</a><ul><li><a href=#as-is aria-label=[AS-IS]>[AS-IS]</a><ul><li><a href=#%eb%ac%b8%ec%a0%9c aria-label=문제>문제</a></li></ul></li><li><a href=#to-be aria-label=[TO-BE]>[TO-BE]</a><ul><li><a href=#%eb%ac%b8%ec%a0%9c-%ed%95%b4%ea%b2%b0 aria-label="문제 해결">문제 해결</a></li></ul></li></ul></li><li><a href=#%ed%95%b4%ea%b2%b0-%eb%b0%a9%ec%95%88 aria-label="해결 방안">해결 방안</a><ul><ul><li><a href=#%ec%9a%94%ea%b5%ac%ec%82%ac%ed%95%ad aria-label=요구사항>요구사항</a></li><li><a href=#1%ec%95%88--worker-pool-%eb%b0%a9%ec%95%88 aria-label="1안 : Worker Pool 방안">1안 : Worker Pool 방안</a><ul><li><a href=#pros aria-label=Pros>Pros</a></li><li><a href=#cons aria-label=Cons>Cons</a></li></ul></li><li><a href=#2%ec%95%88--%ed%95%98%eb%82%98%ec%9d%98-worker--async-http-request aria-label="2안 : 하나의 Worker + Async HTTP Request">2안 : 하나의 Worker + Async HTTP Request</a><ul><li><a href=#pros-1 aria-label=Pros>Pros</a></li><li><a href=#cons-1 aria-label=Cons>Cons</a></li></ul></li></ul></ul></li><li><a href=#%ed%94%84%eb%a1%9c%ed%8c%8c%ec%9d%bc%eb%a7%81 aria-label=프로파일링>프로파일링</a><ul><li><a href=#%ed%94%84%eb%a1%9c%ed%8c%8c%ec%9d%bc%eb%a7%81-%eb%aa%a9%ed%91%9c aria-label="프로파일링 목표">프로파일링 목표</a></li><li><a href=#%ed%85%8c%ec%8a%a4%ed%8a%b8-%eb%b0%a9%eb%b2%95 aria-label="테스트 방법">테스트 방법</a><ul><ul><li><a href=#%ec%b2%98%eb%a6%ac%eb%90%9c-%ea%b0%9c%ec%88%98%eb%8a%94-%ec%96%b4%eb%96%bb%ea%b2%8c-%ec%84%b8%eb%82%98%ec%9a%94 aria-label="처리된 개수는 어떻게 세나요?">처리된 개수는 어떻게 세나요?</a></li></ul></ul></li><li><a href=#cpu-profile aria-label="CPU Profile">CPU Profile</a><ul><ul><li><a href=#worker-pool-100--sync-io aria-label="Worker Pool (100) + Sync IO">Worker Pool (100) + Sync IO</a></li><li><a href=#worker-pool-10--sync-io aria-label="Worker Pool (10) + Sync IO">Worker Pool (10) + Sync IO</a></li><li><a href=#%ed%95%98%eb%82%98%ec%9d%98-worker--async-io aria-label="하나의 Worker + Async IO">하나의 Worker + Async IO</a></li></ul></ul></li><li><a href=#heap-profile aria-label="Heap Profile">Heap Profile</a><ul><ul><li><a href=#worker-pool aria-label="Worker Pool">Worker Pool</a></li><li><a href=#%ed%95%98%eb%82%98%ec%9d%98-worker--async-io-1 aria-label="하나의 Worker + Async IO">하나의 Worker + Async IO</a></li></ul></ul></li></ul></li><li><a href=#%ed%85%8c%ec%8a%a4%ed%8a%b8-%ea%b2%b0%ea%b3%bc aria-label="테스트 결과">테스트 결과</a><ul><li><a href=#%ec%a0%95%eb%a6%ac aria-label=정리>정리</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p><img loading=lazy src=/posts/worker-pool-async/image.png></p><blockquote><p><strong>pprof 적용</strong>은
<a href=https://dingyu.dev/posts/go-pprof-gc/>pprof로 GC 튜닝하기</a>를 참고 해주세요</p></blockquote><h1 id=배경>배경<a hidden class=anchor aria-hidden=true href=#배경>#</a></h1><hr><blockquote><p>비즈니스 요구사항에 따른 서비스를 수행하는 서비스 서버를 **&ldquo;서비스 서버&rdquo;**라 칭합니다</p></blockquote><h2 id=as-is>[AS-IS]<a hidden class=anchor aria-hidden=true href=#as-is>#</a></h2><p>서비스 서버에서는 매번 단 건의 HTTP Request로 서버내에서 발생한 이벤트를 발행하고 있었습니다
비동기로 HTTP 요청을 수행하고는 있었지만, HTTP 요청 수에 비례하여 Batch Loader 응답지연 시간이 리니어하게 증가하고 있었습니다.
<img loading=lazy src=/posts/worker-pool-async/image-1.png></p><h3 id=문제>문제<a hidden class=anchor aria-hidden=true href=#문제>#</a></h3><ol><li><strong>과도한 네트워크 요청</strong> : 이벤트가 발생할 때마다 HTTP 요청을 보내므로, 이벤트 발생 빈도가 높아질수록 네트워크 트래픽이 과도하게 증가</li><li><strong>레이턴시 증가</strong> : 요청이 많아지면 큐잉이 발생하여 응답 시간 지연</li><li><strong>확장성 부재</strong> : 다수의 서비스에서 제각각의 구현 방식으로 Batch Loader에 적재중. HTTP 요청이 아닌 이벤트 스트리밍 기반으로 확장하였을 때, 불필요하게 반복적인 수정 작업을 다수의 서버에서 진행하게 됨</li></ol><h2 id=to-be>[TO-BE]<a hidden class=anchor aria-hidden=true href=#to-be>#</a></h2><p><img loading=lazy src=/posts/worker-pool-async/image-2.png></p><h3 id=문제-해결>문제 해결<a hidden class=anchor aria-hidden=true href=#문제-해결>#</a></h3><ol><li><strong>과도한 네트워크 요청 해결</strong> : 서비스 서버 내에서 이벤트에 대한 큐를 두어, 최대 버퍼 limit을 초과 하거나 Batch 주기에 도달하는 경우, buffer를 Batch Loader로 이벤트 발행.<ul><li>오버헤드인 HTTP Request 를 최소화</li></ul></li><li><strong>레이턴시 증가 해결</strong> : 서버에서 지정해둔 <code>Interval Duration</code>에 따라 buffer를 모아 요청하기에 큐잉으로 인한 레이턴시 증가는 해결됨.</li><li><strong>확장성 증가</strong> : 서비스 서버에서 사용할 공통 라이브러리를 Repository로 구축하여, Batch Loader 서버의 변경 또는 확장에 따른 서비스 서버들의 반복적인 수정 작업을 최소화. Batch Loader 서버와는 <strong>느슨한 결합</strong>을 갖도록 함</li></ol><h1 id=해결-방안>해결 방안<a hidden class=anchor aria-hidden=true href=#해결-방안>#</a></h1><hr><blockquote><p>Batch Loader 서버와는 느슨한 결합을 가지도록 공통 라이브러리를 구축하는 의사 결정 완료
공통 라이브러리에서 이벤트 버퍼를 모아 요청을 하는 모듈을 **&ldquo;Batch Processor&rdquo;**라 칭합니다.</p></blockquote><h3 id=요구사항>요구사항<a hidden class=anchor aria-hidden=true href=#요구사항>#</a></h3><ul><li><strong>IO Bound Task</strong>를 최소화</li><li><code>goroutine</code> 생명주기를 제어 가능해야 함</li></ul><h3 id=1안--worker-pool-방안>1안 : Worker Pool 방안<a hidden class=anchor aria-hidden=true href=#1안--worker-pool-방안>#</a></h3><p><img loading=lazy src=/posts/worker-pool-async/image-3.png></p><p>여러개의 worker들이 각각의 <code>Interval Duration</code> 동안 내부적인 버퍼를 채워 동기적으로 API로 요청하는 방안</p><h4 id=pros>Pros<a hidden class=anchor aria-hidden=true href=#pros>#</a></h4><ul><li>deep copy가 발생되지 않는다</li><li>성능 개선을 위해 Worker Pool을 튜닝할 수 있다</li></ul><h4 id=cons>Cons<a hidden class=anchor aria-hidden=true href=#cons>#</a></h4><ul><li><code>Interval Duration</code> 주기로 Worse Case Worker Pool 수 만큼 HTTP Request 발생</li><li>서비스 서버는 Worker Pool의 Magic Number를 찾기 위해 테스트를 진행해야함</li></ul><h3 id=2안--하나의-worker--async-http-request>2안 : 하나의 Worker + Async HTTP Request<a hidden class=anchor aria-hidden=true href=#2안--하나의-worker--async-http-request>#</a></h3><p><img loading=lazy src=/posts/worker-pool-async/image-4.png></p><h4 id=pros-1>Pros<a hidden class=anchor aria-hidden=true href=#pros-1>#</a></h4><ul><li>Interval Duration 동안 한번만 HTTP Request 발생</li><li>Worker Pool Magic Number를 찾기 위한 테스트가 불필요</li></ul><h4 id=cons-1>Cons<a hidden class=anchor aria-hidden=true href=#cons-1>#</a></h4><ul><li>deep copy로 인한 CPU 부하 가능성 (byte array size 만큼 순회하면서 값 할당)</li><li>deep copy로 인한 Memory 부하 가능성 (byte array를 copy하면서 추가적인 힙 할당)<ul><li>GC 동작 방식에 따라, 복사된 buffer memory로 인한 GC Trigger -> <code>Stop the World</code> 로 인한 서비스 서버의 지연 가능성 고려</li></ul></li></ul><p>두가지 비교군 중, 공통 라이브러리를 구성하는 것에 있어 <strong>사용성</strong>이 보장되어야 하기에, 2안이 적합한 방안이라고 생각되었습니다.</p><p>하지만 <code>deep copy</code>로 인한 CPU / memory 상의 오버헤드가 어느정도이고, 영향도가 없을지 검증이 필요했습니다.</p><h1 id=프로파일링>프로파일링<a hidden class=anchor aria-hidden=true href=#프로파일링>#</a></h1><hr><h2 id=프로파일링-목표>프로파일링 목표<a hidden class=anchor aria-hidden=true href=#프로파일링-목표>#</a></h2><hr><ul><li><strong>분당 처리량</strong>: 1분간 2000 RPS 요청 처리 가능 수</li><li><strong>메모리 사용량</strong>: <code>deepCopy()</code>로 인한 메모리 부하 확인</li><li><strong>GC 발생 오버헤드</strong>: 메모리 복사 과정에서의 GC 확인</li></ul><blockquote><p><strong>deep copy 코드</strong></p></blockquote><pre tabindex=0><code class=language-go>func deepCopy[T any](src []T) []T {
    if src == nil {
        return nil
    }
    dst := make([]T, len(src))
    copy(dst, src)
    return dst
}</code></pre><h2 id=테스트-방법>테스트 방법<a hidden class=anchor aria-hidden=true href=#테스트-방법>#</a></h2><hr><p><strong>10, 100개의 Worker Pool + Sync IO 방안</strong>과 <strong>하나의 Worker + Async IO 방안</strong>의 테스트를 진행합니다.</p><p>각 비교군은 CPU Profile을 활성화하여 docker image를 빌드합니다.</p><ul><li><strong>분당 처리량</strong> : 1분간 2000 RPS의 요청을 몇개까지 처리 가능한가?<ul><li>API 호출 이후 호출된 Event의 개수 로깅</li></ul></li><li><strong>메모리</strong> : deepCopy()로 인한 메모리 부하가 얼마나 생기는 지 확인<ul><li>메모리 copy 과정에서 GC 발생으로 인한 오버헤드 확인</li><li>heap Profile을 통한 관측</li></ul><pre tabindex=0><code class=language-bash>curl {endpoint}/debug/pprof/heap\?seconds\=30 --output {output_path}</code></pre></li></ul><blockquote><h4 id=처리된-개수는-어떻게-세나요>처리된 개수는 어떻게 세나요?<a hidden class=anchor aria-hidden=true href=#처리된-개수는-어떻게-세나요>#</a></h4></blockquote><p>API send() 메서드 중 로깅을 통해 확인</p><blockquote></blockquote><pre tabindex=0><code class=language-go>func (q *BatchProcessor) send(payload []byte, traceIDs []string) {
    ...
    response, err := q.client.Do(request)
    ...
    q.logger.Info().Int(&amp;#34;count&amp;#34;, len(traceIDs)).Send()
}</code></pre><blockquote><p>count를 파싱하여 stop 이전에 처리된 개수를 확인 합니다</p></blockquote><p><strong>[e.g.] logfile 예시</strong></p><ul><li>log file ( sum = &mldr; + 1020 + 1000 )</li></ul><blockquote></blockquote><pre tabindex=0><code class=language-text>...
2024-10-14T05:11:06Z INF count=1020
2024-10-14T05:11:07Z INF count=1000
2024-10-14T05:11:07Z INF stopping BatchProcessor, waiting for remaining events to be sent func=BatchProcessor.Stop
2024-10-14T05:11:07Z INF count=288</code></pre><h2 id=cpu-profile>CPU Profile<a hidden class=anchor aria-hidden=true href=#cpu-profile>#</a></h2><hr><blockquote><p>selectgo : select 구문 중 여러 채널에서 데이터를 동시에 기다리면서 그 중 하나가 준비되면 해당 작업을 수행하는 기능</p></blockquote><ul><li>채널 1: queue 에서 Pop()하여 stack buffer에 적재, buffer maxlimit을 초과하는 경우 API 전송 및 buffer Flush</li><li>채널 2: <code>time.Ticker</code> 일정 시간 마다 내부 버퍼 스택으로 API 전송 및 Flush</li><li>채널 3: 종료 시그널을 받아, 남아있는 버퍼 스택을 API 전송 및 고루틴 종료</li></ul><h4 id=worker-pool-100--sync-io>Worker Pool (100) + Sync IO<a hidden class=anchor aria-hidden=true href=#worker-pool-100--sync-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-5.png></p><p><code>runWithSync()</code> 분석</p><ul><li>각 worker들은 공유 자원인 queue 채널을 소비하며, 워커의 수가 많아질 수록 내부적인 lock과 acquireSudog(채널 수신 대기)에 드는 비용이 발생</li><li>runtime 스케쥴러에 의해, 동시성 처리에 드는 비용이 예상외의 오버헤드</li><li>selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 <strong>85%</strong></li></ul><h4 id=worker-pool-10--sync-io>Worker Pool (10) + Sync IO<a hidden class=anchor aria-hidden=true href=#worker-pool-10--sync-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-6.png></p><p><code>runWithSync()</code> 분석</p><ul><li>sellock 비율이 100 worker pool에 비해 현저히 감소하는 것을 확인</li><li>selectgo 중, 오버헤드인 sellock과 acquireSudog의 비율은 <strong>66%</strong></li></ul><h4 id=하나의-worker--async-io>하나의 Worker + Async IO<a hidden class=anchor aria-hidden=true href=#하나의-worker--async-io>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-7.png></p><p><code>run()</code> 분석</p><ul><li>deepCopy(그림 중 runtime.memmove)로 인한 오버헤드는 10ms</li><li>selectgo 중, 오버헤드인 runtime.recv (외부 API 호출 시, goroutine 준비 작업)+ deep copy의 비율은 <strong>50%</strong></li></ul><h2 id=heap-profile>Heap Profile<a hidden class=anchor aria-hidden=true href=#heap-profile>#</a></h2><hr><p><code>run()</code> / <code>runWithSync()</code> 함수가 실행되는 동안 수행되는 DeepCopy에 초점을 맞추어 프로파일링</p><h4 id=worker-pool>Worker Pool<a hidden class=anchor aria-hidden=true href=#worker-pool>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-8.png>
deepCopy() 로 인한 오버헤드 없음</p><ul><li>100 workers 중 8.2MB 중 HTTP Request가 7.7MB 소모</li></ul><h4 id=하나의-worker--async-io-1>하나의 Worker + Async IO<a hidden class=anchor aria-hidden=true href=#하나의-worker--async-io-1>#</a></h4><p><img loading=lazy src=/posts/worker-pool-async/image-9.png>
총 12.21MB의 run 과정 중 내부 버퍼를 쓰는 작업인 Write를 제외한 오버헤드를 산정</p><ul><li>worker run / Request 비율<ul><li>100 worker pool 중, 8.2MB:7.7MB</li><li><strong>12.21MB 인 경우 11.4MB가 HTTP Request에 사용</strong></li></ul></li><li>deepCopy에 드는 오버헤드는 150kB (1.22%) 매우 미미한 수준</li></ul><h1 id=테스트-결과>테스트 결과<a hidden class=anchor aria-hidden=true href=#테스트-결과>#</a></h1><hr><table><thead><tr><th>분류</th><th>분당 처리량</th><th>CPU 오버헤드</th><th>메모리 오버헤드</th></tr></thead><tbody><tr><td>10 worker</td><td>83,663</td><td>66%</td><td>0%</td></tr><tr><td>100 worker</td><td>84,042</td><td>85%</td><td>0%</td></tr><tr><td>1 worker + async</td><td>119,720</td><td>50%</td><td>1.22%</td></tr></tbody></table><h2 id=정리>정리<a hidden class=anchor aria-hidden=true href=#정리>#</a></h2><ul><li>Worker Pool을 사용할 경우, Queue의 동시성 처리를 위해 사용되는 오버헤드가 상당하다</li><li>Worker Number를 늘리더라도 동시성 처리 오버헤드가 상승되기에 number of worker 와 처리량은 리니어하게 상승하진 않는다</li><li>IO Bound Task를 수행할 경우, Worker Pool 보다는 비동기로 처리하는 것이 성능상의 이점이 크다</li><li>CPU Bound Task의 경우, runtime에 의해 goroutine 이 수행되기 까지 대기 시간이 걸리기에 worker pool을 사용하는 것이 좋다</li><li>순서가 보장되어야 하는 경우에는 IO Bound Task 일지라도 Worker Pool을 사용하는 것이 좋다</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://dingyu.dev/tags/go/>Go</a></li><li><a href=https://dingyu.dev/tags/async/>Async</a></li><li><a href=https://dingyu.dev/tags/sync/>Sync</a></li><li><a href=https://dingyu.dev/tags/pprof/>Pprof</a></li></ul><nav class=paginav><a class=prev href=https://dingyu.dev/posts/gopher-con-2024-kubernetes-programing/><span class=title>« 이전 페이지</span><br><span>[Go] Gophercon 2024 - 쿠버네티스 플랫폼 프로그래밍</span>
</a><a class=next href=https://dingyu.dev/posts/coffee-pal/><span class=title>다음 페이지 »</span><br><span>[DX] 사내 커피 챗 슬랙 봇 개발기</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=dings-things/blog data-repo-id=R_kgDON9IuAw data-category=Announcements data-category-id=DIC_kwDON9IuA84CnTai data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://dingyu.dev/>Ding's Coding Forge</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="복사";function s(){t.innerHTML="복사 완료!",setTimeout(()=>{t.innerHTML="복사"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>